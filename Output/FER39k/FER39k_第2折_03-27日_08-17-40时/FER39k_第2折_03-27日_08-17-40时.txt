working dir: /data/zjl/192-torch2/VideoX-master/X-CLIP/Output/
Train: [0/300][0/971]	eta 3:14:29 lr 0.000000000	time 12.0184 (12.0184)	tot_loss 0.8080 (0.8080)	mem 9632MB
Train: [0/300][50/971]	eta 0:09:13 lr 0.000000019	time 0.3499 (0.6006)	tot_loss 0.8418 (0.8314)	mem 12188MB
Train: [0/300][100/971]	eta 0:07:03 lr 0.000000041	time 0.3651 (0.4866)	tot_loss 0.6419 (0.7820)	mem 12188MB
Train: [0/300][150/971]	eta 0:06:08 lr 0.000000061	time 0.3579 (0.4487)	tot_loss 0.6213 (0.7325)	mem 12194MB
Train: [0/300][200/971]	eta 0:05:32 lr 0.000000082	time 0.3582 (0.4318)	tot_loss 0.5814 (0.6917)	mem 12194MB
Train: [0/300][250/971]	eta 0:05:02 lr 0.000000102	time 0.3531 (0.4198)	tot_loss 0.5015 (0.6522)	mem 12194MB
Train: [0/300][300/971]	eta 0:04:36 lr 0.000000123	time 0.3912 (0.4122)	tot_loss 0.4677 (0.6216)	mem 12194MB
Train: [0/300][350/971]	eta 0:04:12 lr 0.000000143	time 0.3864 (0.4065)	tot_loss 0.4695 (0.6001)	mem 12194MB
Train: [0/300][400/971]	eta 0:03:50 lr 0.000000164	time 0.3427 (0.4030)	tot_loss 0.4996 (0.5838)	mem 12194MB
Train: [0/300][450/971]	eta 0:03:28 lr 0.000000184	time 0.3495 (0.3993)	tot_loss 0.4724 (0.5704)	mem 12194MB
Train: [0/300][500/971]	eta 0:03:07 lr 0.000000206	time 0.3830 (0.3972)	tot_loss 0.4729 (0.5599)	mem 12194MB
Train: [0/300][550/971]	eta 0:02:46 lr 0.000000225	time 0.3802 (0.3955)	tot_loss 0.4366 (0.5509)	mem 12194MB
Train: [0/300][600/971]	eta 0:02:26 lr 0.000000247	time 0.3633 (0.3943)	tot_loss 0.4266 (0.5434)	mem 12194MB
Train: [0/300][650/971]	eta 0:02:06 lr 0.000000267	time 0.3642 (0.3932)	tot_loss 0.4673 (0.5376)	mem 12194MB
Train: [0/300][700/971]	eta 0:01:46 lr 0.000000288	time 0.3494 (0.3917)	tot_loss 0.4597 (0.5319)	mem 12194MB
Train: [0/300][750/971]	eta 0:01:26 lr 0.000000308	time 0.3542 (0.3907)	tot_loss 0.4596 (0.5270)	mem 12194MB
Train: [0/300][800/971]	eta 0:01:06 lr 0.000000329	time 0.3652 (0.3897)	tot_loss 0.4742 (0.5232)	mem 12194MB
Train: [0/300][850/971]	eta 0:00:47 lr 0.000000349	time 0.3517 (0.3886)	tot_loss 0.4449 (0.5197)	mem 12194MB
Train: [0/300][900/971]	eta 0:00:27 lr 0.000000370	time 0.3505 (0.3877)	tot_loss 0.4517 (0.5164)	mem 12194MB
Train: [0/300][950/971]	eta 0:00:08 lr 0.000000390	time 0.3348 (0.3870)	tot_loss 0.4469 (0.5132)	mem 12194MB
EPOCH 0 training takes 0:06:15
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 32.353	
Test: [100/3923]	Acc@1: 29.208	
Test: [150/3923]	Acc@1: 29.470	
Test: [200/3923]	Acc@1: 28.358	
Test: [250/3923]	Acc@1: 27.689	
Test: [300/3923]	Acc@1: 27.907	
Test: [350/3923]	Acc@1: 26.923	
Test: [400/3923]	Acc@1: 26.559	
Test: [450/3923]	Acc@1: 26.275	
Test: [500/3923]	Acc@1: 25.948	
Test: [550/3923]	Acc@1: 27.223	
Test: [600/3923]	Acc@1: 27.038	
Test: [650/3923]	Acc@1: 27.496	
Test: [700/3923]	Acc@1: 27.532	
Test: [750/3923]	Acc@1: 27.630	
Test: [800/3923]	Acc@1: 27.403	
Test: [850/3923]	Acc@1: 27.086	
Test: [900/3923]	Acc@1: 27.026	
Test: [950/3923]	Acc@1: 27.340	
Test: [1000/3923]	Acc@1: 27.273	
Test: [1050/3923]	Acc@1: 27.450	
Test: [1100/3923]	Acc@1: 27.157	
Test: [1150/3923]	Acc@1: 26.977	
Test: [1200/3923]	Acc@1: 27.019	
Test: [1250/3923]	Acc@1: 26.978	
Test: [1300/3923]	Acc@1: 27.210	
Test: [1350/3923]	Acc@1: 27.313	
Test: [1400/3923]	Acc@1: 27.231	
Test: [1450/3923]	Acc@1: 27.464	
Test: [1500/3923]	Acc@1: 27.315	
Test: [1550/3923]	Acc@1: 27.369	
Test: [1600/3923]	Acc@1: 27.514	
Test: [1650/3923]	Acc@1: 27.468	
Test: [1700/3923]	Acc@1: 27.396	
Test: [1750/3923]	Acc@1: 27.470	
Test: [1800/3923]	Acc@1: 27.401	
Test: [1850/3923]	Acc@1: 27.634	
Test: [1900/3923]	Acc@1: 27.617	
Test: [1950/3923]	Acc@1: 27.550	
Test: [2000/3923]	Acc@1: 27.511	
Test: [2050/3923]	Acc@1: 27.474	
Test: [2100/3923]	Acc@1: 27.487	
Test: [2150/3923]	Acc@1: 27.476	
Test: [2200/3923]	Acc@1: 27.260	
Test: [2250/3923]	Acc@1: 27.499	
Test: [2300/3923]	Acc@1: 27.423	
Test: [2350/3923]	Acc@1: 27.414	
Test: [2400/3923]	Acc@1: 27.509	
Test: [2450/3923]	Acc@1: 27.315	
Test: [2500/3923]	Acc@1: 27.449	
Test: [2550/3923]	Acc@1: 27.381	
Test: [2600/3923]	Acc@1: 27.432	
Test: [2650/3923]	Acc@1: 27.367	
Test: [2700/3923]	Acc@1: 27.434	
Test: [2750/3923]	Acc@1: 27.299	
Test: [2800/3923]	Acc@1: 27.365	
Test: [2850/3923]	Acc@1: 27.447	
Test: [2900/3923]	Acc@1: 27.473	
Test: [2950/3923]	Acc@1: 27.482	
Test: [3000/3923]	Acc@1: 27.441	
Test: [3050/3923]	Acc@1: 27.450	
Test: [3100/3923]	Acc@1: 27.394	
Test: [3150/3923]	Acc@1: 27.626	
Test: [3200/3923]	Acc@1: 27.694	
Test: [3250/3923]	Acc@1: 27.668	
Test: [3300/3923]	Acc@1: 27.522	
Test: [3350/3923]	Acc@1: 27.499	
Test: [3400/3923]	Acc@1: 27.507	
Test: [3450/3923]	Acc@1: 27.398	
Test: [3500/3923]	Acc@1: 27.435	
Test: [3550/3923]	Acc@1: 27.387	
Test: [3600/3923]	Acc@1: 27.409	
Test: [3650/3923]	Acc@1: 27.376	
Test: [3700/3923]	Acc@1: 27.412	
Test: [3750/3923]	Acc@1: 27.486	
Test: [3800/3923]	Acc@1: 27.480	
Test: [3850/3923]	Acc@1: 27.486	
Test: [3900/3923]	Acc@1: 27.429	
 * Acc@1 27.402 Acc@5 88.491 UAR 19.176Accuracy of the network on the 7847 test videos: 27.4%
Max accuracy: 27.40%, Current UAR : 19.18%, Max UAR :19.18%Train: [1/300][0/971]	eta 1:25:53 lr 0.000000398	time 5.3072 (5.3072)	tot_loss 0.4516 (0.4516)	mem 12194MB
Train: [1/300][50/971]	eta 0:07:20 lr 0.000000419	time 0.3608 (0.4780)	tot_loss 0.4785 (0.4609)	mem 12194MB
Train: [1/300][100/971]	eta 0:06:12 lr 0.000000441	time 0.3616 (0.4277)	tot_loss 0.4451 (0.4598)	mem 12194MB
Train: [1/300][150/971]	eta 0:05:36 lr 0.000000461	time 0.3534 (0.4098)	tot_loss 0.4342 (0.4583)	mem 12194MB
Train: [1/300][200/971]	eta 0:05:08 lr 0.000000482	time 0.3494 (0.3997)	tot_loss 0.4570 (0.4578)	mem 12194MB
Train: [1/300][250/971]	eta 0:04:43 lr 0.000000502	time 0.3498 (0.3936)	tot_loss 0.4566 (0.4575)	mem 12194MB
Train: [1/300][300/971]	eta 0:04:22 lr 0.000000523	time 0.3508 (0.3915)	tot_loss 0.4657 (0.4574)	mem 12194MB
Train: [1/300][350/971]	eta 0:04:01 lr 0.000000543	time 0.3646 (0.3891)	tot_loss 0.4770 (0.4575)	mem 12194MB
Train: [1/300][400/971]	eta 0:03:41 lr 0.000000564	time 0.3605 (0.3875)	tot_loss 0.5001 (0.4580)	mem 12194MB
Train: [1/300][450/971]	eta 0:03:21 lr 0.000000584	time 0.3661 (0.3861)	tot_loss 0.4518 (0.4579)	mem 12194MB
Train: [1/300][500/971]	eta 0:03:01 lr 0.000000606	time 0.3466 (0.3855)	tot_loss 0.4814 (0.4574)	mem 12194MB
Train: [1/300][550/971]	eta 0:02:41 lr 0.000000625	time 0.3448 (0.3844)	tot_loss 0.4605 (0.4571)	mem 12194MB
Train: [1/300][600/971]	eta 0:02:22 lr 0.000000647	time 0.3528 (0.3833)	tot_loss 0.4393 (0.4572)	mem 12194MB
Train: [1/300][650/971]	eta 0:02:02 lr 0.000000667	time 0.3671 (0.3823)	tot_loss 0.4625 (0.4570)	mem 12194MB
Train: [1/300][700/971]	eta 0:01:43 lr 0.000000688	time 0.3548 (0.3816)	tot_loss 0.4987 (0.4566)	mem 12194MB
Train: [1/300][750/971]	eta 0:01:24 lr 0.000000708	time 0.3587 (0.3807)	tot_loss 0.4673 (0.4568)	mem 12194MB
Train: [1/300][800/971]	eta 0:01:05 lr 0.000000729	time 0.3512 (0.3802)	tot_loss 0.4314 (0.4564)	mem 12194MB
Train: [1/300][850/971]	eta 0:00:45 lr 0.000000749	time 0.3537 (0.3797)	tot_loss 0.4879 (0.4563)	mem 12194MB
Train: [1/300][900/971]	eta 0:00:26 lr 0.000000770	time 0.3416 (0.3793)	tot_loss 0.4788 (0.4561)	mem 12194MB
Train: [1/300][950/971]	eta 0:00:07 lr 0.000000790	time 0.3370 (0.3786)	tot_loss 0.4635 (0.4563)	mem 12194MB
EPOCH 1 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 21.569	
Test: [100/3923]	Acc@1: 23.267	
Test: [150/3923]	Acc@1: 22.185	
Test: [200/3923]	Acc@1: 22.886	
Test: [250/3923]	Acc@1: 23.506	
Test: [300/3923]	Acc@1: 24.252	
Test: [350/3923]	Acc@1: 25.641	
Test: [400/3923]	Acc@1: 27.556	
Test: [450/3923]	Acc@1: 26.940	
Test: [500/3923]	Acc@1: 26.647	
Test: [550/3923]	Acc@1: 26.951	
Test: [600/3923]	Acc@1: 26.955	
Test: [650/3923]	Acc@1: 27.803	
Test: [700/3923]	Acc@1: 28.031	
Test: [750/3923]	Acc@1: 28.429	
Test: [800/3923]	Acc@1: 28.277	
Test: [850/3923]	Acc@1: 28.026	
Test: [900/3923]	Acc@1: 28.135	
Test: [950/3923]	Acc@1: 28.181	
Test: [1000/3923]	Acc@1: 27.922	
Test: [1050/3923]	Acc@1: 28.164	
Test: [1100/3923]	Acc@1: 27.929	
Test: [1150/3923]	Acc@1: 28.323	
Test: [1200/3923]	Acc@1: 28.185	
Test: [1250/3923]	Acc@1: 28.297	
Test: [1300/3923]	Acc@1: 28.709	
Test: [1350/3923]	Acc@1: 28.979	
Test: [1400/3923]	Acc@1: 29.229	
Test: [1450/3923]	Acc@1: 29.359	
Test: [1500/3923]	Acc@1: 29.414	
Test: [1550/3923]	Acc@1: 29.626	
Test: [1600/3923]	Acc@1: 29.731	
Test: [1650/3923]	Acc@1: 29.679	
Test: [1700/3923]	Acc@1: 29.806	
Test: [1750/3923]	Acc@1: 29.697	
Test: [1800/3923]	Acc@1: 29.706	
Test: [1850/3923]	Acc@1: 29.660	
Test: [1900/3923]	Acc@1: 29.695	
Test: [1950/3923]	Acc@1: 29.575	
Test: [2000/3923]	Acc@1: 29.535	
Test: [2050/3923]	Acc@1: 29.595	
Test: [2100/3923]	Acc@1: 29.700	
Test: [2150/3923]	Acc@1: 29.800	
Test: [2200/3923]	Acc@1: 29.986	
Test: [2250/3923]	Acc@1: 29.942	
Test: [2300/3923]	Acc@1: 29.791	
Test: [2350/3923]	Acc@1: 29.838	
Test: [2400/3923]	Acc@1: 29.696	
Test: [2450/3923]	Acc@1: 29.600	
Test: [2500/3923]	Acc@1: 29.428	
Test: [2550/3923]	Acc@1: 29.302	
Test: [2600/3923]	Acc@1: 29.316	
Test: [2650/3923]	Acc@1: 29.215	
Test: [2700/3923]	Acc@1: 29.156	
Test: [2750/3923]	Acc@1: 29.153	
Test: [2800/3923]	Acc@1: 29.115	
Test: [2850/3923]	Acc@1: 29.270	
Test: [2900/3923]	Acc@1: 29.352	
Test: [2950/3923]	Acc@1: 29.397	
Test: [3000/3923]	Acc@1: 29.457	
Test: [3050/3923]	Acc@1: 29.630	
Test: [3100/3923]	Acc@1: 29.539	
Test: [3150/3923]	Acc@1: 29.467	
Test: [3200/3923]	Acc@1: 29.444	
Test: [3250/3923]	Acc@1: 29.529	
Test: [3300/3923]	Acc@1: 29.506	
Test: [3350/3923]	Acc@1: 29.543	
Test: [3400/3923]	Acc@1: 29.550	
Test: [3450/3923]	Acc@1: 29.542	
Test: [3500/3923]	Acc@1: 29.420	
Test: [3550/3923]	Acc@1: 29.555	
Test: [3600/3923]	Acc@1: 29.506	
Test: [3650/3923]	Acc@1: 29.403	
Test: [3700/3923]	Acc@1: 29.370	
Test: [3750/3923]	Acc@1: 29.366	
Test: [3800/3923]	Acc@1: 29.400	
Test: [3850/3923]	Acc@1: 29.356	
Test: [3900/3923]	Acc@1: 29.390	
 * Acc@1 29.442 Acc@5 89.064 UAR 21.363Accuracy of the network on the 7847 test videos: 29.4%
Max accuracy: 29.44%, Current UAR : 21.36%, Max UAR :21.36%Train: [2/300][0/971]	eta 1:14:20 lr 0.000000798	time 4.5935 (4.5935)	tot_loss 0.4538 (0.4538)	mem 12194MB
Train: [2/300][50/971]	eta 0:07:19 lr 0.000000819	time 0.3592 (0.4768)	tot_loss 0.4535 (0.4513)	mem 12194MB
Train: [2/300][100/971]	eta 0:06:12 lr 0.000000841	time 0.3530 (0.4272)	tot_loss 0.4787 (0.4516)	mem 12194MB
Train: [2/300][150/971]	eta 0:05:37 lr 0.000000861	time 0.3567 (0.4110)	tot_loss 0.4679 (0.4535)	mem 12194MB
Train: [2/300][200/971]	eta 0:05:09 lr 0.000000882	time 0.3468 (0.4019)	tot_loss 0.4644 (0.4530)	mem 12194MB
Train: [2/300][250/971]	eta 0:04:45 lr 0.000000902	time 0.3468 (0.3959)	tot_loss 0.4713 (0.4525)	mem 12194MB
Train: [2/300][300/971]	eta 0:04:23 lr 0.000000923	time 0.3586 (0.3927)	tot_loss 0.4406 (0.4521)	mem 12194MB
Train: [2/300][350/971]	eta 0:04:02 lr 0.000000943	time 0.3584 (0.3902)	tot_loss 0.4460 (0.4521)	mem 12194MB
Train: [2/300][400/971]	eta 0:03:41 lr 0.000000964	time 0.3595 (0.3887)	tot_loss 0.4816 (0.4521)	mem 12194MB
Train: [2/300][450/971]	eta 0:03:21 lr 0.000000984	time 0.3552 (0.3874)	tot_loss 0.4298 (0.4517)	mem 12194MB
Train: [2/300][500/971]	eta 0:03:01 lr 0.000001006	time 0.3627 (0.3863)	tot_loss 0.4046 (0.4513)	mem 12194MB
Train: [2/300][550/971]	eta 0:02:42 lr 0.000001025	time 0.3582 (0.3856)	tot_loss 0.4874 (0.4504)	mem 12194MB
Train: [2/300][600/971]	eta 0:02:22 lr 0.000001047	time 0.3615 (0.3845)	tot_loss 0.4438 (0.4503)	mem 12194MB
Train: [2/300][650/971]	eta 0:02:03 lr 0.000001067	time 0.3533 (0.3840)	tot_loss 0.4356 (0.4498)	mem 12194MB
Train: [2/300][700/971]	eta 0:01:43 lr 0.000001088	time 0.3891 (0.3835)	tot_loss 0.4513 (0.4495)	mem 12194MB
Train: [2/300][750/971]	eta 0:01:24 lr 0.000001108	time 0.3692 (0.3829)	tot_loss 0.4809 (0.4493)	mem 12194MB
Train: [2/300][800/971]	eta 0:01:05 lr 0.000001129	time 0.3956 (0.3827)	tot_loss 0.4454 (0.4491)	mem 12194MB
Train: [2/300][850/971]	eta 0:00:46 lr 0.000001149	time 0.3541 (0.3820)	tot_loss 0.4248 (0.4492)	mem 12194MB
Train: [2/300][900/971]	eta 0:00:27 lr 0.000001170	time 0.3529 (0.3818)	tot_loss 0.3987 (0.4490)	mem 12194MB
Train: [2/300][950/971]	eta 0:00:08 lr 0.000001190	time 0.3392 (0.3810)	tot_loss 0.4502 (0.4486)	mem 12194MB
EPOCH 2 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 34.314	
Test: [100/3923]	Acc@1: 34.158	
Test: [150/3923]	Acc@1: 33.775	
Test: [200/3923]	Acc@1: 34.826	
Test: [250/3923]	Acc@1: 33.665	
Test: [300/3923]	Acc@1: 33.887	
Test: [350/3923]	Acc@1: 35.185	
Test: [400/3923]	Acc@1: 35.411	
Test: [450/3923]	Acc@1: 35.255	
Test: [500/3923]	Acc@1: 35.130	
Test: [550/3923]	Acc@1: 35.299	
Test: [600/3923]	Acc@1: 35.691	
Test: [650/3923]	Acc@1: 35.177	
Test: [700/3923]	Acc@1: 35.093	
Test: [750/3923]	Acc@1: 35.419	
Test: [800/3923]	Acc@1: 35.518	
Test: [850/3923]	Acc@1: 35.076	
Test: [900/3923]	Acc@1: 35.350	
Test: [950/3923]	Acc@1: 35.752	
Test: [1000/3923]	Acc@1: 35.315	
Test: [1050/3923]	Acc@1: 35.014	
Test: [1100/3923]	Acc@1: 35.014	
Test: [1150/3923]	Acc@1: 35.187	
Test: [1200/3923]	Acc@1: 35.179	
Test: [1250/3923]	Acc@1: 34.772	
Test: [1300/3923]	Acc@1: 34.397	
Test: [1350/3923]	Acc@1: 34.567	
Test: [1400/3923]	Acc@1: 34.761	
Test: [1450/3923]	Acc@1: 34.735	
Test: [1500/3923]	Acc@1: 34.610	
Test: [1550/3923]	Acc@1: 34.752	
Test: [1600/3923]	Acc@1: 34.791	
Test: [1650/3923]	Acc@1: 34.827	
Test: [1700/3923]	Acc@1: 34.950	
Test: [1750/3923]	Acc@1: 35.151	
Test: [1800/3923]	Acc@1: 35.314	
Test: [1850/3923]	Acc@1: 35.224	
Test: [1900/3923]	Acc@1: 35.060	
Test: [1950/3923]	Acc@1: 35.264	
Test: [2000/3923]	Acc@1: 35.207	
Test: [2050/3923]	Acc@1: 35.251	
Test: [2100/3923]	Acc@1: 35.150	
Test: [2150/3923]	Acc@1: 34.960	
Test: [2200/3923]	Acc@1: 35.075	
Test: [2250/3923]	Acc@1: 35.029	
Test: [2300/3923]	Acc@1: 34.963	
Test: [2350/3923]	Acc@1: 34.900	
Test: [2400/3923]	Acc@1: 34.756	
Test: [2450/3923]	Acc@1: 34.782	
Test: [2500/3923]	Acc@1: 34.766	
Test: [2550/3923]	Acc@1: 34.829	
Test: [2600/3923]	Acc@1: 34.660	
Test: [2650/3923]	Acc@1: 34.930	
Test: [2700/3923]	Acc@1: 35.080	
Test: [2750/3923]	Acc@1: 35.115	
Test: [2800/3923]	Acc@1: 35.220	
Test: [2850/3923]	Acc@1: 35.163	
Test: [2900/3923]	Acc@1: 35.143	
Test: [2950/3923]	Acc@1: 35.056	
Test: [3000/3923]	Acc@1: 35.038	
Test: [3050/3923]	Acc@1: 34.972	
Test: [3100/3923]	Acc@1: 34.973	
Test: [3150/3923]	Acc@1: 35.021	
Test: [3200/3923]	Acc@1: 35.020	
Test: [3250/3923]	Acc@1: 34.989	
Test: [3300/3923]	Acc@1: 34.868	
Test: [3350/3923]	Acc@1: 34.781	
Test: [3400/3923]	Acc@1: 34.799	
Test: [3450/3923]	Acc@1: 34.773	
Test: [3500/3923]	Acc@1: 34.604	
Test: [3550/3923]	Acc@1: 34.582	
Test: [3600/3923]	Acc@1: 34.477	
Test: [3650/3923]	Acc@1: 34.443	
Test: [3700/3923]	Acc@1: 34.369	
Test: [3750/3923]	Acc@1: 34.351	
Test: [3800/3923]	Acc@1: 34.307	
Test: [3850/3923]	Acc@1: 34.511	
Test: [3900/3923]	Acc@1: 34.491	
 * Acc@1 34.463 Acc@5 90.811 UAR 24.293Accuracy of the network on the 7847 test videos: 34.5%
Max accuracy: 34.46%, Current UAR : 24.29%, Max UAR :24.29%Train: [3/300][0/971]	eta 1:37:35 lr 0.000001198	time 6.0308 (6.0308)	tot_loss 0.4549 (0.4549)	mem 12194MB
Train: [3/300][50/971]	eta 0:07:26 lr 0.000001219	time 0.3428 (0.4844)	tot_loss 0.4180 (0.4439)	mem 12194MB
Train: [3/300][100/971]	eta 0:06:17 lr 0.000001241	time 0.3651 (0.4335)	tot_loss 0.4672 (0.4433)	mem 12194MB
Train: [3/300][150/971]	eta 0:05:40 lr 0.000001261	time 0.3540 (0.4145)	tot_loss 0.4227 (0.4438)	mem 12194MB
Train: [3/300][200/971]	eta 0:05:12 lr 0.000001282	time 0.3922 (0.4054)	tot_loss 0.4366 (0.4443)	mem 12194MB
Train: [3/300][250/971]	eta 0:04:48 lr 0.000001302	time 0.3527 (0.4003)	tot_loss 0.4465 (0.4445)	mem 12194MB
Train: [3/300][300/971]	eta 0:04:25 lr 0.000001323	time 0.3490 (0.3962)	tot_loss 0.4309 (0.4448)	mem 12194MB
Train: [3/300][350/971]	eta 0:04:04 lr 0.000001343	time 0.3690 (0.3931)	tot_loss 0.4562 (0.4449)	mem 12194MB
Train: [3/300][400/971]	eta 0:03:43 lr 0.000001364	time 0.3488 (0.3908)	tot_loss 0.4591 (0.4450)	mem 12194MB
Train: [3/300][450/971]	eta 0:03:22 lr 0.000001384	time 0.3596 (0.3895)	tot_loss 0.4734 (0.4447)	mem 12194MB
Train: [3/300][500/971]	eta 0:03:02 lr 0.000001406	time 0.3548 (0.3879)	tot_loss 0.4657 (0.4446)	mem 12194MB
Train: [3/300][550/971]	eta 0:02:42 lr 0.000001425	time 0.3612 (0.3868)	tot_loss 0.4586 (0.4446)	mem 12194MB
Train: [3/300][600/971]	eta 0:02:23 lr 0.000001447	time 0.3530 (0.3860)	tot_loss 0.4134 (0.4446)	mem 12194MB
Train: [3/300][650/971]	eta 0:02:03 lr 0.000001467	time 0.3539 (0.3853)	tot_loss 0.4028 (0.4441)	mem 12194MB
Train: [3/300][700/971]	eta 0:01:44 lr 0.000001488	time 0.3502 (0.3845)	tot_loss 0.4693 (0.4441)	mem 12194MB
Train: [3/300][750/971]	eta 0:01:24 lr 0.000001508	time 0.3490 (0.3836)	tot_loss 0.4916 (0.4443)	mem 12194MB
Train: [3/300][800/971]	eta 0:01:05 lr 0.000001529	time 0.3555 (0.3835)	tot_loss 0.4270 (0.4438)	mem 12194MB
Train: [3/300][850/971]	eta 0:00:46 lr 0.000001549	time 0.3524 (0.3825)	tot_loss 0.4002 (0.4438)	mem 12194MB
Train: [3/300][900/971]	eta 0:00:27 lr 0.000001570	time 0.3658 (0.3821)	tot_loss 0.4334 (0.4434)	mem 12194MB
Train: [3/300][950/971]	eta 0:00:08 lr 0.000001590	time 0.3375 (0.3818)	tot_loss 0.4247 (0.4430)	mem 12194MB
EPOCH 3 training takes 0:06:10
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 37.255	
Test: [100/3923]	Acc@1: 35.149	
Test: [150/3923]	Acc@1: 38.411	
Test: [200/3923]	Acc@1: 38.060	
Test: [250/3923]	Acc@1: 37.251	
Test: [300/3923]	Acc@1: 38.206	
Test: [350/3923]	Acc@1: 37.749	
Test: [400/3923]	Acc@1: 38.529	
Test: [450/3923]	Acc@1: 38.248	
Test: [500/3923]	Acc@1: 38.523	
Test: [550/3923]	Acc@1: 38.657	
Test: [600/3923]	Acc@1: 38.686	
Test: [650/3923]	Acc@1: 38.940	
Test: [700/3923]	Acc@1: 39.444	
Test: [750/3923]	Acc@1: 39.081	
Test: [800/3923]	Acc@1: 38.951	
Test: [850/3923]	Acc@1: 39.130	
Test: [900/3923]	Acc@1: 38.957	
Test: [950/3923]	Acc@1: 39.485	
Test: [1000/3923]	Acc@1: 39.660	
Test: [1050/3923]	Acc@1: 39.343	
Test: [1100/3923]	Acc@1: 39.282	
Test: [1150/3923]	Acc@1: 39.444	
Test: [1200/3923]	Acc@1: 39.467	
Test: [1250/3923]	Acc@1: 39.169	
Test: [1300/3923]	Acc@1: 39.431	
Test: [1350/3923]	Acc@1: 39.600	
Test: [1400/3923]	Acc@1: 39.400	
Test: [1450/3923]	Acc@1: 39.456	
Test: [1500/3923]	Acc@1: 39.474	
Test: [1550/3923]	Acc@1: 39.620	
Test: [1600/3923]	Acc@1: 39.475	
Test: [1650/3923]	Acc@1: 39.340	
Test: [1700/3923]	Acc@1: 39.212	
Test: [1750/3923]	Acc@1: 39.292	
Test: [1800/3923]	Acc@1: 39.228	
Test: [1850/3923]	Acc@1: 39.357	
Test: [1900/3923]	Acc@1: 39.663	
Test: [1950/3923]	Acc@1: 39.774	
Test: [2000/3923]	Acc@1: 40.030	
Test: [2050/3923]	Acc@1: 40.102	
Test: [2100/3923]	Acc@1: 40.219	
Test: [2150/3923]	Acc@1: 40.284	
Test: [2200/3923]	Acc@1: 40.300	
Test: [2250/3923]	Acc@1: 40.227	
Test: [2300/3923]	Acc@1: 40.309	
Test: [2350/3923]	Acc@1: 40.408	
Test: [2400/3923]	Acc@1: 40.254	
Test: [2450/3923]	Acc@1: 40.330	
Test: [2500/3923]	Acc@1: 40.304	
Test: [2550/3923]	Acc@1: 40.200	
Test: [2600/3923]	Acc@1: 40.158	
Test: [2650/3923]	Acc@1: 40.155	
Test: [2700/3923]	Acc@1: 40.189	
Test: [2750/3923]	Acc@1: 40.185	
Test: [2800/3923]	Acc@1: 40.093	
Test: [2850/3923]	Acc@1: 40.091	
Test: [2900/3923]	Acc@1: 40.003	
Test: [2950/3923]	Acc@1: 40.190	
Test: [3000/3923]	Acc@1: 39.987	
Test: [3050/3923]	Acc@1: 39.938	
Test: [3100/3923]	Acc@1: 39.987	
Test: [3150/3923]	Acc@1: 39.924	
Test: [3200/3923]	Acc@1: 39.878	
Test: [3250/3923]	Acc@1: 39.695	
Test: [3300/3923]	Acc@1: 39.685	
Test: [3350/3923]	Acc@1: 39.645	
Test: [3400/3923]	Acc@1: 39.694	
Test: [3450/3923]	Acc@1: 39.728	
Test: [3500/3923]	Acc@1: 39.703	
Test: [3550/3923]	Acc@1: 39.693	
Test: [3600/3923]	Acc@1: 39.670	
Test: [3650/3923]	Acc@1: 39.619	
Test: [3700/3923]	Acc@1: 39.597	
Test: [3750/3923]	Acc@1: 39.603	
Test: [3800/3923]	Acc@1: 39.542	
Test: [3850/3923]	Acc@1: 39.522	
Test: [3900/3923]	Acc@1: 39.451	
 * Acc@1 39.409 Acc@5 91.728 UAR 26.934Accuracy of the network on the 7847 test videos: 39.4%
Max accuracy: 39.41%, Current UAR : 26.93%, Max UAR :26.93%Train: [4/300][0/971]	eta 1:28:11 lr 0.000001598	time 5.4493 (5.4493)	tot_loss 0.4496 (0.4496)	mem 12194MB
Train: [4/300][50/971]	eta 0:07:25 lr 0.000001619	time 0.3542 (0.4837)	tot_loss 0.4508 (0.4451)	mem 12194MB
Train: [4/300][100/971]	eta 0:06:13 lr 0.000001641	time 0.3518 (0.4287)	tot_loss 0.4510 (0.4405)	mem 12194MB
Train: [4/300][150/971]	eta 0:05:36 lr 0.000001661	time 0.3579 (0.4104)	tot_loss 0.4356 (0.4377)	mem 12194MB
Train: [4/300][200/971]	eta 0:05:09 lr 0.000001682	time 0.3486 (0.4013)	tot_loss 0.4542 (0.4384)	mem 12194MB
Train: [4/300][250/971]	eta 0:04:45 lr 0.000001702	time 0.3571 (0.3953)	tot_loss 0.4320 (0.4388)	mem 12194MB
Train: [4/300][300/971]	eta 0:04:22 lr 0.000001723	time 0.3520 (0.3919)	tot_loss 0.4416 (0.4379)	mem 12194MB
Train: [4/300][350/971]	eta 0:04:01 lr 0.000001743	time 0.3525 (0.3890)	tot_loss 0.4116 (0.4371)	mem 12194MB
Train: [4/300][400/971]	eta 0:03:41 lr 0.000001764	time 0.3444 (0.3875)	tot_loss 0.4201 (0.4370)	mem 12194MB
Train: [4/300][450/971]	eta 0:03:21 lr 0.000001784	time 0.3542 (0.3858)	tot_loss 0.4396 (0.4367)	mem 12194MB
Train: [4/300][500/971]	eta 0:03:01 lr 0.000001806	time 0.3442 (0.3845)	tot_loss 0.4171 (0.4368)	mem 12194MB
Train: [4/300][550/971]	eta 0:02:41 lr 0.000001825	time 0.3588 (0.3832)	tot_loss 0.4168 (0.4369)	mem 12194MB
Train: [4/300][600/971]	eta 0:02:21 lr 0.000001847	time 0.3494 (0.3824)	tot_loss 0.3930 (0.4366)	mem 12194MB
Train: [4/300][650/971]	eta 0:02:02 lr 0.000001867	time 0.3546 (0.3822)	tot_loss 0.4678 (0.4368)	mem 12194MB
Train: [4/300][700/971]	eta 0:01:43 lr 0.000001888	time 0.3533 (0.3816)	tot_loss 0.4630 (0.4371)	mem 12194MB
Train: [4/300][750/971]	eta 0:01:24 lr 0.000001908	time 0.3563 (0.3810)	tot_loss 0.4497 (0.4373)	mem 12194MB
Train: [4/300][800/971]	eta 0:01:05 lr 0.000001929	time 0.3505 (0.3804)	tot_loss 0.4466 (0.4373)	mem 12194MB
Train: [4/300][850/971]	eta 0:00:45 lr 0.000001949	time 0.3486 (0.3798)	tot_loss 0.4645 (0.4374)	mem 12194MB
Train: [4/300][900/971]	eta 0:00:26 lr 0.000001970	time 0.3576 (0.3798)	tot_loss 0.4915 (0.4373)	mem 12194MB
Train: [4/300][950/971]	eta 0:00:07 lr 0.000001990	time 0.3319 (0.3792)	tot_loss 0.4698 (0.4373)	mem 12194MB
EPOCH 4 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 39.216	
Test: [100/3923]	Acc@1: 43.069	
Test: [150/3923]	Acc@1: 43.046	
Test: [200/3923]	Acc@1: 40.050	
Test: [250/3923]	Acc@1: 40.837	
Test: [300/3923]	Acc@1: 41.528	
Test: [350/3923]	Acc@1: 41.311	
Test: [400/3923]	Acc@1: 41.521	
Test: [450/3923]	Acc@1: 41.242	
Test: [500/3923]	Acc@1: 40.519	
Test: [550/3923]	Acc@1: 41.289	
Test: [600/3923]	Acc@1: 41.597	
Test: [650/3923]	Acc@1: 41.091	
Test: [700/3923]	Acc@1: 40.514	
Test: [750/3923]	Acc@1: 40.280	
Test: [800/3923]	Acc@1: 39.888	
Test: [850/3923]	Acc@1: 39.777	
Test: [900/3923]	Acc@1: 40.011	
Test: [950/3923]	Acc@1: 39.695	
Test: [1000/3923]	Acc@1: 39.411	
Test: [1050/3923]	Acc@1: 39.296	
Test: [1100/3923]	Acc@1: 39.192	
Test: [1150/3923]	Acc@1: 39.183	
Test: [1200/3923]	Acc@1: 39.217	
Test: [1250/3923]	Acc@1: 39.528	
Test: [1300/3923]	Acc@1: 39.470	
Test: [1350/3923]	Acc@1: 39.674	
Test: [1400/3923]	Acc@1: 39.793	
Test: [1450/3923]	Acc@1: 39.800	
Test: [1500/3923]	Acc@1: 39.873	
Test: [1550/3923]	Acc@1: 39.877	
Test: [1600/3923]	Acc@1: 39.913	
Test: [1650/3923]	Acc@1: 40.036	
Test: [1700/3923]	Acc@1: 40.035	
Test: [1750/3923]	Acc@1: 40.063	
Test: [1800/3923]	Acc@1: 40.144	
Test: [1850/3923]	Acc@1: 40.005	
Test: [1900/3923]	Acc@1: 40.216	
Test: [1950/3923]	Acc@1: 40.415	
Test: [2000/3923]	Acc@1: 40.555	
Test: [2050/3923]	Acc@1: 40.346	
Test: [2100/3923]	Acc@1: 40.409	
Test: [2150/3923]	Acc@1: 40.493	
Test: [2200/3923]	Acc@1: 40.618	
Test: [2250/3923]	Acc@1: 40.538	
Test: [2300/3923]	Acc@1: 40.700	
Test: [2350/3923]	Acc@1: 40.706	
Test: [2400/3923]	Acc@1: 40.775	
Test: [2450/3923]	Acc@1: 40.759	
Test: [2500/3923]	Acc@1: 40.804	
Test: [2550/3923]	Acc@1: 40.612	
Test: [2600/3923]	Acc@1: 40.734	
Test: [2650/3923]	Acc@1: 40.777	
Test: [2700/3923]	Acc@1: 40.689	
Test: [2750/3923]	Acc@1: 40.658	
Test: [2800/3923]	Acc@1: 40.628	
Test: [2850/3923]	Acc@1: 40.565	
Test: [2900/3923]	Acc@1: 40.624	
Test: [2950/3923]	Acc@1: 40.613	
Test: [3000/3923]	Acc@1: 40.553	
Test: [3050/3923]	Acc@1: 40.593	
Test: [3100/3923]	Acc@1: 40.600	
Test: [3150/3923]	Acc@1: 40.670	
Test: [3200/3923]	Acc@1: 40.706	
Test: [3250/3923]	Acc@1: 40.541	
Test: [3300/3923]	Acc@1: 40.715	
Test: [3350/3923]	Acc@1: 40.660	
Test: [3400/3923]	Acc@1: 40.650	
Test: [3450/3923]	Acc@1: 40.568	
Test: [3500/3923]	Acc@1: 40.617	
Test: [3550/3923]	Acc@1: 40.665	
Test: [3600/3923]	Acc@1: 40.558	
Test: [3650/3923]	Acc@1: 40.482	
Test: [3700/3923]	Acc@1: 40.570	
Test: [3750/3923]	Acc@1: 40.563	
Test: [3800/3923]	Acc@1: 40.542	
Test: [3850/3923]	Acc@1: 40.626	
Test: [3900/3923]	Acc@1: 40.605	
 * Acc@1 40.594 Acc@5 91.461 UAR 28.164Accuracy of the network on the 7847 test videos: 40.6%
Max accuracy: 40.59%, Current UAR : 28.16%, Max UAR :28.16%Train: [5/300][0/971]	eta 1:30:47 lr 0.000001998	time 5.6098 (5.6098)	tot_loss 0.4348 (0.4348)	mem 12194MB
Train: [5/300][50/971]	eta 0:07:18 lr 0.000001999	time 0.3525 (0.4764)	tot_loss 0.4471 (0.4324)	mem 12194MB
Train: [5/300][100/971]	eta 0:06:10 lr 0.000001999	time 0.3695 (0.4252)	tot_loss 0.4345 (0.4339)	mem 12194MB
Train: [5/300][150/971]	eta 0:05:35 lr 0.000001999	time 0.3519 (0.4086)	tot_loss 0.4018 (0.4338)	mem 12194MB
Train: [5/300][200/971]	eta 0:05:09 lr 0.000001999	time 0.3487 (0.4015)	tot_loss 0.4720 (0.4345)	mem 12194MB
Train: [5/300][250/971]	eta 0:04:44 lr 0.000001999	time 0.3576 (0.3951)	tot_loss 0.4386 (0.4332)	mem 12194MB
Train: [5/300][300/971]	eta 0:04:22 lr 0.000001998	time 0.3922 (0.3919)	tot_loss 0.4623 (0.4332)	mem 12194MB
Train: [5/300][350/971]	eta 0:04:01 lr 0.000001998	time 0.3523 (0.3897)	tot_loss 0.4890 (0.4336)	mem 12194MB
Train: [5/300][400/971]	eta 0:03:41 lr 0.000001998	time 0.3639 (0.3877)	tot_loss 0.4695 (0.4339)	mem 12194MB
Train: [5/300][450/971]	eta 0:03:21 lr 0.000001998	time 0.3580 (0.3859)	tot_loss 0.4148 (0.4344)	mem 12194MB
Train: [5/300][500/971]	eta 0:03:01 lr 0.000001998	time 0.3502 (0.3851)	tot_loss 0.4013 (0.4340)	mem 12194MB
Train: [5/300][550/971]	eta 0:02:41 lr 0.000001998	time 0.3591 (0.3843)	tot_loss 0.4221 (0.4342)	mem 12194MB
Train: [5/300][600/971]	eta 0:02:22 lr 0.000001998	time 0.3612 (0.3839)	tot_loss 0.3964 (0.4338)	mem 12194MB
Train: [5/300][650/971]	eta 0:02:03 lr 0.000001998	time 0.3611 (0.3833)	tot_loss 0.4005 (0.4336)	mem 12194MB
Train: [5/300][700/971]	eta 0:01:43 lr 0.000001998	time 0.3520 (0.3829)	tot_loss 0.4061 (0.4333)	mem 12194MB
Train: [5/300][750/971]	eta 0:01:24 lr 0.000001998	time 0.3579 (0.3827)	tot_loss 0.4105 (0.4330)	mem 12194MB
Train: [5/300][800/971]	eta 0:01:05 lr 0.000001998	time 0.3579 (0.3824)	tot_loss 0.4114 (0.4327)	mem 12194MB
Train: [5/300][850/971]	eta 0:00:46 lr 0.000001998	time 0.3568 (0.3823)	tot_loss 0.4672 (0.4328)	mem 12194MB
Train: [5/300][900/971]	eta 0:00:27 lr 0.000001998	time 0.3635 (0.3819)	tot_loss 0.4328 (0.4328)	mem 12194MB
Train: [5/300][950/971]	eta 0:00:08 lr 0.000001998	time 0.3381 (0.3812)	tot_loss 0.4316 (0.4332)	mem 12194MB
EPOCH 5 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 38.235	
Test: [100/3923]	Acc@1: 36.139	
Test: [150/3923]	Acc@1: 36.755	
Test: [200/3923]	Acc@1: 38.308	
Test: [250/3923]	Acc@1: 38.845	
Test: [300/3923]	Acc@1: 38.372	
Test: [350/3923]	Acc@1: 38.177	
Test: [400/3923]	Acc@1: 37.905	
Test: [450/3923]	Acc@1: 37.805	
Test: [500/3923]	Acc@1: 37.824	
Test: [550/3923]	Acc@1: 38.113	
Test: [600/3923]	Acc@1: 38.436	
Test: [650/3923]	Acc@1: 38.479	
Test: [700/3923]	Acc@1: 38.516	
Test: [750/3923]	Acc@1: 39.214	
Test: [800/3923]	Acc@1: 40.137	
Test: [850/3923]	Acc@1: 40.423	
Test: [900/3923]	Acc@1: 40.566	
Test: [950/3923]	Acc@1: 40.431	
Test: [1000/3923]	Acc@1: 40.659	
Test: [1050/3923]	Acc@1: 40.533	
Test: [1100/3923]	Acc@1: 40.690	
Test: [1150/3923]	Acc@1: 40.443	
Test: [1200/3923]	Acc@1: 40.716	
Test: [1250/3923]	Acc@1: 40.807	
Test: [1300/3923]	Acc@1: 41.314	
Test: [1350/3923]	Acc@1: 41.710	
Test: [1400/3923]	Acc@1: 41.577	
Test: [1450/3923]	Acc@1: 41.523	
Test: [1500/3923]	Acc@1: 41.472	
Test: [1550/3923]	Acc@1: 41.425	
Test: [1600/3923]	Acc@1: 41.287	
Test: [1650/3923]	Acc@1: 41.641	
Test: [1700/3923]	Acc@1: 41.593	
Test: [1750/3923]	Acc@1: 41.519	
Test: [1800/3923]	Acc@1: 41.560	
Test: [1850/3923]	Acc@1: 41.599	
Test: [1900/3923]	Acc@1: 41.636	
Test: [1950/3923]	Acc@1: 41.748	
Test: [2000/3923]	Acc@1: 41.804	
Test: [2050/3923]	Acc@1: 41.784	
Test: [2100/3923]	Acc@1: 41.694	
Test: [2150/3923]	Acc@1: 41.585	
Test: [2200/3923]	Acc@1: 41.322	
Test: [2250/3923]	Acc@1: 41.204	
Test: [2300/3923]	Acc@1: 41.091	
Test: [2350/3923]	Acc@1: 41.174	
Test: [2400/3923]	Acc@1: 41.254	
Test: [2450/3923]	Acc@1: 41.248	
Test: [2500/3923]	Acc@1: 41.204	
Test: [2550/3923]	Acc@1: 41.200	
Test: [2600/3923]	Acc@1: 41.196	
Test: [2650/3923]	Acc@1: 41.362	
Test: [2700/3923]	Acc@1: 41.318	
Test: [2750/3923]	Acc@1: 41.439	
Test: [2800/3923]	Acc@1: 41.485	
Test: [2850/3923]	Acc@1: 41.477	
Test: [2900/3923]	Acc@1: 41.555	
Test: [2950/3923]	Acc@1: 41.562	
Test: [3000/3923]	Acc@1: 41.619	
Test: [3050/3923]	Acc@1: 41.642	
Test: [3100/3923]	Acc@1: 41.745	
Test: [3150/3923]	Acc@1: 41.796	
Test: [3200/3923]	Acc@1: 41.784	
Test: [3250/3923]	Acc@1: 41.803	
Test: [3300/3923]	Acc@1: 41.715	
Test: [3350/3923]	Acc@1: 41.734	
Test: [3400/3923]	Acc@1: 41.752	
Test: [3450/3923]	Acc@1: 41.742	
Test: [3500/3923]	Acc@1: 41.674	
Test: [3550/3923]	Acc@1: 41.594	
Test: [3600/3923]	Acc@1: 41.544	
Test: [3650/3923]	Acc@1: 41.564	
Test: [3700/3923]	Acc@1: 41.502	
Test: [3750/3923]	Acc@1: 41.522	
Test: [3800/3923]	Acc@1: 41.568	
Test: [3850/3923]	Acc@1: 41.587	
Test: [3900/3923]	Acc@1: 41.605	
 * Acc@1 41.563 Acc@5 93.372 UAR 30.209Accuracy of the network on the 7847 test videos: 41.6%
Max accuracy: 41.56%, Current UAR : 30.21%, Max UAR :30.21%Train: [6/300][0/971]	eta 1:03:33 lr 0.000001998	time 3.9271 (3.9271)	tot_loss 0.4320 (0.4320)	mem 12194MB
Train: [6/300][50/971]	eta 0:07:07 lr 0.000001998	time 0.3516 (0.4636)	tot_loss 0.4533 (0.4282)	mem 12194MB
Train: [6/300][100/971]	eta 0:06:06 lr 0.000001998	time 0.3692 (0.4205)	tot_loss 0.4334 (0.4281)	mem 12194MB
Train: [6/300][150/971]	eta 0:05:38 lr 0.000001998	time 0.3919 (0.4122)	tot_loss 0.4102 (0.4285)	mem 12194MB
Train: [6/300][200/971]	eta 0:05:11 lr 0.000001998	time 0.3685 (0.4046)	tot_loss 0.4808 (0.4290)	mem 12194MB
Train: [6/300][250/971]	eta 0:04:47 lr 0.000001998	time 0.3586 (0.3985)	tot_loss 0.4721 (0.4292)	mem 12194MB
Train: [6/300][300/971]	eta 0:04:25 lr 0.000001998	time 0.3517 (0.3953)	tot_loss 0.4295 (0.4302)	mem 12194MB
Train: [6/300][350/971]	eta 0:04:03 lr 0.000001998	time 0.3695 (0.3928)	tot_loss 0.4369 (0.4313)	mem 12194MB
Train: [6/300][400/971]	eta 0:03:43 lr 0.000001998	time 0.3514 (0.3916)	tot_loss 0.4528 (0.4320)	mem 12194MB
Train: [6/300][450/971]	eta 0:03:23 lr 0.000001998	time 0.3651 (0.3899)	tot_loss 0.4291 (0.4324)	mem 12194MB
Train: [6/300][500/971]	eta 0:03:03 lr 0.000001998	time 0.3523 (0.3890)	tot_loss 0.4149 (0.4323)	mem 12194MB
Train: [6/300][550/971]	eta 0:02:43 lr 0.000001998	time 0.3713 (0.3885)	tot_loss 0.4284 (0.4314)	mem 12194MB
Train: [6/300][600/971]	eta 0:02:23 lr 0.000001998	time 0.3481 (0.3877)	tot_loss 0.4353 (0.4311)	mem 12194MB
Train: [6/300][650/971]	eta 0:02:04 lr 0.000001998	time 0.3570 (0.3871)	tot_loss 0.4381 (0.4311)	mem 12194MB
Train: [6/300][700/971]	eta 0:01:44 lr 0.000001998	time 0.3495 (0.3862)	tot_loss 0.4345 (0.4312)	mem 12194MB
Train: [6/300][750/971]	eta 0:01:25 lr 0.000001998	time 0.3607 (0.3854)	tot_loss 0.4655 (0.4306)	mem 12194MB
Train: [6/300][800/971]	eta 0:01:05 lr 0.000001997	time 0.3873 (0.3851)	tot_loss 0.4469 (0.4305)	mem 12194MB
Train: [6/300][850/971]	eta 0:00:46 lr 0.000001997	time 0.3602 (0.3849)	tot_loss 0.4461 (0.4302)	mem 12194MB
Train: [6/300][900/971]	eta 0:00:27 lr 0.000001997	time 0.3857 (0.3847)	tot_loss 0.4580 (0.4304)	mem 12194MB
Train: [6/300][950/971]	eta 0:00:08 lr 0.000001997	time 0.3401 (0.3840)	tot_loss 0.4387 (0.4304)	mem 12194MB
EPOCH 6 training takes 0:06:12
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 46.078	
Test: [100/3923]	Acc@1: 43.069	
Test: [150/3923]	Acc@1: 42.053	
Test: [200/3923]	Acc@1: 42.537	
Test: [250/3923]	Acc@1: 43.625	
Test: [300/3923]	Acc@1: 43.355	
Test: [350/3923]	Acc@1: 44.587	
Test: [400/3923]	Acc@1: 44.389	
Test: [450/3923]	Acc@1: 44.457	
Test: [500/3923]	Acc@1: 43.713	
Test: [550/3923]	Acc@1: 43.194	
Test: [600/3923]	Acc@1: 42.928	
Test: [650/3923]	Acc@1: 42.780	
Test: [700/3923]	Acc@1: 42.725	
Test: [750/3923]	Acc@1: 42.743	
Test: [800/3923]	Acc@1: 43.321	
Test: [850/3923]	Acc@1: 43.713	
Test: [900/3923]	Acc@1: 43.396	
Test: [950/3923]	Acc@1: 43.165	
Test: [1000/3923]	Acc@1: 43.257	
Test: [1050/3923]	Acc@1: 43.435	
Test: [1100/3923]	Acc@1: 43.370	
Test: [1150/3923]	Acc@1: 43.397	
Test: [1200/3923]	Acc@1: 43.505	
Test: [1250/3923]	Acc@1: 43.365	
Test: [1300/3923]	Acc@1: 43.582	
Test: [1350/3923]	Acc@1: 43.634	
Test: [1400/3923]	Acc@1: 43.469	
Test: [1450/3923]	Acc@1: 43.901	
Test: [1500/3923]	Acc@1: 43.804	
Test: [1550/3923]	Acc@1: 43.907	
Test: [1600/3923]	Acc@1: 43.973	
Test: [1650/3923]	Acc@1: 43.882	
Test: [1700/3923]	Acc@1: 43.886	
Test: [1750/3923]	Acc@1: 44.032	
Test: [1800/3923]	Acc@1: 44.059	
Test: [1850/3923]	Acc@1: 43.652	
Test: [1900/3923]	Acc@1: 43.661	
Test: [1950/3923]	Acc@1: 43.439	
Test: [2000/3923]	Acc@1: 43.303	
Test: [2050/3923]	Acc@1: 43.296	
Test: [2100/3923]	Acc@1: 43.408	
Test: [2150/3923]	Acc@1: 43.375	
Test: [2200/3923]	Acc@1: 43.412	
Test: [2250/3923]	Acc@1: 43.381	
Test: [2300/3923]	Acc@1: 43.503	
Test: [2350/3923]	Acc@1: 43.492	
Test: [2400/3923]	Acc@1: 43.669	
Test: [2450/3923]	Acc@1: 43.656	
Test: [2500/3923]	Acc@1: 43.743	
Test: [2550/3923]	Acc@1: 43.865	
Test: [2600/3923]	Acc@1: 44.022	
Test: [2650/3923]	Acc@1: 44.002	
Test: [2700/3923]	Acc@1: 44.002	
Test: [2750/3923]	Acc@1: 44.020	
Test: [2800/3923]	Acc@1: 43.913	
Test: [2850/3923]	Acc@1: 43.792	
Test: [2900/3923]	Acc@1: 43.657	
Test: [2950/3923]	Acc@1: 43.697	
Test: [3000/3923]	Acc@1: 43.802	
Test: [3050/3923]	Acc@1: 43.838	
Test: [3100/3923]	Acc@1: 43.857	
Test: [3150/3923]	Acc@1: 43.907	
Test: [3200/3923]	Acc@1: 43.955	
Test: [3250/3923]	Acc@1: 43.925	
Test: [3300/3923]	Acc@1: 43.987	
Test: [3350/3923]	Acc@1: 44.047	
Test: [3400/3923]	Acc@1: 44.149	
Test: [3450/3923]	Acc@1: 44.190	
Test: [3500/3923]	Acc@1: 44.187	
Test: [3550/3923]	Acc@1: 44.269	
Test: [3600/3923]	Acc@1: 44.265	
Test: [3650/3923]	Acc@1: 44.234	
Test: [3700/3923]	Acc@1: 43.961	
Test: [3750/3923]	Acc@1: 43.975	
Test: [3800/3923]	Acc@1: 43.962	
Test: [3850/3923]	Acc@1: 43.963	
Test: [3900/3923]	Acc@1: 44.040	
 * Acc@1 43.971 Acc@5 92.773 UAR 31.772Accuracy of the network on the 7847 test videos: 44.0%
Max accuracy: 43.97%, Current UAR : 31.77%, Max UAR :31.77%Train: [7/300][0/971]	eta 1:13:22 lr 0.000001997	time 4.5339 (4.5339)	tot_loss 0.4306 (0.4306)	mem 12194MB
Train: [7/300][50/971]	eta 0:07:04 lr 0.000001997	time 0.3524 (0.4613)	tot_loss 0.4095 (0.4235)	mem 12194MB
Train: [7/300][100/971]	eta 0:06:06 lr 0.000001997	time 0.3503 (0.4208)	tot_loss 0.4532 (0.4277)	mem 12194MB
Train: [7/300][150/971]	eta 0:05:33 lr 0.000001997	time 0.3607 (0.4065)	tot_loss 0.4257 (0.4274)	mem 12194MB
Train: [7/300][200/971]	eta 0:05:08 lr 0.000001997	time 0.3549 (0.3995)	tot_loss 0.4220 (0.4261)	mem 12194MB
Train: [7/300][250/971]	eta 0:04:44 lr 0.000001997	time 0.3576 (0.3946)	tot_loss 0.4006 (0.4249)	mem 12194MB
Train: [7/300][300/971]	eta 0:04:23 lr 0.000001997	time 0.3631 (0.3922)	tot_loss 0.4013 (0.4254)	mem 12194MB
Train: [7/300][350/971]	eta 0:04:01 lr 0.000001997	time 0.3558 (0.3892)	tot_loss 0.4502 (0.4260)	mem 12194MB
Train: [7/300][400/971]	eta 0:03:41 lr 0.000001997	time 0.3599 (0.3886)	tot_loss 0.4213 (0.4260)	mem 12194MB
Train: [7/300][450/971]	eta 0:03:21 lr 0.000001997	time 0.3596 (0.3874)	tot_loss 0.4196 (0.4265)	mem 12194MB
Train: [7/300][500/971]	eta 0:03:02 lr 0.000001997	time 0.3559 (0.3867)	tot_loss 0.4333 (0.4266)	mem 12194MB
Train: [7/300][550/971]	eta 0:02:42 lr 0.000001997	time 0.3522 (0.3854)	tot_loss 0.4541 (0.4267)	mem 12194MB
Train: [7/300][600/971]	eta 0:02:22 lr 0.000001997	time 0.4793 (0.3845)	tot_loss 0.4430 (0.4271)	mem 12194MB
Train: [7/300][650/971]	eta 0:02:03 lr 0.000001997	time 0.3570 (0.3840)	tot_loss 0.4630 (0.4274)	mem 12194MB
Train: [7/300][700/971]	eta 0:01:43 lr 0.000001997	time 0.3539 (0.3836)	tot_loss 0.4355 (0.4271)	mem 12194MB
Train: [7/300][750/971]	eta 0:01:24 lr 0.000001997	time 0.3514 (0.3828)	tot_loss 0.4471 (0.4274)	mem 12194MB
Train: [7/300][800/971]	eta 0:01:05 lr 0.000001997	time 0.3910 (0.3827)	tot_loss 0.4510 (0.4274)	mem 12194MB
Train: [7/300][850/971]	eta 0:00:46 lr 0.000001997	time 0.3605 (0.3820)	tot_loss 0.4309 (0.4273)	mem 12194MB
Train: [7/300][900/971]	eta 0:00:27 lr 0.000001997	time 0.3522 (0.3814)	tot_loss 0.4275 (0.4271)	mem 12194MB
Train: [7/300][950/971]	eta 0:00:07 lr 0.000001997	time 0.3474 (0.3809)	tot_loss 0.4223 (0.4273)	mem 12194MB
EPOCH 7 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 37.255	
Test: [100/3923]	Acc@1: 38.614	
Test: [150/3923]	Acc@1: 40.066	
Test: [200/3923]	Acc@1: 39.055	
Test: [250/3923]	Acc@1: 41.235	
Test: [300/3923]	Acc@1: 40.033	
Test: [350/3923]	Acc@1: 40.171	
Test: [400/3923]	Acc@1: 40.150	
Test: [450/3923]	Acc@1: 40.687	
Test: [500/3923]	Acc@1: 40.220	
Test: [550/3923]	Acc@1: 40.381	
Test: [600/3923]	Acc@1: 40.349	
Test: [650/3923]	Acc@1: 40.323	
Test: [700/3923]	Acc@1: 39.872	
Test: [750/3923]	Acc@1: 39.680	
Test: [800/3923]	Acc@1: 39.201	
Test: [850/3923]	Acc@1: 39.365	
Test: [900/3923]	Acc@1: 39.734	
Test: [950/3923]	Acc@1: 39.800	
Test: [1000/3923]	Acc@1: 39.810	
Test: [1050/3923]	Acc@1: 39.962	
Test: [1100/3923]	Acc@1: 40.145	
Test: [1150/3923]	Acc@1: 40.313	
Test: [1200/3923]	Acc@1: 40.300	
Test: [1250/3923]	Acc@1: 40.408	
Test: [1300/3923]	Acc@1: 40.507	
Test: [1350/3923]	Acc@1: 40.489	
Test: [1400/3923]	Acc@1: 40.685	
Test: [1450/3923]	Acc@1: 40.937	
Test: [1500/3923]	Acc@1: 40.906	
Test: [1550/3923]	Acc@1: 40.909	
Test: [1600/3923]	Acc@1: 41.193	
Test: [1650/3923]	Acc@1: 41.217	
Test: [1700/3923]	Acc@1: 41.387	
Test: [1750/3923]	Acc@1: 41.291	
Test: [1800/3923]	Acc@1: 41.366	
Test: [1850/3923]	Acc@1: 41.437	
Test: [1900/3923]	Acc@1: 41.347	
Test: [1950/3923]	Acc@1: 41.261	
Test: [2000/3923]	Acc@1: 41.254	
Test: [2050/3923]	Acc@1: 41.370	
Test: [2100/3923]	Acc@1: 41.290	
Test: [2150/3923]	Acc@1: 41.330	
Test: [2200/3923]	Acc@1: 41.345	
Test: [2250/3923]	Acc@1: 41.315	
Test: [2300/3923]	Acc@1: 41.352	
Test: [2350/3923]	Acc@1: 41.365	
Test: [2400/3923]	Acc@1: 41.420	
Test: [2450/3923]	Acc@1: 41.514	
Test: [2500/3923]	Acc@1: 41.663	
Test: [2550/3923]	Acc@1: 41.729	
Test: [2600/3923]	Acc@1: 41.734	
Test: [2650/3923]	Acc@1: 41.890	
Test: [2700/3923]	Acc@1: 41.910	
Test: [2750/3923]	Acc@1: 41.894	
Test: [2800/3923]	Acc@1: 41.878	
Test: [2850/3923]	Acc@1: 42.020	
Test: [2900/3923]	Acc@1: 41.934	
Test: [2950/3923]	Acc@1: 42.003	
Test: [3000/3923]	Acc@1: 42.153	
Test: [3050/3923]	Acc@1: 42.183	
Test: [3100/3923]	Acc@1: 42.244	
Test: [3150/3923]	Acc@1: 42.415	
Test: [3200/3923]	Acc@1: 42.534	
Test: [3250/3923]	Acc@1: 42.510	
Test: [3300/3923]	Acc@1: 42.472	
Test: [3350/3923]	Acc@1: 42.480	
Test: [3400/3923]	Acc@1: 42.414	
Test: [3450/3923]	Acc@1: 42.394	
Test: [3500/3923]	Acc@1: 42.388	
Test: [3550/3923]	Acc@1: 42.397	
Test: [3600/3923]	Acc@1: 42.488	
Test: [3650/3923]	Acc@1: 42.591	
Test: [3700/3923]	Acc@1: 42.516	
Test: [3750/3923]	Acc@1: 42.549	
Test: [3800/3923]	Acc@1: 42.568	
Test: [3850/3923]	Acc@1: 42.625	
Test: [3900/3923]	Acc@1: 42.617	
 * Acc@1 42.595 Acc@5 93.602 UAR 31.230Accuracy of the network on the 7847 test videos: 42.6%
Max accuracy: 43.97%, Current UAR : 31.77%, Max UAR :31.77%Train: [8/300][0/971]	eta 1:20:05 lr 0.000001997	time 4.9493 (4.9493)	tot_loss 0.4114 (0.4114)	mem 12194MB
Train: [8/300][50/971]	eta 0:07:08 lr 0.000001996	time 0.3645 (0.4652)	tot_loss 0.3759 (0.4284)	mem 12194MB
Train: [8/300][100/971]	eta 0:06:06 lr 0.000001996	time 0.3559 (0.4210)	tot_loss 0.4625 (0.4267)	mem 12194MB
Train: [8/300][150/971]	eta 0:05:33 lr 0.000001996	time 0.3499 (0.4066)	tot_loss 0.4269 (0.4263)	mem 12194MB
Train: [8/300][200/971]	eta 0:05:08 lr 0.000001996	time 0.3508 (0.4007)	tot_loss 0.3895 (0.4252)	mem 12194MB
Train: [8/300][250/971]	eta 0:04:45 lr 0.000001996	time 0.3495 (0.3955)	tot_loss 0.4475 (0.4248)	mem 12194MB
Train: [8/300][300/971]	eta 0:04:22 lr 0.000001996	time 0.3920 (0.3918)	tot_loss 0.4442 (0.4246)	mem 12194MB
Train: [8/300][350/971]	eta 0:04:01 lr 0.000001996	time 0.3587 (0.3886)	tot_loss 0.4110 (0.4248)	mem 12194MB
Train: [8/300][400/971]	eta 0:03:40 lr 0.000001996	time 0.3580 (0.3868)	tot_loss 0.4400 (0.4247)	mem 12194MB
Train: [8/300][450/971]	eta 0:03:20 lr 0.000001996	time 0.3525 (0.3853)	tot_loss 0.4369 (0.4250)	mem 12194MB
Train: [8/300][500/971]	eta 0:03:01 lr 0.000001996	time 0.3571 (0.3848)	tot_loss 0.4363 (0.4251)	mem 12194MB
Train: [8/300][550/971]	eta 0:02:41 lr 0.000001996	time 0.3472 (0.3837)	tot_loss 0.4178 (0.4249)	mem 12194MB
Train: [8/300][600/971]	eta 0:02:22 lr 0.000001996	time 0.3552 (0.3837)	tot_loss 0.4260 (0.4248)	mem 12194MB
Train: [8/300][650/971]	eta 0:02:02 lr 0.000001996	time 0.3582 (0.3828)	tot_loss 0.4272 (0.4249)	mem 12194MB
Train: [8/300][700/971]	eta 0:01:43 lr 0.000001996	time 0.3467 (0.3821)	tot_loss 0.3988 (0.4252)	mem 12194MB
Train: [8/300][750/971]	eta 0:01:24 lr 0.000001996	time 0.4904 (0.3817)	tot_loss 0.4069 (0.4247)	mem 12194MB
Train: [8/300][800/971]	eta 0:01:05 lr 0.000001996	time 0.3683 (0.3811)	tot_loss 0.4206 (0.4246)	mem 12194MB
Train: [8/300][850/971]	eta 0:00:45 lr 0.000001996	time 0.3460 (0.3802)	tot_loss 0.4151 (0.4250)	mem 12194MB
Train: [8/300][900/971]	eta 0:00:26 lr 0.000001996	time 0.3479 (0.3796)	tot_loss 0.4605 (0.4252)	mem 12194MB
Train: [8/300][950/971]	eta 0:00:07 lr 0.000001996	time 0.3399 (0.3793)	tot_loss 0.4171 (0.4251)	mem 12194MB
EPOCH 8 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 44.059	
Test: [150/3923]	Acc@1: 45.695	
Test: [200/3923]	Acc@1: 45.025	
Test: [250/3923]	Acc@1: 46.215	
Test: [300/3923]	Acc@1: 45.515	
Test: [350/3923]	Acc@1: 45.299	
Test: [400/3923]	Acc@1: 46.384	
Test: [450/3923]	Acc@1: 46.452	
Test: [500/3923]	Acc@1: 46.607	
Test: [550/3923]	Acc@1: 46.461	
Test: [600/3923]	Acc@1: 46.339	
Test: [650/3923]	Acc@1: 45.853	
Test: [700/3923]	Acc@1: 45.863	
Test: [750/3923]	Acc@1: 45.606	
Test: [800/3923]	Acc@1: 45.568	
Test: [850/3923]	Acc@1: 45.476	
Test: [900/3923]	Acc@1: 45.172	
Test: [950/3923]	Acc@1: 45.268	
Test: [1000/3923]	Acc@1: 45.055	
Test: [1050/3923]	Acc@1: 44.672	
Test: [1100/3923]	Acc@1: 44.641	
Test: [1150/3923]	Acc@1: 44.570	
Test: [1200/3923]	Acc@1: 44.588	
Test: [1250/3923]	Acc@1: 44.404	
Test: [1300/3923]	Acc@1: 44.620	
Test: [1350/3923]	Acc@1: 44.745	
Test: [1400/3923]	Acc@1: 44.647	
Test: [1450/3923]	Acc@1: 44.590	
Test: [1500/3923]	Acc@1: 44.737	
Test: [1550/3923]	Acc@1: 44.649	
Test: [1600/3923]	Acc@1: 44.503	
Test: [1650/3923]	Acc@1: 44.397	
Test: [1700/3923]	Acc@1: 44.386	
Test: [1750/3923]	Acc@1: 44.375	
Test: [1800/3923]	Acc@1: 44.420	
Test: [1850/3923]	Acc@1: 44.516	
Test: [1900/3923]	Acc@1: 44.424	
Test: [1950/3923]	Acc@1: 44.464	
Test: [2000/3923]	Acc@1: 44.403	
Test: [2050/3923]	Acc@1: 44.515	
Test: [2100/3923]	Acc@1: 44.336	
Test: [2150/3923]	Acc@1: 44.491	
Test: [2200/3923]	Acc@1: 44.298	
Test: [2250/3923]	Acc@1: 44.358	
Test: [2300/3923]	Acc@1: 44.307	
Test: [2350/3923]	Acc@1: 44.215	
Test: [2400/3923]	Acc@1: 44.315	
Test: [2450/3923]	Acc@1: 44.370	
Test: [2500/3923]	Acc@1: 44.462	
Test: [2550/3923]	Acc@1: 44.551	
Test: [2600/3923]	Acc@1: 44.675	
Test: [2650/3923]	Acc@1: 44.625	
Test: [2700/3923]	Acc@1: 44.558	
Test: [2750/3923]	Acc@1: 44.457	
Test: [2800/3923]	Acc@1: 44.484	
Test: [2850/3923]	Acc@1: 44.476	
Test: [2900/3923]	Acc@1: 44.450	
Test: [2950/3923]	Acc@1: 44.561	
Test: [3000/3923]	Acc@1: 44.485	
Test: [3050/3923]	Acc@1: 44.510	
Test: [3100/3923]	Acc@1: 44.421	
Test: [3150/3923]	Acc@1: 44.541	
Test: [3200/3923]	Acc@1: 44.517	
Test: [3250/3923]	Acc@1: 44.540	
Test: [3300/3923]	Acc@1: 44.608	
Test: [3350/3923]	Acc@1: 44.509	
Test: [3400/3923]	Acc@1: 44.502	
Test: [3450/3923]	Acc@1: 44.509	
Test: [3500/3923]	Acc@1: 44.530	
Test: [3550/3923]	Acc@1: 44.495	
Test: [3600/3923]	Acc@1: 44.460	
Test: [3650/3923]	Acc@1: 44.412	
Test: [3700/3923]	Acc@1: 44.420	
Test: [3750/3923]	Acc@1: 44.481	
Test: [3800/3923]	Acc@1: 44.501	
Test: [3850/3923]	Acc@1: 44.495	
Test: [3900/3923]	Acc@1: 44.463	
 * Acc@1 44.405 Acc@5 93.717 UAR 33.275Accuracy of the network on the 7847 test videos: 44.4%
Max accuracy: 44.40%, Current UAR : 33.28%, Max UAR :33.28%Train: [9/300][0/971]	eta 1:22:12 lr 0.000001996	time 5.0797 (5.0797)	tot_loss 0.3797 (0.3797)	mem 12194MB
Train: [9/300][50/971]	eta 0:07:18 lr 0.000001996	time 0.3594 (0.4761)	tot_loss 0.4227 (0.4216)	mem 12194MB
Train: [9/300][100/971]	eta 0:06:11 lr 0.000001996	time 0.3541 (0.4264)	tot_loss 0.4528 (0.4238)	mem 12194MB
Train: [9/300][150/971]	eta 0:05:35 lr 0.000001995	time 0.3473 (0.4087)	tot_loss 0.3971 (0.4246)	mem 12194MB
Train: [9/300][200/971]	eta 0:05:09 lr 0.000001995	time 0.3440 (0.4009)	tot_loss 0.4574 (0.4240)	mem 12194MB
Train: [9/300][250/971]	eta 0:04:45 lr 0.000001995	time 0.3719 (0.3953)	tot_loss 0.4285 (0.4238)	mem 12194MB
Train: [9/300][300/971]	eta 0:04:22 lr 0.000001995	time 0.3479 (0.3910)	tot_loss 0.4210 (0.4241)	mem 12194MB
Train: [9/300][350/971]	eta 0:04:01 lr 0.000001995	time 0.3620 (0.3883)	tot_loss 0.4168 (0.4237)	mem 12194MB
Train: [9/300][400/971]	eta 0:03:41 lr 0.000001995	time 0.3510 (0.3872)	tot_loss 0.4199 (0.4226)	mem 12194MB
Train: [9/300][450/971]	eta 0:03:20 lr 0.000001995	time 0.3476 (0.3856)	tot_loss 0.4444 (0.4229)	mem 12194MB
Train: [9/300][500/971]	eta 0:03:00 lr 0.000001995	time 0.3504 (0.3840)	tot_loss 0.4326 (0.4230)	mem 12194MB
Train: [9/300][550/971]	eta 0:02:41 lr 0.000001995	time 0.3447 (0.3825)	tot_loss 0.4029 (0.4230)	mem 12194MB
Train: [9/300][600/971]	eta 0:02:21 lr 0.000001995	time 0.3453 (0.3810)	tot_loss 0.4456 (0.4228)	mem 12194MB
Train: [9/300][650/971]	eta 0:02:02 lr 0.000001995	time 0.3590 (0.3802)	tot_loss 0.4484 (0.4228)	mem 12194MB
Train: [9/300][700/971]	eta 0:01:42 lr 0.000001995	time 0.3436 (0.3797)	tot_loss 0.3633 (0.4233)	mem 12194MB
Train: [9/300][750/971]	eta 0:01:23 lr 0.000001995	time 0.3563 (0.3793)	tot_loss 0.4052 (0.4235)	mem 12194MB
Train: [9/300][800/971]	eta 0:01:04 lr 0.000001995	time 0.3541 (0.3786)	tot_loss 0.4629 (0.4238)	mem 12194MB
Train: [9/300][850/971]	eta 0:00:45 lr 0.000001995	time 0.3566 (0.3783)	tot_loss 0.3652 (0.4240)	mem 12194MB
Train: [9/300][900/971]	eta 0:00:26 lr 0.000001995	time 0.3463 (0.3781)	tot_loss 0.4606 (0.4240)	mem 12194MB
Train: [9/300][950/971]	eta 0:00:07 lr 0.000001995	time 0.3409 (0.3775)	tot_loss 0.4241 (0.4241)	mem 12194MB
EPOCH 9 training takes 0:06:06
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 41.176	
Test: [100/3923]	Acc@1: 45.050	
Test: [150/3923]	Acc@1: 44.040	
Test: [200/3923]	Acc@1: 45.522	
Test: [250/3923]	Acc@1: 46.215	
Test: [300/3923]	Acc@1: 45.847	
Test: [350/3923]	Acc@1: 44.729	
Test: [400/3923]	Acc@1: 45.262	
Test: [450/3923]	Acc@1: 46.231	
Test: [500/3923]	Acc@1: 46.607	
Test: [550/3923]	Acc@1: 46.733	
Test: [600/3923]	Acc@1: 46.256	
Test: [650/3923]	Acc@1: 45.853	
Test: [700/3923]	Acc@1: 45.578	
Test: [750/3923]	Acc@1: 45.340	
Test: [800/3923]	Acc@1: 45.318	
Test: [850/3923]	Acc@1: 45.593	
Test: [900/3923]	Acc@1: 45.228	
Test: [950/3923]	Acc@1: 44.953	
Test: [1000/3923]	Acc@1: 45.305	
Test: [1050/3923]	Acc@1: 45.623	
Test: [1100/3923]	Acc@1: 46.140	
Test: [1150/3923]	Acc@1: 46.742	
Test: [1200/3923]	Acc@1: 46.711	
Test: [1250/3923]	Acc@1: 47.122	
Test: [1300/3923]	Acc@1: 47.118	
Test: [1350/3923]	Acc@1: 47.002	
Test: [1400/3923]	Acc@1: 47.002	
Test: [1450/3923]	Acc@1: 47.174	
Test: [1500/3923]	Acc@1: 47.202	
Test: [1550/3923]	Acc@1: 47.066	
Test: [1600/3923]	Acc@1: 47.096	
Test: [1650/3923]	Acc@1: 46.972	
Test: [1700/3923]	Acc@1: 46.825	
Test: [1750/3923]	Acc@1: 46.745	
Test: [1800/3923]	Acc@1: 46.835	
Test: [1850/3923]	Acc@1: 46.759	
Test: [1900/3923]	Acc@1: 46.712	
Test: [1950/3923]	Acc@1: 46.668	
Test: [2000/3923]	Acc@1: 46.577	
Test: [2050/3923]	Acc@1: 46.416	
Test: [2100/3923]	Acc@1: 46.549	
Test: [2150/3923]	Acc@1: 46.583	
Test: [2200/3923]	Acc@1: 46.502	
Test: [2250/3923]	Acc@1: 46.202	
Test: [2300/3923]	Acc@1: 45.980	
Test: [2350/3923]	Acc@1: 45.980	
Test: [2400/3923]	Acc@1: 45.981	
Test: [2450/3923]	Acc@1: 46.022	
Test: [2500/3923]	Acc@1: 45.822	
Test: [2550/3923]	Acc@1: 45.766	
Test: [2600/3923]	Acc@1: 45.905	
Test: [2650/3923]	Acc@1: 45.983	
Test: [2700/3923]	Acc@1: 45.946	
Test: [2750/3923]	Acc@1: 45.929	
Test: [2800/3923]	Acc@1: 45.912	
Test: [2850/3923]	Acc@1: 45.668	
Test: [2900/3923]	Acc@1: 45.570	
Test: [2950/3923]	Acc@1: 45.595	
Test: [3000/3923]	Acc@1: 45.768	
Test: [3050/3923]	Acc@1: 45.641	
Test: [3100/3923]	Acc@1: 45.679	
Test: [3150/3923]	Acc@1: 45.684	
Test: [3200/3923]	Acc@1: 45.564	
Test: [3250/3923]	Acc@1: 45.386	
Test: [3300/3923]	Acc@1: 45.426	
Test: [3350/3923]	Acc@1: 45.389	
Test: [3400/3923]	Acc@1: 45.384	
Test: [3450/3923]	Acc@1: 45.320	
Test: [3500/3923]	Acc@1: 45.244	
Test: [3550/3923]	Acc@1: 45.269	
Test: [3600/3923]	Acc@1: 45.362	
Test: [3650/3923]	Acc@1: 45.330	
Test: [3700/3923]	Acc@1: 45.326	
Test: [3750/3923]	Acc@1: 45.295	
Test: [3800/3923]	Acc@1: 45.251	
Test: [3850/3923]	Acc@1: 45.209	
Test: [3900/3923]	Acc@1: 45.206	
 * Acc@1 45.208 Acc@5 92.914 UAR 33.542Accuracy of the network on the 7847 test videos: 45.2%
Max accuracy: 45.21%, Current UAR : 33.54%, Max UAR :33.54%Train: [10/300][0/971]	eta 1:17:02 lr 0.000001995	time 4.7610 (4.7610)	tot_loss 0.4142 (0.4142)	mem 12194MB
Train: [10/300][50/971]	eta 0:07:18 lr 0.000001995	time 0.3699 (0.4763)	tot_loss 0.4422 (0.4279)	mem 12194MB
Train: [10/300][100/971]	eta 0:06:11 lr 0.000001994	time 0.3619 (0.4270)	tot_loss 0.4118 (0.4247)	mem 12194MB
Train: [10/300][150/971]	eta 0:05:37 lr 0.000001994	time 0.3633 (0.4114)	tot_loss 0.4337 (0.4228)	mem 12194MB
Train: [10/300][200/971]	eta 0:05:11 lr 0.000001994	time 0.3588 (0.4041)	tot_loss 0.4010 (0.4247)	mem 12194MB
Train: [10/300][250/971]	eta 0:04:47 lr 0.000001994	time 0.3591 (0.3983)	tot_loss 0.4064 (0.4256)	mem 12194MB
Train: [10/300][300/971]	eta 0:04:24 lr 0.000001994	time 0.3574 (0.3945)	tot_loss 0.3887 (0.4257)	mem 12194MB
Train: [10/300][350/971]	eta 0:04:03 lr 0.000001994	time 0.3501 (0.3918)	tot_loss 0.4258 (0.4257)	mem 12194MB
Train: [10/300][400/971]	eta 0:03:42 lr 0.000001994	time 0.3545 (0.3893)	tot_loss 0.4177 (0.4255)	mem 12194MB
Train: [10/300][450/971]	eta 0:03:21 lr 0.000001994	time 0.3526 (0.3873)	tot_loss 0.4129 (0.4258)	mem 12194MB
Train: [10/300][500/971]	eta 0:03:01 lr 0.000001994	time 0.3706 (0.3864)	tot_loss 0.4495 (0.4245)	mem 12194MB
Train: [10/300][550/971]	eta 0:02:42 lr 0.000001994	time 0.3569 (0.3855)	tot_loss 0.4441 (0.4242)	mem 12194MB
Train: [10/300][600/971]	eta 0:02:22 lr 0.000001994	time 0.3573 (0.3850)	tot_loss 0.4405 (0.4241)	mem 12194MB
Train: [10/300][650/971]	eta 0:02:03 lr 0.000001994	time 0.3486 (0.3842)	tot_loss 0.4543 (0.4233)	mem 12194MB
Train: [10/300][700/971]	eta 0:01:44 lr 0.000001994	time 0.3635 (0.3841)	tot_loss 0.4095 (0.4232)	mem 12194MB
Train: [10/300][750/971]	eta 0:01:24 lr 0.000001994	time 0.3629 (0.3836)	tot_loss 0.3846 (0.4225)	mem 12194MB
Train: [10/300][800/971]	eta 0:01:05 lr 0.000001994	time 0.3567 (0.3829)	tot_loss 0.4448 (0.4224)	mem 12194MB
Train: [10/300][850/971]	eta 0:00:46 lr 0.000001994	time 0.3463 (0.3828)	tot_loss 0.3827 (0.4222)	mem 12194MB
Train: [10/300][900/971]	eta 0:00:27 lr 0.000001994	time 0.3539 (0.3823)	tot_loss 0.3932 (0.4219)	mem 12194MB
Train: [10/300][950/971]	eta 0:00:08 lr 0.000001993	time 0.3710 (0.3819)	tot_loss 0.4393 (0.4218)	mem 12194MB
EPOCH 10 training takes 0:06:10
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 42.157	
Test: [100/3923]	Acc@1: 44.059	
Test: [150/3923]	Acc@1: 45.364	
Test: [200/3923]	Acc@1: 46.020	
Test: [250/3923]	Acc@1: 46.215	
Test: [300/3923]	Acc@1: 45.515	
Test: [350/3923]	Acc@1: 45.299	
Test: [400/3923]	Acc@1: 46.259	
Test: [450/3923]	Acc@1: 46.563	
Test: [500/3923]	Acc@1: 45.908	
Test: [550/3923]	Acc@1: 46.733	
Test: [600/3923]	Acc@1: 46.672	
Test: [650/3923]	Acc@1: 46.237	
Test: [700/3923]	Acc@1: 46.505	
Test: [750/3923]	Acc@1: 46.804	
Test: [800/3923]	Acc@1: 46.005	
Test: [850/3923]	Acc@1: 46.240	
Test: [900/3923]	Acc@1: 45.949	
Test: [950/3923]	Acc@1: 46.057	
Test: [1000/3923]	Acc@1: 45.904	
Test: [1050/3923]	Acc@1: 46.051	
Test: [1100/3923]	Acc@1: 45.822	
Test: [1150/3923]	Acc@1: 45.873	
Test: [1200/3923]	Acc@1: 45.712	
Test: [1250/3923]	Acc@1: 45.364	
Test: [1300/3923]	Acc@1: 45.580	
Test: [1350/3923]	Acc@1: 45.670	
Test: [1400/3923]	Acc@1: 45.610	
Test: [1450/3923]	Acc@1: 45.451	
Test: [1500/3923]	Acc@1: 45.503	
Test: [1550/3923]	Acc@1: 45.229	
Test: [1600/3923]	Acc@1: 44.909	
Test: [1650/3923]	Acc@1: 44.973	
Test: [1700/3923]	Acc@1: 44.827	
Test: [1750/3923]	Acc@1: 44.746	
Test: [1800/3923]	Acc@1: 44.670	
Test: [1850/3923]	Acc@1: 44.733	
Test: [1900/3923]	Acc@1: 44.871	
Test: [1950/3923]	Acc@1: 44.951	
Test: [2000/3923]	Acc@1: 45.002	
Test: [2050/3923]	Acc@1: 45.197	
Test: [2100/3923]	Acc@1: 45.050	
Test: [2150/3923]	Acc@1: 44.933	
Test: [2200/3923]	Acc@1: 44.980	
Test: [2250/3923]	Acc@1: 45.269	
Test: [2300/3923]	Acc@1: 45.263	
Test: [2350/3923]	Acc@1: 45.491	
Test: [2400/3923]	Acc@1: 45.419	
Test: [2450/3923]	Acc@1: 45.349	
Test: [2500/3923]	Acc@1: 45.262	
Test: [2550/3923]	Acc@1: 45.100	
Test: [2600/3923]	Acc@1: 45.194	
Test: [2650/3923]	Acc@1: 45.341	
Test: [2700/3923]	Acc@1: 45.298	
Test: [2750/3923]	Acc@1: 45.220	
Test: [2800/3923]	Acc@1: 45.216	
Test: [2850/3923]	Acc@1: 45.247	
Test: [2900/3923]	Acc@1: 45.312	
Test: [2950/3923]	Acc@1: 45.358	
Test: [3000/3923]	Acc@1: 45.402	
Test: [3050/3923]	Acc@1: 45.428	
Test: [3100/3923]	Acc@1: 45.550	
Test: [3150/3923]	Acc@1: 45.509	
Test: [3200/3923]	Acc@1: 45.470	
Test: [3250/3923]	Acc@1: 45.432	
Test: [3300/3923]	Acc@1: 45.486	
Test: [3350/3923]	Acc@1: 45.434	
Test: [3400/3923]	Acc@1: 45.531	
Test: [3450/3923]	Acc@1: 45.668	
Test: [3500/3923]	Acc@1: 45.601	
Test: [3550/3923]	Acc@1: 45.705	
Test: [3600/3923]	Acc@1: 45.585	
Test: [3650/3923]	Acc@1: 45.563	
Test: [3700/3923]	Acc@1: 45.501	
Test: [3750/3923]	Acc@1: 45.495	
Test: [3800/3923]	Acc@1: 45.475	
Test: [3850/3923]	Acc@1: 45.495	
Test: [3900/3923]	Acc@1: 45.463	
 * Acc@1 45.386 Acc@5 93.564 UAR 32.644Accuracy of the network on the 7847 test videos: 45.4%
Max accuracy: 45.39%, Current UAR : 32.64%, Max UAR :33.54%Train: [11/300][0/971]	eta 1:25:19 lr 0.000001993	time 5.2728 (5.2728)	tot_loss 0.3750 (0.3750)	mem 12194MB
Train: [11/300][50/971]	eta 0:07:07 lr 0.000001993	time 0.3538 (0.4641)	tot_loss 0.4618 (0.4249)	mem 12194MB
Train: [11/300][100/971]	eta 0:06:06 lr 0.000001993	time 0.3523 (0.4207)	tot_loss 0.4059 (0.4251)	mem 12194MB
Train: [11/300][150/971]	eta 0:05:37 lr 0.000001993	time 0.3512 (0.4114)	tot_loss 0.3651 (0.4224)	mem 12194MB
Train: [11/300][200/971]	eta 0:05:10 lr 0.000001993	time 0.3565 (0.4021)	tot_loss 0.3865 (0.4223)	mem 12194MB
Train: [11/300][250/971]	eta 0:04:45 lr 0.000001993	time 0.3587 (0.3955)	tot_loss 0.3982 (0.4209)	mem 12194MB
Train: [11/300][300/971]	eta 0:04:23 lr 0.000001993	time 0.3575 (0.3921)	tot_loss 0.4197 (0.4200)	mem 12194MB
Train: [11/300][350/971]	eta 0:04:01 lr 0.000001993	time 0.3468 (0.3887)	tot_loss 0.4743 (0.4208)	mem 12194MB
Train: [11/300][400/971]	eta 0:03:41 lr 0.000001993	time 0.3482 (0.3871)	tot_loss 0.4454 (0.4203)	mem 12194MB
Train: [11/300][450/971]	eta 0:03:21 lr 0.000001993	time 0.3553 (0.3860)	tot_loss 0.4255 (0.4202)	mem 12194MB
Train: [11/300][500/971]	eta 0:03:01 lr 0.000001993	time 0.3549 (0.3854)	tot_loss 0.4294 (0.4210)	mem 12194MB
Train: [11/300][550/971]	eta 0:02:42 lr 0.000001993	time 0.3854 (0.3855)	tot_loss 0.3994 (0.4218)	mem 12194MB
Train: [11/300][600/971]	eta 0:02:22 lr 0.000001993	time 0.3514 (0.3853)	tot_loss 0.4513 (0.4221)	mem 12194MB
Train: [11/300][650/971]	eta 0:02:03 lr 0.000001993	time 0.3935 (0.3861)	tot_loss 0.4364 (0.4219)	mem 12194MB
Train: [11/300][700/971]	eta 0:01:44 lr 0.000001993	time 0.3517 (0.3857)	tot_loss 0.4366 (0.4218)	mem 12194MB
Train: [11/300][750/971]	eta 0:01:25 lr 0.000001992	time 0.3459 (0.3858)	tot_loss 0.3981 (0.4220)	mem 12194MB
Train: [11/300][800/971]	eta 0:01:05 lr 0.000001992	time 0.3605 (0.3851)	tot_loss 0.4012 (0.4218)	mem 12194MB
Train: [11/300][850/971]	eta 0:00:46 lr 0.000001992	time 0.3621 (0.3843)	tot_loss 0.4023 (0.4218)	mem 12194MB
Train: [11/300][900/971]	eta 0:00:27 lr 0.000001992	time 0.3546 (0.3835)	tot_loss 0.4322 (0.4220)	mem 12194MB
Train: [11/300][950/971]	eta 0:00:08 lr 0.000001992	time 0.3712 (0.3831)	tot_loss 0.4586 (0.4218)	mem 12194MB
EPOCH 11 training takes 0:06:12
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 42.157	
Test: [100/3923]	Acc@1: 44.554	
Test: [150/3923]	Acc@1: 45.033	
Test: [200/3923]	Acc@1: 44.030	
Test: [250/3923]	Acc@1: 43.028	
Test: [300/3923]	Acc@1: 43.522	
Test: [350/3923]	Acc@1: 43.162	
Test: [400/3923]	Acc@1: 43.766	
Test: [450/3923]	Acc@1: 45.122	
Test: [500/3923]	Acc@1: 45.509	
Test: [550/3923]	Acc@1: 45.191	
Test: [600/3923]	Acc@1: 45.591	
Test: [650/3923]	Acc@1: 45.469	
Test: [700/3923]	Acc@1: 45.150	
Test: [750/3923]	Acc@1: 44.940	
Test: [800/3923]	Acc@1: 45.318	
Test: [850/3923]	Acc@1: 45.358	
Test: [900/3923]	Acc@1: 45.505	
Test: [950/3923]	Acc@1: 45.321	
Test: [1000/3923]	Acc@1: 45.005	
Test: [1050/3923]	Acc@1: 45.147	
Test: [1100/3923]	Acc@1: 45.050	
Test: [1150/3923]	Acc@1: 45.048	
Test: [1200/3923]	Acc@1: 45.171	
Test: [1250/3923]	Acc@1: 45.324	
Test: [1300/3923]	Acc@1: 45.465	
Test: [1350/3923]	Acc@1: 45.522	
Test: [1400/3923]	Acc@1: 45.717	
Test: [1450/3923]	Acc@1: 45.830	
Test: [1500/3923]	Acc@1: 45.803	
Test: [1550/3923]	Acc@1: 45.616	
Test: [1600/3923]	Acc@1: 45.315	
Test: [1650/3923]	Acc@1: 45.427	
Test: [1700/3923]	Acc@1: 45.356	
Test: [1750/3923]	Acc@1: 45.403	
Test: [1800/3923]	Acc@1: 45.197	
Test: [1850/3923]	Acc@1: 45.219	
Test: [1900/3923]	Acc@1: 45.318	
Test: [1950/3923]	Acc@1: 45.387	
Test: [2000/3923]	Acc@1: 45.277	
Test: [2050/3923]	Acc@1: 45.197	
Test: [2100/3923]	Acc@1: 45.359	
Test: [2150/3923]	Acc@1: 45.444	
Test: [2200/3923]	Acc@1: 45.343	
Test: [2250/3923]	Acc@1: 45.247	
Test: [2300/3923]	Acc@1: 45.089	
Test: [2350/3923]	Acc@1: 45.023	
Test: [2400/3923]	Acc@1: 44.898	
Test: [2450/3923]	Acc@1: 44.941	
Test: [2500/3923]	Acc@1: 44.862	
Test: [2550/3923]	Acc@1: 44.884	
Test: [2600/3923]	Acc@1: 44.848	
Test: [2650/3923]	Acc@1: 44.832	
Test: [2700/3923]	Acc@1: 44.872	
Test: [2750/3923]	Acc@1: 44.784	
Test: [2800/3923]	Acc@1: 44.609	
Test: [2850/3923]	Acc@1: 44.511	
Test: [2900/3923]	Acc@1: 44.554	
Test: [2950/3923]	Acc@1: 44.476	
Test: [3000/3923]	Acc@1: 44.419	
Test: [3050/3923]	Acc@1: 44.412	
Test: [3100/3923]	Acc@1: 44.308	
Test: [3150/3923]	Acc@1: 44.303	
Test: [3200/3923]	Acc@1: 44.439	
Test: [3250/3923]	Acc@1: 44.263	
Test: [3300/3923]	Acc@1: 44.184	
Test: [3350/3923]	Acc@1: 44.285	
Test: [3400/3923]	Acc@1: 44.296	
Test: [3450/3923]	Acc@1: 44.407	
Test: [3500/3923]	Acc@1: 44.459	
Test: [3550/3923]	Acc@1: 44.466	
Test: [3600/3923]	Acc@1: 44.543	
Test: [3650/3923]	Acc@1: 44.618	
Test: [3700/3923]	Acc@1: 44.623	
Test: [3750/3923]	Acc@1: 44.681	
Test: [3800/3923]	Acc@1: 44.646	
Test: [3850/3923]	Acc@1: 44.677	
Test: [3900/3923]	Acc@1: 44.771	
 * Acc@1 44.813 Acc@5 92.977 UAR 32.723Accuracy of the network on the 7847 test videos: 44.8%
Max accuracy: 45.39%, Current UAR : 32.64%, Max UAR :33.54%Train: [12/300][0/971]	eta 1:25:47 lr 0.000001992	time 5.3017 (5.3017)	tot_loss 0.4079 (0.4079)	mem 12194MB
Train: [12/300][50/971]	eta 0:07:13 lr 0.000001992	time 0.3510 (0.4705)	tot_loss 0.4477 (0.4144)	mem 12194MB
Train: [12/300][100/971]	eta 0:06:10 lr 0.000001992	time 0.3513 (0.4248)	tot_loss 0.4086 (0.4173)	mem 12194MB
Train: [12/300][150/971]	eta 0:05:36 lr 0.000001992	time 0.3639 (0.4096)	tot_loss 0.3972 (0.4162)	mem 12194MB
Train: [12/300][200/971]	eta 0:05:09 lr 0.000001992	time 0.3520 (0.4019)	tot_loss 0.4562 (0.4155)	mem 12194MB
Train: [12/300][250/971]	eta 0:04:45 lr 0.000001992	time 0.3636 (0.3955)	tot_loss 0.4118 (0.4166)	mem 12194MB
Train: [12/300][300/971]	eta 0:04:23 lr 0.000001992	time 0.3872 (0.3933)	tot_loss 0.3752 (0.4163)	mem 12194MB
Train: [12/300][350/971]	eta 0:04:02 lr 0.000001992	time 0.3511 (0.3906)	tot_loss 0.4304 (0.4176)	mem 12194MB
Train: [12/300][400/971]	eta 0:03:42 lr 0.000001992	time 0.3812 (0.3895)	tot_loss 0.4133 (0.4175)	mem 12194MB
Train: [12/300][450/971]	eta 0:03:22 lr 0.000001992	time 0.3563 (0.3879)	tot_loss 0.4501 (0.4184)	mem 12194MB
Train: [12/300][500/971]	eta 0:03:02 lr 0.000001992	time 0.3448 (0.3868)	tot_loss 0.4545 (0.4186)	mem 12194MB
Train: [12/300][550/971]	eta 0:02:42 lr 0.000001991	time 0.3605 (0.3861)	tot_loss 0.4119 (0.4184)	mem 12194MB
Train: [12/300][600/971]	eta 0:02:22 lr 0.000001991	time 0.3605 (0.3850)	tot_loss 0.4363 (0.4186)	mem 12194MB
Train: [12/300][650/971]	eta 0:02:03 lr 0.000001991	time 0.3604 (0.3846)	tot_loss 0.4791 (0.4187)	mem 12194MB
Train: [12/300][700/971]	eta 0:01:43 lr 0.000001991	time 0.3572 (0.3837)	tot_loss 0.3880 (0.4189)	mem 12194MB
Train: [12/300][750/971]	eta 0:01:24 lr 0.000001991	time 0.3484 (0.3829)	tot_loss 0.4484 (0.4195)	mem 12194MB
Train: [12/300][800/971]	eta 0:01:05 lr 0.000001991	time 0.3519 (0.3827)	tot_loss 0.4320 (0.4192)	mem 12194MB
Train: [12/300][850/971]	eta 0:00:46 lr 0.000001991	time 0.3495 (0.3821)	tot_loss 0.4457 (0.4192)	mem 12194MB
Train: [12/300][900/971]	eta 0:00:27 lr 0.000001991	time 0.3457 (0.3821)	tot_loss 0.4013 (0.4188)	mem 12194MB
Train: [12/300][950/971]	eta 0:00:08 lr 0.000001991	time 0.3308 (0.3813)	tot_loss 0.4352 (0.4189)	mem 12194MB
EPOCH 12 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 50.000	
Test: [100/3923]	Acc@1: 47.525	
Test: [150/3923]	Acc@1: 47.020	
Test: [200/3923]	Acc@1: 47.264	
Test: [250/3923]	Acc@1: 47.610	
Test: [300/3923]	Acc@1: 49.003	
Test: [350/3923]	Acc@1: 48.860	
Test: [400/3923]	Acc@1: 48.753	
Test: [450/3923]	Acc@1: 48.559	
Test: [500/3923]	Acc@1: 48.204	
Test: [550/3923]	Acc@1: 48.457	
Test: [600/3923]	Acc@1: 48.419	
Test: [650/3923]	Acc@1: 48.003	
Test: [700/3923]	Acc@1: 47.504	
Test: [750/3923]	Acc@1: 47.936	
Test: [800/3923]	Acc@1: 47.378	
Test: [850/3923]	Acc@1: 47.121	
Test: [900/3923]	Acc@1: 47.281	
Test: [950/3923]	Acc@1: 47.108	
Test: [1000/3923]	Acc@1: 47.003	
Test: [1050/3923]	Acc@1: 46.908	
Test: [1100/3923]	Acc@1: 46.140	
Test: [1150/3923]	Acc@1: 46.308	
Test: [1200/3923]	Acc@1: 46.170	
Test: [1250/3923]	Acc@1: 46.323	
Test: [1300/3923]	Acc@1: 46.272	
Test: [1350/3923]	Acc@1: 46.484	
Test: [1400/3923]	Acc@1: 46.859	
Test: [1450/3923]	Acc@1: 46.726	
Test: [1500/3923]	Acc@1: 46.935	
Test: [1550/3923]	Acc@1: 46.937	
Test: [1600/3923]	Acc@1: 47.002	
Test: [1650/3923]	Acc@1: 47.002	
Test: [1700/3923]	Acc@1: 46.943	
Test: [1750/3923]	Acc@1: 46.688	
Test: [1800/3923]	Acc@1: 46.641	
Test: [1850/3923]	Acc@1: 46.650	
Test: [1900/3923]	Acc@1: 46.817	
Test: [1950/3923]	Acc@1: 46.617	
Test: [2000/3923]	Acc@1: 46.402	
Test: [2050/3923]	Acc@1: 46.490	
Test: [2100/3923]	Acc@1: 46.692	
Test: [2150/3923]	Acc@1: 46.815	
Test: [2200/3923]	Acc@1: 46.592	
Test: [2250/3923]	Acc@1: 46.801	
Test: [2300/3923]	Acc@1: 46.675	
Test: [2350/3923]	Acc@1: 46.661	
Test: [2400/3923]	Acc@1: 46.793	
Test: [2450/3923]	Acc@1: 46.879	
Test: [2500/3923]	Acc@1: 46.801	
Test: [2550/3923]	Acc@1: 46.746	
Test: [2600/3923]	Acc@1: 46.847	
Test: [2650/3923]	Acc@1: 46.926	
Test: [2700/3923]	Acc@1: 47.001	
Test: [2750/3923]	Acc@1: 46.892	
Test: [2800/3923]	Acc@1: 46.983	
Test: [2850/3923]	Acc@1: 47.001	
Test: [2900/3923]	Acc@1: 47.053	
Test: [2950/3923]	Acc@1: 47.035	
Test: [3000/3923]	Acc@1: 47.018	
Test: [3050/3923]	Acc@1: 47.067	
Test: [3100/3923]	Acc@1: 47.033	
Test: [3150/3923]	Acc@1: 47.049	
Test: [3200/3923]	Acc@1: 46.985	
Test: [3250/3923]	Acc@1: 46.939	
Test: [3300/3923]	Acc@1: 46.971	
Test: [3350/3923]	Acc@1: 46.986	
Test: [3400/3923]	Acc@1: 47.030	
Test: [3450/3923]	Acc@1: 47.044	
Test: [3500/3923]	Acc@1: 47.215	
Test: [3550/3923]	Acc@1: 47.226	
Test: [3600/3923]	Acc@1: 47.154	
Test: [3650/3923]	Acc@1: 47.247	
Test: [3700/3923]	Acc@1: 47.203	
Test: [3750/3923]	Acc@1: 47.214	
Test: [3800/3923]	Acc@1: 47.330	
Test: [3850/3923]	Acc@1: 47.429	
Test: [3900/3923]	Acc@1: 47.334	
 * Acc@1 47.362 Acc@5 94.188 UAR 34.739Accuracy of the network on the 7847 test videos: 47.4%
Max accuracy: 47.36%, Current UAR : 34.74%, Max UAR :34.74%Train: [13/300][0/971]	eta 1:19:38 lr 0.000001991	time 4.9211 (4.9211)	tot_loss 0.4222 (0.4222)	mem 12194MB
Train: [13/300][50/971]	eta 0:07:21 lr 0.000001991	time 0.3491 (0.4796)	tot_loss 0.4526 (0.4180)	mem 12194MB
Train: [13/300][100/971]	eta 0:06:14 lr 0.000001991	time 0.3559 (0.4295)	tot_loss 0.3619 (0.4169)	mem 12194MB
Train: [13/300][150/971]	eta 0:05:37 lr 0.000001991	time 0.3849 (0.4115)	tot_loss 0.4223 (0.4187)	mem 12194MB
Train: [13/300][200/971]	eta 0:05:11 lr 0.000001991	time 0.3569 (0.4036)	tot_loss 0.4203 (0.4190)	mem 12194MB
Train: [13/300][250/971]	eta 0:04:47 lr 0.000001990	time 0.3557 (0.3988)	tot_loss 0.3944 (0.4187)	mem 12194MB
Train: [13/300][300/971]	eta 0:04:25 lr 0.000001990	time 0.3622 (0.3950)	tot_loss 0.4261 (0.4178)	mem 12194MB
Train: [13/300][350/971]	eta 0:04:03 lr 0.000001990	time 0.3490 (0.3925)	tot_loss 0.4325 (0.4172)	mem 12194MB
Train: [13/300][400/971]	eta 0:03:43 lr 0.000001990	time 0.5031 (0.3911)	tot_loss 0.4066 (0.4178)	mem 12194MB
Train: [13/300][450/971]	eta 0:03:22 lr 0.000001990	time 0.3516 (0.3893)	tot_loss 0.3942 (0.4176)	mem 12194MB
Train: [13/300][500/971]	eta 0:03:02 lr 0.000001990	time 0.3493 (0.3884)	tot_loss 0.4645 (0.4179)	mem 12194MB
Train: [13/300][550/971]	eta 0:02:43 lr 0.000001990	time 0.3519 (0.3873)	tot_loss 0.4403 (0.4178)	mem 12194MB
Train: [13/300][600/971]	eta 0:02:23 lr 0.000001990	time 0.3673 (0.3868)	tot_loss 0.3916 (0.4180)	mem 12194MB
Train: [13/300][650/971]	eta 0:02:03 lr 0.000001990	time 0.3657 (0.3859)	tot_loss 0.4580 (0.4179)	mem 12194MB
Train: [13/300][700/971]	eta 0:01:44 lr 0.000001990	time 0.3557 (0.3852)	tot_loss 0.4271 (0.4176)	mem 12194MB
Train: [13/300][750/971]	eta 0:01:25 lr 0.000001990	time 0.3579 (0.3850)	tot_loss 0.4375 (0.4178)	mem 12194MB
Train: [13/300][800/971]	eta 0:01:05 lr 0.000001990	time 0.3528 (0.3843)	tot_loss 0.4390 (0.4183)	mem 12194MB
Train: [13/300][850/971]	eta 0:00:46 lr 0.000001990	time 0.3533 (0.3839)	tot_loss 0.4483 (0.4183)	mem 12194MB
Train: [13/300][900/971]	eta 0:00:27 lr 0.000001989	time 0.3518 (0.3838)	tot_loss 0.4119 (0.4180)	mem 12194MB
Train: [13/300][950/971]	eta 0:00:08 lr 0.000001989	time 0.3693 (0.3837)	tot_loss 0.4239 (0.4180)	mem 12194MB
EPOCH 13 training takes 0:06:12
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 47.525	
Test: [150/3923]	Acc@1: 47.020	
Test: [200/3923]	Acc@1: 48.756	
Test: [250/3923]	Acc@1: 49.004	
Test: [300/3923]	Acc@1: 49.336	
Test: [350/3923]	Acc@1: 49.573	
Test: [400/3923]	Acc@1: 49.127	
Test: [450/3923]	Acc@1: 49.113	
Test: [500/3923]	Acc@1: 49.301	
Test: [550/3923]	Acc@1: 49.002	
Test: [600/3923]	Acc@1: 48.669	
Test: [650/3923]	Acc@1: 49.002	
Test: [700/3923]	Acc@1: 48.716	
Test: [750/3923]	Acc@1: 49.068	
Test: [800/3923]	Acc@1: 48.627	
Test: [850/3923]	Acc@1: 48.590	
Test: [900/3923]	Acc@1: 48.835	
Test: [950/3923]	Acc@1: 48.475	
Test: [1000/3923]	Acc@1: 48.152	
Test: [1050/3923]	Acc@1: 48.192	
Test: [1100/3923]	Acc@1: 48.229	
Test: [1150/3923]	Acc@1: 48.306	
Test: [1200/3923]	Acc@1: 48.335	
Test: [1250/3923]	Acc@1: 48.321	
Test: [1300/3923]	Acc@1: 48.194	
Test: [1350/3923]	Acc@1: 48.113	
Test: [1400/3923]	Acc@1: 48.180	
Test: [1450/3923]	Acc@1: 48.139	
Test: [1500/3923]	Acc@1: 48.068	
Test: [1550/3923]	Acc@1: 48.453	
Test: [1600/3923]	Acc@1: 48.345	
Test: [1650/3923]	Acc@1: 48.092	
Test: [1700/3923]	Acc@1: 47.884	
Test: [1750/3923]	Acc@1: 47.773	
Test: [1800/3923]	Acc@1: 47.862	
Test: [1850/3923]	Acc@1: 48.109	
Test: [1900/3923]	Acc@1: 48.211	
Test: [1950/3923]	Acc@1: 48.206	
Test: [2000/3923]	Acc@1: 48.101	
Test: [2050/3923]	Acc@1: 48.269	
Test: [2100/3923]	Acc@1: 48.168	
Test: [2150/3923]	Acc@1: 48.001	
Test: [2200/3923]	Acc@1: 48.046	
Test: [2250/3923]	Acc@1: 48.090	
Test: [2300/3923]	Acc@1: 48.044	
Test: [2350/3923]	Acc@1: 47.873	
Test: [2400/3923]	Acc@1: 47.855	
Test: [2450/3923]	Acc@1: 47.736	
Test: [2500/3923]	Acc@1: 47.541	
Test: [2550/3923]	Acc@1: 47.550	
Test: [2600/3923]	Acc@1: 47.674	
Test: [2650/3923]	Acc@1: 47.661	
Test: [2700/3923]	Acc@1: 47.723	
Test: [2750/3923]	Acc@1: 47.692	
Test: [2800/3923]	Acc@1: 47.858	
Test: [2850/3923]	Acc@1: 47.913	
Test: [2900/3923]	Acc@1: 47.846	
Test: [2950/3923]	Acc@1: 47.882	
Test: [3000/3923]	Acc@1: 47.851	
Test: [3050/3923]	Acc@1: 47.968	
Test: [3100/3923]	Acc@1: 47.888	
Test: [3150/3923]	Acc@1: 47.778	
Test: [3200/3923]	Acc@1: 47.751	
Test: [3250/3923]	Acc@1: 47.693	
Test: [3300/3923]	Acc@1: 47.804	
Test: [3350/3923]	Acc@1: 47.747	
Test: [3400/3923]	Acc@1: 47.809	
Test: [3450/3923]	Acc@1: 47.798	
Test: [3500/3923]	Acc@1: 47.772	
Test: [3550/3923]	Acc@1: 47.789	
Test: [3600/3923]	Acc@1: 47.737	
Test: [3650/3923]	Acc@1: 47.576	
Test: [3700/3923]	Acc@1: 47.501	
Test: [3750/3923]	Acc@1: 47.454	
Test: [3800/3923]	Acc@1: 47.488	
Test: [3850/3923]	Acc@1: 47.468	
Test: [3900/3923]	Acc@1: 47.347	
 * Acc@1 47.336 Acc@5 94.150 UAR 34.424Accuracy of the network on the 7847 test videos: 47.3%
Max accuracy: 47.36%, Current UAR : 34.74%, Max UAR :34.74%Train: [14/300][0/971]	eta 1:23:34 lr 0.000001989	time 5.1645 (5.1645)	tot_loss 0.4304 (0.4304)	mem 12194MB
Train: [14/300][50/971]	eta 0:07:22 lr 0.000001989	time 0.3807 (0.4799)	tot_loss 0.3184 (0.4125)	mem 12194MB
Train: [14/300][100/971]	eta 0:06:17 lr 0.000001989	time 0.3597 (0.4336)	tot_loss 0.4239 (0.4131)	mem 12194MB
Train: [14/300][150/971]	eta 0:05:42 lr 0.000001989	time 0.3864 (0.4167)	tot_loss 0.4729 (0.4164)	mem 12194MB
Train: [14/300][200/971]	eta 0:05:14 lr 0.000001989	time 0.3418 (0.4081)	tot_loss 0.4365 (0.4169)	mem 12194MB
Train: [14/300][250/971]	eta 0:04:50 lr 0.000001989	time 0.3726 (0.4023)	tot_loss 0.4501 (0.4164)	mem 12194MB
Train: [14/300][300/971]	eta 0:04:27 lr 0.000001989	time 0.3520 (0.3980)	tot_loss 0.4165 (0.4166)	mem 12194MB
Train: [14/300][350/971]	eta 0:04:04 lr 0.000001989	time 0.3539 (0.3942)	tot_loss 0.4153 (0.4159)	mem 12194MB
Train: [14/300][400/971]	eta 0:03:44 lr 0.000001989	time 0.3502 (0.3926)	tot_loss 0.4019 (0.4168)	mem 12194MB
Train: [14/300][450/971]	eta 0:03:23 lr 0.000001989	time 0.3847 (0.3914)	tot_loss 0.4309 (0.4166)	mem 12194MB
Train: [14/300][500/971]	eta 0:03:03 lr 0.000001989	time 0.3632 (0.3896)	tot_loss 0.4181 (0.4167)	mem 12194MB
Train: [14/300][550/971]	eta 0:02:43 lr 0.000001989	time 0.4778 (0.3882)	tot_loss 0.3833 (0.4165)	mem 12194MB
Train: [14/300][600/971]	eta 0:02:23 lr 0.000001988	time 0.3522 (0.3867)	tot_loss 0.4311 (0.4168)	mem 12194MB
Train: [14/300][650/971]	eta 0:02:04 lr 0.000001988	time 0.3481 (0.3865)	tot_loss 0.4153 (0.4170)	mem 12194MB
Train: [14/300][700/971]	eta 0:01:44 lr 0.000001988	time 0.3457 (0.3851)	tot_loss 0.4428 (0.4174)	mem 12194MB
Train: [14/300][750/971]	eta 0:01:24 lr 0.000001988	time 0.3572 (0.3841)	tot_loss 0.4406 (0.4173)	mem 12194MB
Train: [14/300][800/971]	eta 0:01:05 lr 0.000001988	time 0.3437 (0.3831)	tot_loss 0.3490 (0.4177)	mem 12194MB
Train: [14/300][850/971]	eta 0:00:46 lr 0.000001988	time 0.3524 (0.3822)	tot_loss 0.4302 (0.4173)	mem 12194MB
Train: [14/300][900/971]	eta 0:00:27 lr 0.000001988	time 0.3520 (0.3816)	tot_loss 0.3687 (0.4171)	mem 12194MB
Train: [14/300][950/971]	eta 0:00:07 lr 0.000001988	time 0.3333 (0.3806)	tot_loss 0.4452 (0.4170)	mem 12194MB
EPOCH 14 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 44.554	
Test: [150/3923]	Acc@1: 44.702	
Test: [200/3923]	Acc@1: 45.771	
Test: [250/3923]	Acc@1: 47.809	
Test: [300/3923]	Acc@1: 48.339	
Test: [350/3923]	Acc@1: 47.721	
Test: [400/3923]	Acc@1: 46.135	
Test: [450/3923]	Acc@1: 46.674	
Test: [500/3923]	Acc@1: 46.906	
Test: [550/3923]	Acc@1: 46.461	
Test: [600/3923]	Acc@1: 46.339	
Test: [650/3923]	Acc@1: 46.544	
Test: [700/3923]	Acc@1: 46.648	
Test: [750/3923]	Acc@1: 47.071	
Test: [800/3923]	Acc@1: 47.129	
Test: [850/3923]	Acc@1: 46.886	
Test: [900/3923]	Acc@1: 47.059	
Test: [950/3923]	Acc@1: 47.371	
Test: [1000/3923]	Acc@1: 47.353	
Test: [1050/3923]	Acc@1: 47.526	
Test: [1100/3923]	Acc@1: 47.775	
Test: [1150/3923]	Acc@1: 47.741	
Test: [1200/3923]	Acc@1: 47.585	
Test: [1250/3923]	Acc@1: 47.762	
Test: [1300/3923]	Acc@1: 47.463	
Test: [1350/3923]	Acc@1: 47.372	
Test: [1400/3923]	Acc@1: 47.573	
Test: [1450/3923]	Acc@1: 47.553	
Test: [1500/3923]	Acc@1: 47.602	
Test: [1550/3923]	Acc@1: 47.840	
Test: [1600/3923]	Acc@1: 47.595	
Test: [1650/3923]	Acc@1: 47.729	
Test: [1700/3923]	Acc@1: 47.678	
Test: [1750/3923]	Acc@1: 47.658	
Test: [1800/3923]	Acc@1: 47.529	
Test: [1850/3923]	Acc@1: 47.407	
Test: [1900/3923]	Acc@1: 47.291	
Test: [1950/3923]	Acc@1: 47.437	
Test: [2000/3923]	Acc@1: 47.301	
Test: [2050/3923]	Acc@1: 47.367	
Test: [2100/3923]	Acc@1: 47.144	
Test: [2150/3923]	Acc@1: 47.350	
Test: [2200/3923]	Acc@1: 47.297	
Test: [2250/3923]	Acc@1: 47.312	
Test: [2300/3923]	Acc@1: 47.219	
Test: [2350/3923]	Acc@1: 47.299	
Test: [2400/3923]	Acc@1: 47.418	
Test: [2450/3923]	Acc@1: 47.430	
Test: [2500/3923]	Acc@1: 47.501	
Test: [2550/3923]	Acc@1: 47.452	
Test: [2600/3923]	Acc@1: 47.328	
Test: [2650/3923]	Acc@1: 47.435	
Test: [2700/3923]	Acc@1: 47.501	
Test: [2750/3923]	Acc@1: 47.528	
Test: [2800/3923]	Acc@1: 47.554	
Test: [2850/3923]	Acc@1: 47.632	
Test: [2900/3923]	Acc@1: 47.708	
Test: [2950/3923]	Acc@1: 47.526	
Test: [3000/3923]	Acc@1: 47.617	
Test: [3050/3923]	Acc@1: 47.575	
Test: [3100/3923]	Acc@1: 47.565	
Test: [3150/3923]	Acc@1: 47.461	
Test: [3200/3923]	Acc@1: 47.407	
Test: [3250/3923]	Acc@1: 47.355	
Test: [3300/3923]	Acc@1: 47.380	
Test: [3350/3923]	Acc@1: 47.374	
Test: [3400/3923]	Acc@1: 47.471	
Test: [3450/3923]	Acc@1: 47.493	
Test: [3500/3923]	Acc@1: 47.586	
Test: [3550/3923]	Acc@1: 47.620	
Test: [3600/3923]	Acc@1: 47.626	
Test: [3650/3923]	Acc@1: 47.576	
Test: [3700/3923]	Acc@1: 47.460	
Test: [3750/3923]	Acc@1: 47.441	
Test: [3800/3923]	Acc@1: 47.422	
Test: [3850/3923]	Acc@1: 47.403	
Test: [3900/3923]	Acc@1: 47.372	
 * Acc@1 47.323 Acc@5 94.405 UAR 34.933Accuracy of the network on the 7847 test videos: 47.3%
Max accuracy: 47.36%, Current UAR : 34.74%, Max UAR :34.93%Train: [15/300][0/971]	eta 1:27:21 lr 0.000001988	time 5.3984 (5.3984)	tot_loss 0.4562 (0.4562)	mem 12194MB
Train: [15/300][50/971]	eta 0:07:18 lr 0.000001988	time 0.3521 (0.4757)	tot_loss 0.4357 (0.4266)	mem 12194MB
Train: [15/300][100/971]	eta 0:06:12 lr 0.000001988	time 0.3591 (0.4279)	tot_loss 0.4513 (0.4213)	mem 12194MB
Train: [15/300][150/971]	eta 0:05:36 lr 0.000001988	time 0.3524 (0.4104)	tot_loss 0.4125 (0.4176)	mem 12194MB
Train: [15/300][200/971]	eta 0:05:09 lr 0.000001987	time 0.3548 (0.4018)	tot_loss 0.4431 (0.4172)	mem 12194MB
Train: [15/300][250/971]	eta 0:04:44 lr 0.000001987	time 0.3506 (0.3951)	tot_loss 0.4185 (0.4161)	mem 12194MB
Train: [15/300][300/971]	eta 0:04:22 lr 0.000001987	time 0.3582 (0.3917)	tot_loss 0.3877 (0.4168)	mem 12194MB
Train: [15/300][350/971]	eta 0:04:01 lr 0.000001987	time 0.3502 (0.3885)	tot_loss 0.4189 (0.4172)	mem 12194MB
Train: [15/300][400/971]	eta 0:03:41 lr 0.000001987	time 0.3508 (0.3871)	tot_loss 0.4099 (0.4172)	mem 12194MB
Train: [15/300][450/971]	eta 0:03:20 lr 0.000001987	time 0.3522 (0.3855)	tot_loss 0.4524 (0.4164)	mem 12194MB
Train: [15/300][500/971]	eta 0:03:01 lr 0.000001987	time 0.3561 (0.3845)	tot_loss 0.4689 (0.4162)	mem 12194MB
Train: [15/300][550/971]	eta 0:02:41 lr 0.000001987	time 0.3519 (0.3835)	tot_loss 0.4175 (0.4158)	mem 12194MB
Train: [15/300][600/971]	eta 0:02:21 lr 0.000001987	time 0.3578 (0.3824)	tot_loss 0.3850 (0.4158)	mem 12194MB
Train: [15/300][650/971]	eta 0:02:02 lr 0.000001987	time 0.3503 (0.3816)	tot_loss 0.4156 (0.4158)	mem 12194MB
Train: [15/300][700/971]	eta 0:01:43 lr 0.000001987	time 0.4899 (0.3811)	tot_loss 0.4468 (0.4158)	mem 12194MB
Train: [15/300][750/971]	eta 0:01:24 lr 0.000001987	time 0.3507 (0.3803)	tot_loss 0.4166 (0.4157)	mem 12194MB
Train: [15/300][800/971]	eta 0:01:04 lr 0.000001986	time 0.3740 (0.3799)	tot_loss 0.4174 (0.4157)	mem 12194MB
Train: [15/300][850/971]	eta 0:00:45 lr 0.000001986	time 0.3507 (0.3794)	tot_loss 0.4318 (0.4163)	mem 12194MB
Train: [15/300][900/971]	eta 0:00:26 lr 0.000001986	time 0.3542 (0.3791)	tot_loss 0.4269 (0.4166)	mem 12194MB
Train: [15/300][950/971]	eta 0:00:07 lr 0.000001986	time 0.3383 (0.3785)	tot_loss 0.4231 (0.4163)	mem 12194MB
EPOCH 15 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 41.176	
Test: [100/3923]	Acc@1: 46.040	
Test: [150/3923]	Acc@1: 45.033	
Test: [200/3923]	Acc@1: 45.522	
Test: [250/3923]	Acc@1: 44.622	
Test: [300/3923]	Acc@1: 44.684	
Test: [350/3923]	Acc@1: 45.442	
Test: [400/3923]	Acc@1: 45.387	
Test: [450/3923]	Acc@1: 45.565	
Test: [500/3923]	Acc@1: 46.507	
Test: [550/3923]	Acc@1: 46.552	
Test: [600/3923]	Acc@1: 46.589	
Test: [650/3923]	Acc@1: 47.081	
Test: [700/3923]	Acc@1: 47.290	
Test: [750/3923]	Acc@1: 47.403	
Test: [800/3923]	Acc@1: 47.441	
Test: [850/3923]	Acc@1: 47.121	
Test: [900/3923]	Acc@1: 47.059	
Test: [950/3923]	Acc@1: 47.108	
Test: [1000/3923]	Acc@1: 47.453	
Test: [1050/3923]	Acc@1: 47.383	
Test: [1100/3923]	Acc@1: 47.457	
Test: [1150/3923]	Acc@1: 47.089	
Test: [1200/3923]	Acc@1: 47.002	
Test: [1250/3923]	Acc@1: 47.042	
Test: [1300/3923]	Acc@1: 46.733	
Test: [1350/3923]	Acc@1: 46.706	
Test: [1400/3923]	Acc@1: 46.431	
Test: [1450/3923]	Acc@1: 46.347	
Test: [1500/3923]	Acc@1: 46.402	
Test: [1550/3923]	Acc@1: 46.422	
Test: [1600/3923]	Acc@1: 45.909	
Test: [1650/3923]	Acc@1: 46.154	
Test: [1700/3923]	Acc@1: 46.149	
Test: [1750/3923]	Acc@1: 46.202	
Test: [1800/3923]	Acc@1: 46.557	
Test: [1850/3923]	Acc@1: 46.461	
Test: [1900/3923]	Acc@1: 46.476	
Test: [1950/3923]	Acc@1: 46.540	
Test: [2000/3923]	Acc@1: 46.677	
Test: [2050/3923]	Acc@1: 46.733	
Test: [2100/3923]	Acc@1: 46.882	
Test: [2150/3923]	Acc@1: 46.815	
Test: [2200/3923]	Acc@1: 46.842	
Test: [2250/3923]	Acc@1: 46.957	
Test: [2300/3923]	Acc@1: 46.871	
Test: [2350/3923]	Acc@1: 46.916	
Test: [2400/3923]	Acc@1: 47.105	
Test: [2450/3923]	Acc@1: 47.103	
Test: [2500/3923]	Acc@1: 47.181	
Test: [2550/3923]	Acc@1: 46.982	
Test: [2600/3923]	Acc@1: 46.982	
Test: [2650/3923]	Acc@1: 47.171	
Test: [2700/3923]	Acc@1: 47.149	
Test: [2750/3923]	Acc@1: 47.292	
Test: [2800/3923]	Acc@1: 47.305	
Test: [2850/3923]	Acc@1: 47.475	
Test: [2900/3923]	Acc@1: 47.518	
Test: [2950/3923]	Acc@1: 47.560	
Test: [3000/3923]	Acc@1: 47.534	
Test: [3050/3923]	Acc@1: 47.411	
Test: [3100/3923]	Acc@1: 47.243	
Test: [3150/3923]	Acc@1: 47.128	
Test: [3200/3923]	Acc@1: 47.173	
Test: [3250/3923]	Acc@1: 47.293	
Test: [3300/3923]	Acc@1: 47.243	
Test: [3350/3923]	Acc@1: 47.180	
Test: [3400/3923]	Acc@1: 47.236	
Test: [3450/3923]	Acc@1: 47.204	
Test: [3500/3923]	Acc@1: 47.358	
Test: [3550/3923]	Acc@1: 47.395	
Test: [3600/3923]	Acc@1: 47.501	
Test: [3650/3923]	Acc@1: 47.480	
Test: [3700/3923]	Acc@1: 47.541	
Test: [3750/3923]	Acc@1: 47.561	
Test: [3800/3923]	Acc@1: 47.566	
Test: [3850/3923]	Acc@1: 47.585	
Test: [3900/3923]	Acc@1: 47.552	
 * Acc@1 47.578 Acc@5 94.290 UAR 35.893Accuracy of the network on the 7847 test videos: 47.6%
Max accuracy: 47.58%, Current UAR : 35.89%, Max UAR :35.89%Train: [16/300][0/971]	eta 1:34:39 lr 0.000001986	time 5.8487 (5.8487)	tot_loss 0.4482 (0.4482)	mem 12194MB
Train: [16/300][50/971]	eta 0:07:28 lr 0.000001986	time 0.3535 (0.4867)	tot_loss 0.3946 (0.4143)	mem 12194MB
Train: [16/300][100/971]	eta 0:06:15 lr 0.000001986	time 0.3601 (0.4307)	tot_loss 0.3997 (0.4127)	mem 12194MB
Train: [16/300][150/971]	eta 0:05:39 lr 0.000001986	time 0.3516 (0.4135)	tot_loss 0.3879 (0.4171)	mem 12194MB
Train: [16/300][200/971]	eta 0:05:11 lr 0.000001986	time 0.3628 (0.4036)	tot_loss 0.4385 (0.4179)	mem 12194MB
Train: [16/300][250/971]	eta 0:04:46 lr 0.000001986	time 0.3440 (0.3976)	tot_loss 0.3757 (0.4180)	mem 12194MB
Train: [16/300][300/971]	eta 0:04:24 lr 0.000001986	time 0.3546 (0.3936)	tot_loss 0.3646 (0.4172)	mem 12194MB
Train: [16/300][350/971]	eta 0:04:02 lr 0.000001986	time 0.3523 (0.3905)	tot_loss 0.4462 (0.4175)	mem 12194MB
Train: [16/300][400/971]	eta 0:03:41 lr 0.000001985	time 0.3561 (0.3881)	tot_loss 0.3833 (0.4169)	mem 12194MB
Train: [16/300][450/971]	eta 0:03:21 lr 0.000001985	time 0.3807 (0.3865)	tot_loss 0.4128 (0.4165)	mem 12194MB
Train: [16/300][500/971]	eta 0:03:02 lr 0.000001985	time 0.3835 (0.3866)	tot_loss 0.4061 (0.4165)	mem 12194MB
Train: [16/300][550/971]	eta 0:02:42 lr 0.000001985	time 0.3577 (0.3855)	tot_loss 0.4030 (0.4159)	mem 12194MB
Train: [16/300][600/971]	eta 0:02:22 lr 0.000001985	time 0.3566 (0.3843)	tot_loss 0.4172 (0.4156)	mem 12194MB
Train: [16/300][650/971]	eta 0:02:03 lr 0.000001985	time 0.3557 (0.3832)	tot_loss 0.3814 (0.4156)	mem 12194MB
Train: [16/300][700/971]	eta 0:01:43 lr 0.000001985	time 0.3476 (0.3827)	tot_loss 0.4027 (0.4156)	mem 12194MB
Train: [16/300][750/971]	eta 0:01:24 lr 0.000001985	time 0.3743 (0.3822)	tot_loss 0.4369 (0.4159)	mem 12194MB
Train: [16/300][800/971]	eta 0:01:05 lr 0.000001985	time 0.3460 (0.3816)	tot_loss 0.3735 (0.4158)	mem 12194MB
Train: [16/300][850/971]	eta 0:00:46 lr 0.000001985	time 0.3649 (0.3810)	tot_loss 0.4333 (0.4159)	mem 12194MB
Train: [16/300][900/971]	eta 0:00:27 lr 0.000001984	time 0.3525 (0.3804)	tot_loss 0.4268 (0.4159)	mem 12194MB
Train: [16/300][950/971]	eta 0:00:07 lr 0.000001984	time 0.3401 (0.3796)	tot_loss 0.4360 (0.4155)	mem 12194MB
EPOCH 16 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 43.069	
Test: [150/3923]	Acc@1: 43.709	
Test: [200/3923]	Acc@1: 47.015	
Test: [250/3923]	Acc@1: 47.610	
Test: [300/3923]	Acc@1: 48.173	
Test: [350/3923]	Acc@1: 49.003	
Test: [400/3923]	Acc@1: 49.252	
Test: [450/3923]	Acc@1: 49.667	
Test: [500/3923]	Acc@1: 49.601	
Test: [550/3923]	Acc@1: 49.819	
Test: [600/3923]	Acc@1: 49.251	
Test: [650/3923]	Acc@1: 49.616	
Test: [700/3923]	Acc@1: 49.358	
Test: [750/3923]	Acc@1: 48.802	
Test: [800/3923]	Acc@1: 48.564	
Test: [850/3923]	Acc@1: 48.590	
Test: [900/3923]	Acc@1: 48.224	
Test: [950/3923]	Acc@1: 48.265	
Test: [1000/3923]	Acc@1: 48.102	
Test: [1050/3923]	Acc@1: 48.097	
Test: [1100/3923]	Acc@1: 47.820	
Test: [1150/3923]	Acc@1: 47.480	
Test: [1200/3923]	Acc@1: 47.544	
Test: [1250/3923]	Acc@1: 47.242	
Test: [1300/3923]	Acc@1: 47.194	
Test: [1350/3923]	Acc@1: 47.076	
Test: [1400/3923]	Acc@1: 47.109	
Test: [1450/3923]	Acc@1: 47.347	
Test: [1500/3923]	Acc@1: 47.302	
Test: [1550/3923]	Acc@1: 47.228	
Test: [1600/3923]	Acc@1: 47.502	
Test: [1650/3923]	Acc@1: 47.789	
Test: [1700/3923]	Acc@1: 47.854	
Test: [1750/3923]	Acc@1: 47.944	
Test: [1800/3923]	Acc@1: 47.918	
Test: [1850/3923]	Acc@1: 47.677	
Test: [1900/3923]	Acc@1: 47.712	
Test: [1950/3923]	Acc@1: 47.899	
Test: [2000/3923]	Acc@1: 47.776	
Test: [2050/3923]	Acc@1: 47.977	
Test: [2100/3923]	Acc@1: 47.549	
Test: [2150/3923]	Acc@1: 47.443	
Test: [2200/3923]	Acc@1: 47.297	
Test: [2250/3923]	Acc@1: 47.179	
Test: [2300/3923]	Acc@1: 47.153	
Test: [2350/3923]	Acc@1: 46.980	
Test: [2400/3923]	Acc@1: 46.876	
Test: [2450/3923]	Acc@1: 46.838	
Test: [2500/3923]	Acc@1: 46.921	
Test: [2550/3923]	Acc@1: 46.923	
Test: [2600/3923]	Acc@1: 47.040	
Test: [2650/3923]	Acc@1: 47.001	
Test: [2700/3923]	Acc@1: 46.983	
Test: [2750/3923]	Acc@1: 47.037	
Test: [2800/3923]	Acc@1: 47.037	
Test: [2850/3923]	Acc@1: 47.054	
Test: [2900/3923]	Acc@1: 47.036	
Test: [2950/3923]	Acc@1: 47.052	
Test: [3000/3923]	Acc@1: 47.151	
Test: [3050/3923]	Acc@1: 47.165	
Test: [3100/3923]	Acc@1: 47.162	
Test: [3150/3923]	Acc@1: 47.207	
Test: [3200/3923]	Acc@1: 47.157	
Test: [3250/3923]	Acc@1: 47.278	
Test: [3300/3923]	Acc@1: 47.228	
Test: [3350/3923]	Acc@1: 47.314	
Test: [3400/3923]	Acc@1: 47.295	
Test: [3450/3923]	Acc@1: 47.334	
Test: [3500/3923]	Acc@1: 47.315	
Test: [3550/3923]	Acc@1: 47.268	
Test: [3600/3923]	Acc@1: 47.209	
Test: [3650/3923]	Acc@1: 47.193	
Test: [3700/3923]	Acc@1: 47.285	
Test: [3750/3923]	Acc@1: 47.294	
Test: [3800/3923]	Acc@1: 47.369	
Test: [3850/3923]	Acc@1: 47.416	
Test: [3900/3923]	Acc@1: 47.437	
 * Acc@1 47.502 Acc@5 94.430 UAR 33.844Accuracy of the network on the 7847 test videos: 47.5%
Max accuracy: 47.58%, Current UAR : 35.89%, Max UAR :35.89%Train: [17/300][0/971]	eta 1:26:10 lr 0.000001984	time 5.3254 (5.3254)	tot_loss 0.4487 (0.4487)	mem 12194MB
Train: [17/300][50/971]	eta 0:07:20 lr 0.000001984	time 0.3565 (0.4784)	tot_loss 0.3919 (0.4136)	mem 12194MB
Train: [17/300][100/971]	eta 0:06:15 lr 0.000001984	time 0.3667 (0.4312)	tot_loss 0.3983 (0.4155)	mem 12194MB
Train: [17/300][150/971]	eta 0:05:42 lr 0.000001984	time 0.3659 (0.4167)	tot_loss 0.3875 (0.4158)	mem 12194MB
Train: [17/300][200/971]	eta 0:05:13 lr 0.000001984	time 0.3589 (0.4072)	tot_loss 0.4502 (0.4168)	mem 12194MB
Train: [17/300][250/971]	eta 0:04:51 lr 0.000001984	time 0.3645 (0.4040)	tot_loss 0.3708 (0.4160)	mem 12194MB
Train: [17/300][300/971]	eta 0:04:27 lr 0.000001984	time 0.3501 (0.3988)	tot_loss 0.4455 (0.4162)	mem 12194MB
Train: [17/300][350/971]	eta 0:04:05 lr 0.000001984	time 0.3515 (0.3946)	tot_loss 0.4282 (0.4160)	mem 12194MB
Train: [17/300][400/971]	eta 0:03:43 lr 0.000001984	time 0.3511 (0.3915)	tot_loss 0.4431 (0.4158)	mem 12194MB
Train: [17/300][450/971]	eta 0:03:22 lr 0.000001983	time 0.3592 (0.3889)	tot_loss 0.4336 (0.4147)	mem 12194MB
Train: [17/300][500/971]	eta 0:03:02 lr 0.000001983	time 0.3651 (0.3875)	tot_loss 0.4115 (0.4147)	mem 12194MB
Train: [17/300][550/971]	eta 0:02:42 lr 0.000001983	time 0.3515 (0.3868)	tot_loss 0.4260 (0.4146)	mem 12194MB
Train: [17/300][600/971]	eta 0:02:23 lr 0.000001983	time 0.3471 (0.3856)	tot_loss 0.4279 (0.4142)	mem 12194MB
Train: [17/300][650/971]	eta 0:02:03 lr 0.000001983	time 0.3539 (0.3844)	tot_loss 0.3230 (0.4144)	mem 12194MB
Train: [17/300][700/971]	eta 0:01:43 lr 0.000001983	time 0.3618 (0.3835)	tot_loss 0.3759 (0.4145)	mem 12194MB
Train: [17/300][750/971]	eta 0:01:24 lr 0.000001983	time 0.3675 (0.3828)	tot_loss 0.3461 (0.4147)	mem 12194MB
Train: [17/300][800/971]	eta 0:01:05 lr 0.000001983	time 0.3514 (0.3820)	tot_loss 0.4035 (0.4152)	mem 12194MB
Train: [17/300][850/971]	eta 0:00:46 lr 0.000001983	time 0.3867 (0.3830)	tot_loss 0.3836 (0.4155)	mem 12194MB
Train: [17/300][900/971]	eta 0:00:27 lr 0.000001983	time 0.3869 (0.3832)	tot_loss 0.4074 (0.4153)	mem 12194MB
Train: [17/300][950/971]	eta 0:00:08 lr 0.000001983	time 0.3377 (0.3827)	tot_loss 0.4610 (0.4153)	mem 12194MB
EPOCH 17 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 41.584	
Test: [150/3923]	Acc@1: 44.702	
Test: [200/3923]	Acc@1: 45.771	
Test: [250/3923]	Acc@1: 46.215	
Test: [300/3923]	Acc@1: 46.179	
Test: [350/3923]	Acc@1: 46.296	
Test: [400/3923]	Acc@1: 46.758	
Test: [450/3923]	Acc@1: 45.787	
Test: [500/3923]	Acc@1: 46.008	
Test: [550/3923]	Acc@1: 45.554	
Test: [600/3923]	Acc@1: 46.007	
Test: [650/3923]	Acc@1: 46.928	
Test: [700/3923]	Acc@1: 47.218	
Test: [750/3923]	Acc@1: 47.403	
Test: [800/3923]	Acc@1: 47.066	
Test: [850/3923]	Acc@1: 48.002	
Test: [900/3923]	Acc@1: 48.224	
Test: [950/3923]	Acc@1: 48.475	
Test: [1000/3923]	Acc@1: 48.052	
Test: [1050/3923]	Acc@1: 48.240	
Test: [1100/3923]	Acc@1: 48.547	
Test: [1150/3923]	Acc@1: 48.132	
Test: [1200/3923]	Acc@1: 48.043	
Test: [1250/3923]	Acc@1: 48.321	
Test: [1300/3923]	Acc@1: 48.347	
Test: [1350/3923]	Acc@1: 48.446	
Test: [1400/3923]	Acc@1: 48.358	
Test: [1450/3923]	Acc@1: 48.312	
Test: [1500/3923]	Acc@1: 48.434	
Test: [1550/3923]	Acc@1: 48.162	
Test: [1600/3923]	Acc@1: 48.032	
Test: [1650/3923]	Acc@1: 47.789	
Test: [1700/3923]	Acc@1: 47.766	
Test: [1750/3923]	Acc@1: 47.801	
Test: [1800/3923]	Acc@1: 47.973	
Test: [1850/3923]	Acc@1: 48.001	
Test: [1900/3923]	Acc@1: 48.027	
Test: [1950/3923]	Acc@1: 48.129	
Test: [2000/3923]	Acc@1: 47.951	
Test: [2050/3923]	Acc@1: 47.733	
Test: [2100/3923]	Acc@1: 47.692	
Test: [2150/3923]	Acc@1: 47.792	
Test: [2200/3923]	Acc@1: 48.024	
Test: [2250/3923]	Acc@1: 48.068	
Test: [2300/3923]	Acc@1: 47.957	
Test: [2350/3923]	Acc@1: 48.065	
Test: [2400/3923]	Acc@1: 48.063	
Test: [2450/3923]	Acc@1: 47.940	
Test: [2500/3923]	Acc@1: 47.961	
Test: [2550/3923]	Acc@1: 47.824	
Test: [2600/3923]	Acc@1: 47.905	
Test: [2650/3923]	Acc@1: 47.869	
Test: [2700/3923]	Acc@1: 47.871	
Test: [2750/3923]	Acc@1: 47.874	
Test: [2800/3923]	Acc@1: 48.036	
Test: [2850/3923]	Acc@1: 47.808	
Test: [2900/3923]	Acc@1: 47.811	
Test: [2950/3923]	Acc@1: 47.933	
Test: [3000/3923]	Acc@1: 47.801	
Test: [3050/3923]	Acc@1: 47.919	
Test: [3100/3923]	Acc@1: 48.065	
Test: [3150/3923]	Acc@1: 48.017	
Test: [3200/3923]	Acc@1: 48.047	
Test: [3250/3923]	Acc@1: 48.124	
Test: [3300/3923]	Acc@1: 48.001	
Test: [3350/3923]	Acc@1: 48.075	
Test: [3400/3923]	Acc@1: 47.971	
Test: [3450/3923]	Acc@1: 47.986	
Test: [3500/3923]	Acc@1: 47.972	
Test: [3550/3923]	Acc@1: 48.015	
Test: [3600/3923]	Acc@1: 48.001	
Test: [3650/3923]	Acc@1: 48.055	
Test: [3700/3923]	Acc@1: 48.001	
Test: [3750/3923]	Acc@1: 48.107	
Test: [3800/3923]	Acc@1: 48.119	
Test: [3850/3923]	Acc@1: 48.143	
Test: [3900/3923]	Acc@1: 48.154	
 * Acc@1 48.152 Acc@5 94.035 UAR 36.959Accuracy of the network on the 7847 test videos: 48.2%
Max accuracy: 48.15%, Current UAR : 36.96%, Max UAR :36.96%Train: [18/300][0/971]	eta 1:27:12 lr 0.000001982	time 5.3890 (5.3890)	tot_loss 0.4103 (0.4103)	mem 12194MB
Train: [18/300][50/971]	eta 0:07:22 lr 0.000001982	time 0.3583 (0.4804)	tot_loss 0.4246 (0.4092)	mem 12194MB
Train: [18/300][100/971]	eta 0:06:19 lr 0.000001982	time 0.3488 (0.4357)	tot_loss 0.4160 (0.4124)	mem 12194MB
Train: [18/300][150/971]	eta 0:05:41 lr 0.000001982	time 0.3647 (0.4162)	tot_loss 0.3644 (0.4129)	mem 12194MB
Train: [18/300][200/971]	eta 0:05:13 lr 0.000001982	time 0.3540 (0.4065)	tot_loss 0.3968 (0.4142)	mem 12194MB
Train: [18/300][250/971]	eta 0:04:48 lr 0.000001982	time 0.3469 (0.4004)	tot_loss 0.4144 (0.4131)	mem 12194MB
Train: [18/300][300/971]	eta 0:04:26 lr 0.000001982	time 0.3782 (0.3965)	tot_loss 0.4016 (0.4122)	mem 12194MB
Train: [18/300][350/971]	eta 0:04:04 lr 0.000001982	time 0.3849 (0.3940)	tot_loss 0.4273 (0.4112)	mem 12194MB
Train: [18/300][400/971]	eta 0:03:43 lr 0.000001982	time 0.3491 (0.3917)	tot_loss 0.3633 (0.4115)	mem 12194MB
Train: [18/300][450/971]	eta 0:03:23 lr 0.000001982	time 0.3559 (0.3908)	tot_loss 0.3962 (0.4118)	mem 12194MB
Train: [18/300][500/971]	eta 0:03:03 lr 0.000001981	time 0.3490 (0.3893)	tot_loss 0.4242 (0.4123)	mem 12194MB
Train: [18/300][550/971]	eta 0:02:43 lr 0.000001981	time 0.3511 (0.3879)	tot_loss 0.4195 (0.4120)	mem 12194MB
Train: [18/300][600/971]	eta 0:02:23 lr 0.000001981	time 0.3613 (0.3873)	tot_loss 0.4795 (0.4128)	mem 12194MB
Train: [18/300][650/971]	eta 0:02:04 lr 0.000001981	time 0.3602 (0.3865)	tot_loss 0.4373 (0.4129)	mem 12194MB
Train: [18/300][700/971]	eta 0:01:44 lr 0.000001981	time 0.3557 (0.3858)	tot_loss 0.4584 (0.4131)	mem 12194MB
Train: [18/300][750/971]	eta 0:01:25 lr 0.000001981	time 0.3504 (0.3854)	tot_loss 0.4109 (0.4129)	mem 12194MB
Train: [18/300][800/971]	eta 0:01:05 lr 0.000001981	time 0.3506 (0.3848)	tot_loss 0.3967 (0.4131)	mem 12194MB
Train: [18/300][850/971]	eta 0:00:46 lr 0.000001981	time 0.3632 (0.3841)	tot_loss 0.3971 (0.4130)	mem 12194MB
Train: [18/300][900/971]	eta 0:00:27 lr 0.000001981	time 0.3515 (0.3837)	tot_loss 0.3942 (0.4134)	mem 12194MB
Train: [18/300][950/971]	eta 0:00:08 lr 0.000001981	time 0.3347 (0.3833)	tot_loss 0.4391 (0.4135)	mem 12194MB
EPOCH 18 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 56.863	
Test: [100/3923]	Acc@1: 51.485	
Test: [150/3923]	Acc@1: 49.669	
Test: [200/3923]	Acc@1: 48.507	
Test: [250/3923]	Acc@1: 48.805	
Test: [300/3923]	Acc@1: 47.342	
Test: [350/3923]	Acc@1: 46.581	
Test: [400/3923]	Acc@1: 46.633	
Test: [450/3923]	Acc@1: 47.339	
Test: [500/3923]	Acc@1: 46.507	
Test: [550/3923]	Acc@1: 45.554	
Test: [600/3923]	Acc@1: 45.923	
Test: [650/3923]	Acc@1: 46.160	
Test: [700/3923]	Acc@1: 45.863	
Test: [750/3923]	Acc@1: 46.138	
Test: [800/3923]	Acc@1: 46.754	
Test: [850/3923]	Acc@1: 46.945	
Test: [900/3923]	Acc@1: 47.558	
Test: [950/3923]	Acc@1: 47.739	
Test: [1000/3923]	Acc@1: 47.902	
Test: [1050/3923]	Acc@1: 47.812	
Test: [1100/3923]	Acc@1: 47.866	
Test: [1150/3923]	Acc@1: 47.698	
Test: [1200/3923]	Acc@1: 47.794	
Test: [1250/3923]	Acc@1: 47.762	
Test: [1300/3923]	Acc@1: 47.963	
Test: [1350/3923]	Acc@1: 48.038	
Test: [1400/3923]	Acc@1: 48.144	
Test: [1450/3923]	Acc@1: 48.036	
Test: [1500/3923]	Acc@1: 48.068	
Test: [1550/3923]	Acc@1: 47.872	
Test: [1600/3923]	Acc@1: 48.095	
Test: [1650/3923]	Acc@1: 48.395	
Test: [1700/3923]	Acc@1: 48.060	
Test: [1750/3923]	Acc@1: 47.801	
Test: [1800/3923]	Acc@1: 47.779	
Test: [1850/3923]	Acc@1: 47.704	
Test: [1900/3923]	Acc@1: 47.738	
Test: [1950/3923]	Acc@1: 47.822	
Test: [2000/3923]	Acc@1: 47.626	
Test: [2050/3923]	Acc@1: 47.367	
Test: [2100/3923]	Acc@1: 47.287	
Test: [2150/3923]	Acc@1: 47.466	
Test: [2200/3923]	Acc@1: 47.456	
Test: [2250/3923]	Acc@1: 47.223	
Test: [2300/3923]	Acc@1: 47.240	
Test: [2350/3923]	Acc@1: 47.342	
Test: [2400/3923]	Acc@1: 47.293	
Test: [2450/3923]	Acc@1: 47.368	
Test: [2500/3923]	Acc@1: 47.441	
Test: [2550/3923]	Acc@1: 47.491	
Test: [2600/3923]	Acc@1: 47.501	
Test: [2650/3923]	Acc@1: 47.529	
Test: [2700/3923]	Acc@1: 47.482	
Test: [2750/3923]	Acc@1: 47.455	
Test: [2800/3923]	Acc@1: 47.590	
Test: [2850/3923]	Acc@1: 47.580	
Test: [2900/3923]	Acc@1: 47.604	
Test: [2950/3923]	Acc@1: 47.696	
Test: [3000/3923]	Acc@1: 47.884	
Test: [3050/3923]	Acc@1: 47.886	
Test: [3100/3923]	Acc@1: 47.952	
Test: [3150/3923]	Acc@1: 47.969	
Test: [3200/3923]	Acc@1: 47.985	
Test: [3250/3923]	Acc@1: 48.047	
Test: [3300/3923]	Acc@1: 48.061	
Test: [3350/3923]	Acc@1: 48.150	
Test: [3400/3923]	Acc@1: 48.177	
Test: [3450/3923]	Acc@1: 48.261	
Test: [3500/3923]	Acc@1: 48.186	
Test: [3550/3923]	Acc@1: 48.170	
Test: [3600/3923]	Acc@1: 48.292	
Test: [3650/3923]	Acc@1: 48.357	
Test: [3700/3923]	Acc@1: 48.298	
Test: [3750/3923]	Acc@1: 48.280	
Test: [3800/3923]	Acc@1: 48.395	
Test: [3850/3923]	Acc@1: 48.416	
Test: [3900/3923]	Acc@1: 48.475	
 * Acc@1 48.496 Acc@5 94.762 UAR 36.501Accuracy of the network on the 7847 test videos: 48.5%
Max accuracy: 48.50%, Current UAR : 36.50%, Max UAR :36.96%Train: [19/300][0/971]	eta 1:21:31 lr 0.000001980	time 5.0371 (5.0371)	tot_loss 0.4095 (0.4095)	mem 12194MB
Train: [19/300][50/971]	eta 0:07:18 lr 0.000001980	time 0.3455 (0.4756)	tot_loss 0.4162 (0.4158)	mem 12194MB
Train: [19/300][100/971]	eta 0:06:11 lr 0.000001980	time 0.3441 (0.4263)	tot_loss 0.4383 (0.4117)	mem 12194MB
Train: [19/300][150/971]	eta 0:05:36 lr 0.000001980	time 0.3453 (0.4102)	tot_loss 0.4286 (0.4107)	mem 12194MB
Train: [19/300][200/971]	eta 0:05:09 lr 0.000001980	time 0.3550 (0.4015)	tot_loss 0.3668 (0.4092)	mem 12194MB
Train: [19/300][250/971]	eta 0:04:45 lr 0.000001980	time 0.3593 (0.3965)	tot_loss 0.3569 (0.4102)	mem 12194MB
Train: [19/300][300/971]	eta 0:04:24 lr 0.000001980	time 0.3618 (0.3939)	tot_loss 0.3744 (0.4119)	mem 12194MB
Train: [19/300][350/971]	eta 0:04:02 lr 0.000001980	time 0.3515 (0.3908)	tot_loss 0.4186 (0.4129)	mem 12194MB
Train: [19/300][400/971]	eta 0:03:42 lr 0.000001980	time 0.3507 (0.3898)	tot_loss 0.3855 (0.4128)	mem 12194MB
Train: [19/300][450/971]	eta 0:03:22 lr 0.000001980	time 0.3534 (0.3884)	tot_loss 0.4066 (0.4128)	mem 12194MB
Train: [19/300][500/971]	eta 0:03:02 lr 0.000001979	time 0.3439 (0.3871)	tot_loss 0.4349 (0.4130)	mem 12194MB
Train: [19/300][550/971]	eta 0:02:42 lr 0.000001979	time 0.3490 (0.3859)	tot_loss 0.3835 (0.4131)	mem 12194MB
Train: [19/300][600/971]	eta 0:02:22 lr 0.000001979	time 0.3592 (0.3847)	tot_loss 0.4591 (0.4129)	mem 12194MB
Train: [19/300][650/971]	eta 0:02:03 lr 0.000001979	time 0.3643 (0.3839)	tot_loss 0.4198 (0.4131)	mem 12194MB
Train: [19/300][700/971]	eta 0:01:43 lr 0.000001979	time 0.3470 (0.3833)	tot_loss 0.3580 (0.4131)	mem 12194MB
Train: [19/300][750/971]	eta 0:01:24 lr 0.000001979	time 0.3439 (0.3828)	tot_loss 0.4075 (0.4128)	mem 12194MB
Train: [19/300][800/971]	eta 0:01:05 lr 0.000001979	time 0.3522 (0.3822)	tot_loss 0.3920 (0.4133)	mem 12194MB
Train: [19/300][850/971]	eta 0:00:46 lr 0.000001979	time 0.3554 (0.3817)	tot_loss 0.4028 (0.4126)	mem 12194MB
Train: [19/300][900/971]	eta 0:00:27 lr 0.000001979	time 0.3421 (0.3812)	tot_loss 0.4027 (0.4127)	mem 12194MB
Train: [19/300][950/971]	eta 0:00:07 lr 0.000001978	time 0.3382 (0.3806)	tot_loss 0.3785 (0.4127)	mem 12194MB
EPOCH 19 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 44.118	
Test: [100/3923]	Acc@1: 40.594	
Test: [150/3923]	Acc@1: 42.384	
Test: [200/3923]	Acc@1: 43.532	
Test: [250/3923]	Acc@1: 44.024	
Test: [300/3923]	Acc@1: 44.518	
Test: [350/3923]	Acc@1: 45.299	
Test: [400/3923]	Acc@1: 45.387	
Test: [450/3923]	Acc@1: 45.011	
Test: [500/3923]	Acc@1: 45.010	
Test: [550/3923]	Acc@1: 45.463	
Test: [600/3923]	Acc@1: 45.674	
Test: [650/3923]	Acc@1: 46.006	
Test: [700/3923]	Acc@1: 46.434	
Test: [750/3923]	Acc@1: 46.538	
Test: [800/3923]	Acc@1: 46.816	
Test: [850/3923]	Acc@1: 46.886	
Test: [900/3923]	Acc@1: 46.670	
Test: [950/3923]	Acc@1: 46.477	
Test: [1000/3923]	Acc@1: 46.753	
Test: [1050/3923]	Acc@1: 46.670	
Test: [1100/3923]	Acc@1: 46.912	
Test: [1150/3923]	Acc@1: 47.220	
Test: [1200/3923]	Acc@1: 47.127	
Test: [1250/3923]	Acc@1: 47.202	
Test: [1300/3923]	Acc@1: 47.041	
Test: [1350/3923]	Acc@1: 46.965	
Test: [1400/3923]	Acc@1: 46.859	
Test: [1450/3923]	Acc@1: 47.037	
Test: [1500/3923]	Acc@1: 47.169	
Test: [1550/3923]	Acc@1: 47.357	
Test: [1600/3923]	Acc@1: 47.252	
Test: [1650/3923]	Acc@1: 47.153	
Test: [1700/3923]	Acc@1: 47.119	
Test: [1750/3923]	Acc@1: 47.116	
Test: [1800/3923]	Acc@1: 47.307	
Test: [1850/3923]	Acc@1: 47.245	
Test: [1900/3923]	Acc@1: 47.265	
Test: [1950/3923]	Acc@1: 47.488	
Test: [2000/3923]	Acc@1: 47.476	
Test: [2050/3923]	Acc@1: 47.343	
Test: [2100/3923]	Acc@1: 47.454	
Test: [2150/3923]	Acc@1: 47.373	
Test: [2200/3923]	Acc@1: 47.183	
Test: [2250/3923]	Acc@1: 47.423	
Test: [2300/3923]	Acc@1: 47.566	
Test: [2350/3923]	Acc@1: 47.533	
Test: [2400/3923]	Acc@1: 47.459	
Test: [2450/3923]	Acc@1: 47.552	
Test: [2500/3923]	Acc@1: 47.741	
Test: [2550/3923]	Acc@1: 47.962	
Test: [2600/3923]	Acc@1: 48.039	
Test: [2650/3923]	Acc@1: 47.944	
Test: [2700/3923]	Acc@1: 47.853	
Test: [2750/3923]	Acc@1: 47.855	
Test: [2800/3923]	Acc@1: 48.072	
Test: [2850/3923]	Acc@1: 47.948	
Test: [2900/3923]	Acc@1: 47.983	
Test: [2950/3923]	Acc@1: 48.085	
Test: [3000/3923]	Acc@1: 48.067	
Test: [3050/3923]	Acc@1: 48.050	
Test: [3100/3923]	Acc@1: 48.130	
Test: [3150/3923]	Acc@1: 48.239	
Test: [3200/3923]	Acc@1: 48.313	
Test: [3250/3923]	Acc@1: 48.216	
Test: [3300/3923]	Acc@1: 48.258	
Test: [3350/3923]	Acc@1: 48.254	
Test: [3400/3923]	Acc@1: 48.236	
Test: [3450/3923]	Acc@1: 48.247	
Test: [3500/3923]	Acc@1: 48.043	
Test: [3550/3923]	Acc@1: 48.043	
Test: [3600/3923]	Acc@1: 47.959	
Test: [3650/3923]	Acc@1: 47.891	
Test: [3700/3923]	Acc@1: 47.865	
Test: [3750/3923]	Acc@1: 47.921	
Test: [3800/3923]	Acc@1: 47.816	
Test: [3850/3923]	Acc@1: 47.780	
Test: [3900/3923]	Acc@1: 47.783	
 * Acc@1 47.808 Acc@5 94.290 UAR 34.359Accuracy of the network on the 7847 test videos: 47.8%
Max accuracy: 48.50%, Current UAR : 36.50%, Max UAR :36.96%Train: [20/300][0/971]	eta 1:12:20 lr 0.000001978	time 4.4699 (4.4699)	tot_loss 0.3944 (0.3944)	mem 12194MB
Train: [20/300][50/971]	eta 0:07:11 lr 0.000001978	time 0.3599 (0.4683)	tot_loss 0.4305 (0.4110)	mem 12194MB
Train: [20/300][100/971]	eta 0:06:06 lr 0.000001978	time 0.3593 (0.4210)	tot_loss 0.3732 (0.4131)	mem 12194MB
Train: [20/300][150/971]	eta 0:05:31 lr 0.000001978	time 0.3534 (0.4037)	tot_loss 0.3802 (0.4108)	mem 12194MB
Train: [20/300][200/971]	eta 0:05:05 lr 0.000001978	time 0.3561 (0.3960)	tot_loss 0.3937 (0.4124)	mem 12194MB
Train: [20/300][250/971]	eta 0:04:41 lr 0.000001978	time 0.3517 (0.3910)	tot_loss 0.4065 (0.4119)	mem 12194MB
Train: [20/300][300/971]	eta 0:04:20 lr 0.000001978	time 0.3643 (0.3886)	tot_loss 0.3715 (0.4113)	mem 12194MB
Train: [20/300][350/971]	eta 0:03:59 lr 0.000001978	time 0.3551 (0.3865)	tot_loss 0.4174 (0.4118)	mem 12194MB
Train: [20/300][400/971]	eta 0:03:39 lr 0.000001977	time 0.3459 (0.3845)	tot_loss 0.4564 (0.4116)	mem 12194MB
Train: [20/300][450/971]	eta 0:03:19 lr 0.000001977	time 0.3617 (0.3832)	tot_loss 0.4157 (0.4121)	mem 12194MB
Train: [20/300][500/971]	eta 0:03:00 lr 0.000001977	time 0.3549 (0.3823)	tot_loss 0.4392 (0.4121)	mem 12194MB
Train: [20/300][550/971]	eta 0:02:40 lr 0.000001977	time 0.3505 (0.3817)	tot_loss 0.3825 (0.4121)	mem 12194MB
Train: [20/300][600/971]	eta 0:02:21 lr 0.000001977	time 0.3501 (0.3810)	tot_loss 0.4450 (0.4122)	mem 12194MB
Train: [20/300][650/971]	eta 0:02:02 lr 0.000001977	time 0.3573 (0.3808)	tot_loss 0.4299 (0.4121)	mem 12194MB
Train: [20/300][700/971]	eta 0:01:43 lr 0.000001977	time 0.3490 (0.3806)	tot_loss 0.4306 (0.4123)	mem 12194MB
Train: [20/300][750/971]	eta 0:01:24 lr 0.000001977	time 0.3568 (0.3804)	tot_loss 0.3328 (0.4129)	mem 12194MB
Train: [20/300][800/971]	eta 0:01:04 lr 0.000001977	time 0.3629 (0.3800)	tot_loss 0.3721 (0.4129)	mem 12194MB
Train: [20/300][850/971]	eta 0:00:45 lr 0.000001976	time 0.3533 (0.3797)	tot_loss 0.4223 (0.4131)	mem 12194MB
Train: [20/300][900/971]	eta 0:00:26 lr 0.000001976	time 0.3571 (0.3796)	tot_loss 0.4256 (0.4125)	mem 12194MB
Train: [20/300][950/971]	eta 0:00:07 lr 0.000001976	time 0.3370 (0.3790)	tot_loss 0.4036 (0.4120)	mem 12194MB
EPOCH 20 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 53.922	
Test: [100/3923]	Acc@1: 51.980	
Test: [150/3923]	Acc@1: 50.993	
Test: [200/3923]	Acc@1: 51.244	
Test: [250/3923]	Acc@1: 50.797	
Test: [300/3923]	Acc@1: 51.329	
Test: [350/3923]	Acc@1: 51.282	
Test: [400/3923]	Acc@1: 51.122	
Test: [450/3923]	Acc@1: 51.220	
Test: [500/3923]	Acc@1: 50.699	
Test: [550/3923]	Acc@1: 49.819	
Test: [600/3923]	Acc@1: 50.749	
Test: [650/3923]	Acc@1: 50.461	
Test: [700/3923]	Acc@1: 50.143	
Test: [750/3923]	Acc@1: 50.333	
Test: [800/3923]	Acc@1: 50.562	
Test: [850/3923]	Acc@1: 50.470	
Test: [900/3923]	Acc@1: 50.388	
Test: [950/3923]	Acc@1: 50.158	
Test: [1000/3923]	Acc@1: 50.300	
Test: [1050/3923]	Acc@1: 49.810	
Test: [1100/3923]	Acc@1: 49.591	
Test: [1150/3923]	Acc@1: 49.652	
Test: [1200/3923]	Acc@1: 49.625	
Test: [1250/3923]	Acc@1: 49.520	
Test: [1300/3923]	Acc@1: 49.616	
Test: [1350/3923]	Acc@1: 49.741	
Test: [1400/3923]	Acc@1: 49.572	
Test: [1450/3923]	Acc@1: 49.931	
Test: [1500/3923]	Acc@1: 49.933	
Test: [1550/3923]	Acc@1: 49.871	
Test: [1600/3923]	Acc@1: 49.688	
Test: [1650/3923]	Acc@1: 49.637	
Test: [1700/3923]	Acc@1: 49.500	
Test: [1750/3923]	Acc@1: 49.515	
Test: [1800/3923]	Acc@1: 49.528	
Test: [1850/3923]	Acc@1: 49.541	
Test: [1900/3923]	Acc@1: 49.421	
Test: [1950/3923]	Acc@1: 49.436	
Test: [2000/3923]	Acc@1: 49.625	
Test: [2050/3923]	Acc@1: 49.707	
Test: [2100/3923]	Acc@1: 49.595	
Test: [2150/3923]	Acc@1: 49.698	
Test: [2200/3923]	Acc@1: 49.568	
Test: [2250/3923]	Acc@1: 49.622	
Test: [2300/3923]	Acc@1: 49.544	
Test: [2350/3923]	Acc@1: 49.383	
Test: [2400/3923]	Acc@1: 49.479	
Test: [2450/3923]	Acc@1: 49.368	
Test: [2500/3923]	Acc@1: 49.360	
Test: [2550/3923]	Acc@1: 49.373	
Test: [2600/3923]	Acc@1: 49.404	
Test: [2650/3923]	Acc@1: 49.491	
Test: [2700/3923]	Acc@1: 49.537	
Test: [2750/3923]	Acc@1: 49.636	
Test: [2800/3923]	Acc@1: 49.554	
Test: [2850/3923]	Acc@1: 49.562	
Test: [2900/3923]	Acc@1: 49.483	
Test: [2950/3923]	Acc@1: 49.559	
Test: [3000/3923]	Acc@1: 49.617	
Test: [3050/3923]	Acc@1: 49.558	
Test: [3100/3923]	Acc@1: 49.581	
Test: [3150/3923]	Acc@1: 49.587	
Test: [3200/3923]	Acc@1: 49.641	
Test: [3250/3923]	Acc@1: 49.585	
Test: [3300/3923]	Acc@1: 49.682	
Test: [3350/3923]	Acc@1: 49.537	
Test: [3400/3923]	Acc@1: 49.427	
Test: [3450/3923]	Acc@1: 49.363	
Test: [3500/3923]	Acc@1: 49.357	
Test: [3550/3923]	Acc@1: 49.338	
Test: [3600/3923]	Acc@1: 49.278	
Test: [3650/3923]	Acc@1: 49.315	
Test: [3700/3923]	Acc@1: 49.338	
Test: [3750/3923]	Acc@1: 49.254	
Test: [3800/3923]	Acc@1: 49.263	
Test: [3850/3923]	Acc@1: 49.130	
Test: [3900/3923]	Acc@1: 49.116	
 * Acc@1 49.044 Acc@5 94.953 UAR 37.036Accuracy of the network on the 7847 test videos: 49.0%
Max accuracy: 49.04%, Current UAR : 37.04%, Max UAR :37.04%Train: [21/300][0/971]	eta 1:15:07 lr 0.000001976	time 4.6424 (4.6424)	tot_loss 0.4448 (0.4448)	mem 12194MB
Train: [21/300][50/971]	eta 0:07:07 lr 0.000001976	time 0.3565 (0.4640)	tot_loss 0.4387 (0.4124)	mem 12194MB
Train: [21/300][100/971]	eta 0:06:05 lr 0.000001976	time 0.3491 (0.4199)	tot_loss 0.3869 (0.4136)	mem 12194MB
Train: [21/300][150/971]	eta 0:05:33 lr 0.000001976	time 0.5459 (0.4063)	tot_loss 0.3347 (0.4121)	mem 12194MB
Train: [21/300][200/971]	eta 0:05:07 lr 0.000001976	time 0.3519 (0.3987)	tot_loss 0.3834 (0.4133)	mem 12194MB
Train: [21/300][250/971]	eta 0:04:43 lr 0.000001976	time 0.3498 (0.3939)	tot_loss 0.4128 (0.4134)	mem 12194MB
Train: [21/300][300/971]	eta 0:04:21 lr 0.000001975	time 0.3612 (0.3902)	tot_loss 0.3733 (0.4127)	mem 12194MB
Train: [21/300][350/971]	eta 0:04:00 lr 0.000001975	time 0.3554 (0.3880)	tot_loss 0.4271 (0.4127)	mem 12194MB
Train: [21/300][400/971]	eta 0:03:40 lr 0.000001975	time 0.3614 (0.3865)	tot_loss 0.4366 (0.4124)	mem 12194MB
Train: [21/300][450/971]	eta 0:03:20 lr 0.000001975	time 0.3457 (0.3852)	tot_loss 0.4254 (0.4126)	mem 12194MB
Train: [21/300][500/971]	eta 0:03:00 lr 0.000001975	time 0.3483 (0.3842)	tot_loss 0.3308 (0.4122)	mem 12194MB
Train: [21/300][550/971]	eta 0:02:41 lr 0.000001975	time 0.3509 (0.3833)	tot_loss 0.3933 (0.4121)	mem 12194MB
Train: [21/300][600/971]	eta 0:02:21 lr 0.000001975	time 0.3550 (0.3826)	tot_loss 0.4514 (0.4122)	mem 12194MB
Train: [21/300][650/971]	eta 0:02:02 lr 0.000001975	time 0.3507 (0.3822)	tot_loss 0.4159 (0.4119)	mem 12194MB
Train: [21/300][700/971]	eta 0:01:43 lr 0.000001975	time 0.3500 (0.3814)	tot_loss 0.4220 (0.4123)	mem 12194MB
Train: [21/300][750/971]	eta 0:01:24 lr 0.000001974	time 0.3502 (0.3811)	tot_loss 0.3642 (0.4121)	mem 12194MB
Train: [21/300][800/971]	eta 0:01:05 lr 0.000001974	time 0.3650 (0.3808)	tot_loss 0.3938 (0.4123)	mem 12194MB
Train: [21/300][850/971]	eta 0:00:46 lr 0.000001974	time 0.3653 (0.3805)	tot_loss 0.3727 (0.4125)	mem 12194MB
Train: [21/300][900/971]	eta 0:00:26 lr 0.000001974	time 0.3432 (0.3802)	tot_loss 0.4032 (0.4122)	mem 12194MB
Train: [21/300][950/971]	eta 0:00:07 lr 0.000001974	time 0.3331 (0.3797)	tot_loss 0.3558 (0.4119)	mem 12194MB
EPOCH 21 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 47.030	
Test: [150/3923]	Acc@1: 46.689	
Test: [200/3923]	Acc@1: 49.751	
Test: [250/3923]	Acc@1: 48.606	
Test: [300/3923]	Acc@1: 49.502	
Test: [350/3923]	Acc@1: 49.003	
Test: [400/3923]	Acc@1: 48.878	
Test: [450/3923]	Acc@1: 47.783	
Test: [500/3923]	Acc@1: 48.004	
Test: [550/3923]	Acc@1: 48.185	
Test: [600/3923]	Acc@1: 47.837	
Test: [650/3923]	Acc@1: 47.773	
Test: [700/3923]	Acc@1: 47.860	
Test: [750/3923]	Acc@1: 48.069	
Test: [800/3923]	Acc@1: 48.002	
Test: [850/3923]	Acc@1: 47.591	
Test: [900/3923]	Acc@1: 47.447	
Test: [950/3923]	Acc@1: 47.424	
Test: [1000/3923]	Acc@1: 47.552	
Test: [1050/3923]	Acc@1: 47.098	
Test: [1100/3923]	Acc@1: 46.821	
Test: [1150/3923]	Acc@1: 46.742	
Test: [1200/3923]	Acc@1: 46.628	
Test: [1250/3923]	Acc@1: 46.962	
Test: [1300/3923]	Acc@1: 47.118	
Test: [1350/3923]	Acc@1: 47.002	
Test: [1400/3923]	Acc@1: 46.824	
Test: [1450/3923]	Acc@1: 46.795	
Test: [1500/3923]	Acc@1: 46.835	
Test: [1550/3923]	Acc@1: 46.744	
Test: [1600/3923]	Acc@1: 46.939	
Test: [1650/3923]	Acc@1: 47.093	
Test: [1700/3923]	Acc@1: 46.943	
Test: [1750/3923]	Acc@1: 46.916	
Test: [1800/3923]	Acc@1: 46.974	
Test: [1850/3923]	Acc@1: 46.759	
Test: [1900/3923]	Acc@1: 46.817	
Test: [1950/3923]	Acc@1: 46.720	
Test: [2000/3923]	Acc@1: 46.627	
Test: [2050/3923]	Acc@1: 46.880	
Test: [2100/3923]	Acc@1: 46.835	
Test: [2150/3923]	Acc@1: 46.769	
Test: [2200/3923]	Acc@1: 46.933	
Test: [2250/3923]	Acc@1: 46.957	
Test: [2300/3923]	Acc@1: 47.197	
Test: [2350/3923]	Acc@1: 47.214	
Test: [2400/3923]	Acc@1: 47.209	
Test: [2450/3923]	Acc@1: 47.348	
Test: [2500/3923]	Acc@1: 47.501	
Test: [2550/3923]	Acc@1: 47.393	
Test: [2600/3923]	Acc@1: 47.251	
Test: [2650/3923]	Acc@1: 47.378	
Test: [2700/3923]	Acc@1: 47.501	
Test: [2750/3923]	Acc@1: 47.601	
Test: [2800/3923]	Acc@1: 47.537	
Test: [2850/3923]	Acc@1: 47.562	
Test: [2900/3923]	Acc@1: 47.535	
Test: [2950/3923]	Acc@1: 47.560	
Test: [3000/3923]	Acc@1: 47.701	
Test: [3050/3923]	Acc@1: 47.689	
Test: [3100/3923]	Acc@1: 47.565	
Test: [3150/3923]	Acc@1: 47.493	
Test: [3200/3923]	Acc@1: 47.391	
Test: [3250/3923]	Acc@1: 47.508	
Test: [3300/3923]	Acc@1: 47.546	
Test: [3350/3923]	Acc@1: 47.434	
Test: [3400/3923]	Acc@1: 47.530	
Test: [3450/3923]	Acc@1: 47.537	
Test: [3500/3923]	Acc@1: 47.458	
Test: [3550/3923]	Acc@1: 47.508	
Test: [3600/3923]	Acc@1: 47.473	
Test: [3650/3923]	Acc@1: 47.439	
Test: [3700/3923]	Acc@1: 47.433	
Test: [3750/3923]	Acc@1: 47.427	
Test: [3800/3923]	Acc@1: 47.488	
Test: [3850/3923]	Acc@1: 47.520	
Test: [3900/3923]	Acc@1: 47.526	
 * Acc@1 47.413 Acc@5 94.328 UAR 36.956Accuracy of the network on the 7847 test videos: 47.4%
Max accuracy: 49.04%, Current UAR : 37.04%, Max UAR :37.04%Train: [22/300][0/971]	eta 1:09:49 lr 0.000001974	time 4.3144 (4.3144)	tot_loss 0.4247 (0.4247)	mem 12194MB
Train: [22/300][50/971]	eta 0:07:13 lr 0.000001974	time 0.3529 (0.4705)	tot_loss 0.4265 (0.4113)	mem 12194MB
Train: [22/300][100/971]	eta 0:06:08 lr 0.000001974	time 0.3775 (0.4228)	tot_loss 0.3809 (0.4080)	mem 12194MB
Train: [22/300][150/971]	eta 0:05:35 lr 0.000001973	time 0.3538 (0.4087)	tot_loss 0.4288 (0.4084)	mem 12194MB
Train: [22/300][200/971]	eta 0:05:09 lr 0.000001973	time 0.3643 (0.4014)	tot_loss 0.4126 (0.4079)	mem 12194MB
Train: [22/300][250/971]	eta 0:04:45 lr 0.000001973	time 0.3627 (0.3954)	tot_loss 0.4305 (0.4085)	mem 12194MB
Train: [22/300][300/971]	eta 0:04:22 lr 0.000001973	time 0.3657 (0.3913)	tot_loss 0.4100 (0.4088)	mem 12194MB
Train: [22/300][350/971]	eta 0:04:04 lr 0.000001973	time 0.3875 (0.3934)	tot_loss 0.4596 (0.4107)	mem 12194MB
Train: [22/300][400/971]	eta 0:03:43 lr 0.000001973	time 0.3777 (0.3917)	tot_loss 0.4432 (0.4112)	mem 12194MB
Train: [22/300][450/971]	eta 0:03:23 lr 0.000001973	time 0.3521 (0.3912)	tot_loss 0.4233 (0.4111)	mem 12194MB
Train: [22/300][500/971]	eta 0:03:04 lr 0.000001973	time 0.3557 (0.3908)	tot_loss 0.4206 (0.4115)	mem 12194MB
Train: [22/300][550/971]	eta 0:02:43 lr 0.000001972	time 0.3501 (0.3895)	tot_loss 0.4061 (0.4110)	mem 12194MB
Train: [22/300][600/971]	eta 0:02:23 lr 0.000001972	time 0.3489 (0.3880)	tot_loss 0.4483 (0.4106)	mem 12194MB
Train: [22/300][650/971]	eta 0:02:04 lr 0.000001972	time 0.3682 (0.3872)	tot_loss 0.4174 (0.4102)	mem 12194MB
Train: [22/300][700/971]	eta 0:01:45 lr 0.000001972	time 0.3568 (0.3878)	tot_loss 0.4615 (0.4107)	mem 12194MB
Train: [22/300][750/971]	eta 0:01:25 lr 0.000001972	time 0.3525 (0.3867)	tot_loss 0.4235 (0.4104)	mem 12194MB
Train: [22/300][800/971]	eta 0:01:06 lr 0.000001972	time 0.3568 (0.3863)	tot_loss 0.3848 (0.4104)	mem 12194MB
Train: [22/300][850/971]	eta 0:00:46 lr 0.000001972	time 0.3514 (0.3854)	tot_loss 0.4189 (0.4097)	mem 12194MB
Train: [22/300][900/971]	eta 0:00:27 lr 0.000001972	time 0.3539 (0.3845)	tot_loss 0.3976 (0.4100)	mem 12194MB
Train: [22/300][950/971]	eta 0:00:08 lr 0.000001971	time 0.3352 (0.3835)	tot_loss 0.3691 (0.4103)	mem 12194MB
EPOCH 22 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 44.118	
Test: [100/3923]	Acc@1: 46.535	
Test: [150/3923]	Acc@1: 47.020	
Test: [200/3923]	Acc@1: 48.259	
Test: [250/3923]	Acc@1: 47.809	
Test: [300/3923]	Acc@1: 46.678	
Test: [350/3923]	Acc@1: 47.151	
Test: [400/3923]	Acc@1: 46.509	
Test: [450/3923]	Acc@1: 46.563	
Test: [500/3923]	Acc@1: 47.405	
Test: [550/3923]	Acc@1: 47.187	
Test: [600/3923]	Acc@1: 47.255	
Test: [650/3923]	Acc@1: 47.849	
Test: [700/3923]	Acc@1: 48.146	
Test: [750/3923]	Acc@1: 47.870	
Test: [800/3923]	Acc@1: 48.065	
Test: [850/3923]	Acc@1: 47.532	
Test: [900/3923]	Acc@1: 47.669	
Test: [950/3923]	Acc@1: 48.002	
Test: [1000/3923]	Acc@1: 47.852	
Test: [1050/3923]	Acc@1: 47.669	
Test: [1100/3923]	Acc@1: 47.911	
Test: [1150/3923]	Acc@1: 47.828	
Test: [1200/3923]	Acc@1: 47.877	
Test: [1250/3923]	Acc@1: 48.042	
Test: [1300/3923]	Acc@1: 48.002	
Test: [1350/3923]	Acc@1: 47.742	
Test: [1400/3923]	Acc@1: 47.680	
Test: [1450/3923]	Acc@1: 47.726	
Test: [1500/3923]	Acc@1: 47.735	
Test: [1550/3923]	Acc@1: 47.840	
Test: [1600/3923]	Acc@1: 47.720	
Test: [1650/3923]	Acc@1: 47.941	
Test: [1700/3923]	Acc@1: 48.119	
Test: [1750/3923]	Acc@1: 48.115	
Test: [1800/3923]	Acc@1: 48.140	
Test: [1850/3923]	Acc@1: 48.190	
Test: [1900/3923]	Acc@1: 48.211	
Test: [1950/3923]	Acc@1: 48.206	
Test: [2000/3923]	Acc@1: 48.226	
Test: [2050/3923]	Acc@1: 48.220	
Test: [2100/3923]	Acc@1: 48.168	
Test: [2150/3923]	Acc@1: 48.233	
Test: [2200/3923]	Acc@1: 48.296	
Test: [2250/3923]	Acc@1: 48.356	
Test: [2300/3923]	Acc@1: 48.501	
Test: [2350/3923]	Acc@1: 48.447	
Test: [2400/3923]	Acc@1: 48.501	
Test: [2450/3923]	Acc@1: 48.592	
Test: [2500/3923]	Acc@1: 48.641	
Test: [2550/3923]	Acc@1: 48.706	
Test: [2600/3923]	Acc@1: 48.731	
Test: [2650/3923]	Acc@1: 48.680	
Test: [2700/3923]	Acc@1: 48.834	
Test: [2750/3923]	Acc@1: 48.819	
Test: [2800/3923]	Acc@1: 48.768	
Test: [2850/3923]	Acc@1: 48.685	
Test: [2900/3923]	Acc@1: 48.604	
Test: [2950/3923]	Acc@1: 48.543	
Test: [3000/3923]	Acc@1: 48.434	
Test: [3050/3923]	Acc@1: 48.460	
Test: [3100/3923]	Acc@1: 48.436	
Test: [3150/3923]	Acc@1: 48.445	
Test: [3200/3923]	Acc@1: 48.376	
Test: [3250/3923]	Acc@1: 48.339	
Test: [3300/3923]	Acc@1: 48.516	
Test: [3350/3923]	Acc@1: 48.493	
Test: [3400/3923]	Acc@1: 48.383	
Test: [3450/3923]	Acc@1: 48.392	
Test: [3500/3923]	Acc@1: 48.329	
Test: [3550/3923]	Acc@1: 48.296	
Test: [3600/3923]	Acc@1: 48.306	
Test: [3650/3923]	Acc@1: 48.384	
Test: [3700/3923]	Acc@1: 48.392	
Test: [3750/3923]	Acc@1: 48.374	
Test: [3800/3923]	Acc@1: 48.395	
Test: [3850/3923]	Acc@1: 48.429	
Test: [3900/3923]	Acc@1: 48.436	
 * Acc@1 48.445 Acc@5 94.660 UAR 38.752Accuracy of the network on the 7847 test videos: 48.4%
Max accuracy: 49.04%, Current UAR : 37.04%, Max UAR :38.75%Train: [23/300][0/971]	eta 1:11:09 lr 0.000001971	time 4.3969 (4.3969)	tot_loss 0.4114 (0.4114)	mem 12194MB
Train: [23/300][50/971]	eta 0:07:13 lr 0.000001971	time 0.3548 (0.4704)	tot_loss 0.4510 (0.4115)	mem 12194MB
Train: [23/300][100/971]	eta 0:06:06 lr 0.000001971	time 0.3657 (0.4212)	tot_loss 0.4200 (0.4080)	mem 12194MB
Train: [23/300][150/971]	eta 0:05:33 lr 0.000001971	time 0.3504 (0.4065)	tot_loss 0.3909 (0.4073)	mem 12194MB
Train: [23/300][200/971]	eta 0:05:08 lr 0.000001971	time 0.3700 (0.3999)	tot_loss 0.3485 (0.4088)	mem 12194MB
Train: [23/300][250/971]	eta 0:04:44 lr 0.000001971	time 0.3428 (0.3945)	tot_loss 0.3846 (0.4093)	mem 12194MB
Train: [23/300][300/971]	eta 0:04:22 lr 0.000001971	time 0.3532 (0.3915)	tot_loss 0.4127 (0.4095)	mem 12194MB
Train: [23/300][350/971]	eta 0:04:01 lr 0.000001971	time 0.3556 (0.3885)	tot_loss 0.4320 (0.4100)	mem 12194MB
Train: [23/300][400/971]	eta 0:03:40 lr 0.000001970	time 0.3820 (0.3865)	tot_loss 0.4723 (0.4112)	mem 12194MB
Train: [23/300][450/971]	eta 0:03:20 lr 0.000001970	time 0.3889 (0.3858)	tot_loss 0.3782 (0.4106)	mem 12194MB
Train: [23/300][500/971]	eta 0:03:01 lr 0.000001970	time 0.3771 (0.3852)	tot_loss 0.3559 (0.4098)	mem 12194MB
Train: [23/300][550/971]	eta 0:02:41 lr 0.000001970	time 0.3584 (0.3842)	tot_loss 0.4234 (0.4091)	mem 12194MB
Train: [23/300][600/971]	eta 0:02:22 lr 0.000001970	time 0.3540 (0.3829)	tot_loss 0.4532 (0.4090)	mem 12194MB
Train: [23/300][650/971]	eta 0:02:02 lr 0.000001970	time 0.3839 (0.3825)	tot_loss 0.4400 (0.4096)	mem 12194MB
Train: [23/300][700/971]	eta 0:01:43 lr 0.000001970	time 0.3609 (0.3823)	tot_loss 0.4334 (0.4098)	mem 12194MB
Train: [23/300][750/971]	eta 0:01:24 lr 0.000001969	time 0.3563 (0.3814)	tot_loss 0.4278 (0.4095)	mem 12194MB
Train: [23/300][800/971]	eta 0:01:05 lr 0.000001969	time 0.3699 (0.3809)	tot_loss 0.4417 (0.4094)	mem 12194MB
Train: [23/300][850/971]	eta 0:00:46 lr 0.000001969	time 0.3566 (0.3805)	tot_loss 0.4090 (0.4089)	mem 12194MB
Train: [23/300][900/971]	eta 0:00:26 lr 0.000001969	time 0.3506 (0.3799)	tot_loss 0.4324 (0.4085)	mem 12194MB
Train: [23/300][950/971]	eta 0:00:07 lr 0.000001969	time 0.3269 (0.3791)	tot_loss 0.3318 (0.4087)	mem 12194MB
EPOCH 23 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 52.941	
Test: [100/3923]	Acc@1: 52.970	
Test: [150/3923]	Acc@1: 50.993	
Test: [200/3923]	Acc@1: 50.746	
Test: [250/3923]	Acc@1: 50.000	
Test: [300/3923]	Acc@1: 51.163	
Test: [350/3923]	Acc@1: 50.570	
Test: [400/3923]	Acc@1: 50.125	
Test: [450/3923]	Acc@1: 49.557	
Test: [500/3923]	Acc@1: 49.401	
Test: [550/3923]	Acc@1: 49.183	
Test: [600/3923]	Acc@1: 49.085	
Test: [650/3923]	Acc@1: 49.309	
Test: [700/3923]	Acc@1: 49.643	
Test: [750/3923]	Acc@1: 49.467	
Test: [800/3923]	Acc@1: 49.813	
Test: [850/3923]	Acc@1: 49.530	
Test: [900/3923]	Acc@1: 49.501	
Test: [950/3923]	Acc@1: 50.105	
Test: [1000/3923]	Acc@1: 50.300	
Test: [1050/3923]	Acc@1: 50.381	
Test: [1100/3923]	Acc@1: 50.454	
Test: [1150/3923]	Acc@1: 50.130	
Test: [1200/3923]	Acc@1: 49.792	
Test: [1250/3923]	Acc@1: 49.640	
Test: [1300/3923]	Acc@1: 49.769	
Test: [1350/3923]	Acc@1: 49.556	
Test: [1400/3923]	Acc@1: 49.536	
Test: [1450/3923]	Acc@1: 49.518	
Test: [1500/3923]	Acc@1: 49.300	
Test: [1550/3923]	Acc@1: 49.484	
Test: [1600/3923]	Acc@1: 49.469	
Test: [1650/3923]	Acc@1: 49.637	
Test: [1700/3923]	Acc@1: 49.530	
Test: [1750/3923]	Acc@1: 49.543	
Test: [1800/3923]	Acc@1: 49.528	
Test: [1850/3923]	Acc@1: 49.784	
Test: [1900/3923]	Acc@1: 50.026	
Test: [1950/3923]	Acc@1: 49.897	
Test: [2000/3923]	Acc@1: 50.100	
Test: [2050/3923]	Acc@1: 50.268	
Test: [2100/3923]	Acc@1: 50.238	
Test: [2150/3923]	Acc@1: 50.279	
Test: [2200/3923]	Acc@1: 50.227	
Test: [2250/3923]	Acc@1: 50.311	
Test: [2300/3923]	Acc@1: 50.478	
Test: [2350/3923]	Acc@1: 50.553	
Test: [2400/3923]	Acc@1: 50.500	
Test: [2450/3923]	Acc@1: 50.265	
Test: [2500/3923]	Acc@1: 50.180	
Test: [2550/3923]	Acc@1: 50.235	
Test: [2600/3923]	Acc@1: 50.173	
Test: [2650/3923]	Acc@1: 50.132	
Test: [2700/3923]	Acc@1: 50.074	
Test: [2750/3923]	Acc@1: 50.091	
Test: [2800/3923]	Acc@1: 50.089	
Test: [2850/3923]	Acc@1: 50.123	
Test: [2900/3923]	Acc@1: 50.000	
Test: [2950/3923]	Acc@1: 50.000	
Test: [3000/3923]	Acc@1: 49.950	
Test: [3050/3923]	Acc@1: 49.803	
Test: [3100/3923]	Acc@1: 49.726	
Test: [3150/3923]	Acc@1: 49.730	
Test: [3200/3923]	Acc@1: 49.656	
Test: [3250/3923]	Acc@1: 49.539	
Test: [3300/3923]	Acc@1: 49.515	
Test: [3350/3923]	Acc@1: 49.403	
Test: [3400/3923]	Acc@1: 49.383	
Test: [3450/3923]	Acc@1: 49.464	
Test: [3500/3923]	Acc@1: 49.529	
Test: [3550/3923]	Acc@1: 49.479	
Test: [3600/3923]	Acc@1: 49.445	
Test: [3650/3923]	Acc@1: 49.507	
Test: [3700/3923]	Acc@1: 49.433	
Test: [3750/3923]	Acc@1: 49.387	
Test: [3800/3923]	Acc@1: 49.500	
Test: [3850/3923]	Acc@1: 49.442	
Test: [3900/3923]	Acc@1: 49.449	
 * Acc@1 49.439 Acc@5 94.762 UAR 38.586Accuracy of the network on the 7847 test videos: 49.4%
Max accuracy: 49.44%, Current UAR : 38.59%, Max UAR :38.75%Train: [24/300][0/971]	eta 1:23:27 lr 0.000001969	time 5.1567 (5.1567)	tot_loss 0.4331 (0.4331)	mem 12194MB
Train: [24/300][50/971]	eta 0:07:02 lr 0.000001969	time 0.3381 (0.4592)	tot_loss 0.4039 (0.4136)	mem 12194MB
Train: [24/300][100/971]	eta 0:06:06 lr 0.000001969	time 0.3670 (0.4212)	tot_loss 0.4120 (0.4139)	mem 12194MB
Train: [24/300][150/971]	eta 0:05:31 lr 0.000001969	time 0.3526 (0.4034)	tot_loss 0.3503 (0.4112)	mem 12194MB
Train: [24/300][200/971]	eta 0:05:04 lr 0.000001968	time 0.3549 (0.3955)	tot_loss 0.3965 (0.4104)	mem 12194MB
Train: [24/300][250/971]	eta 0:04:41 lr 0.000001968	time 0.3560 (0.3902)	tot_loss 0.4006 (0.4089)	mem 12194MB
Train: [24/300][300/971]	eta 0:04:19 lr 0.000001968	time 0.3477 (0.3875)	tot_loss 0.3594 (0.4083)	mem 12194MB
Train: [24/300][350/971]	eta 0:03:58 lr 0.000001968	time 0.3615 (0.3844)	tot_loss 0.4245 (0.4081)	mem 12194MB
Train: [24/300][400/971]	eta 0:03:39 lr 0.000001968	time 0.3491 (0.3847)	tot_loss 0.4470 (0.4087)	mem 12194MB
Train: [24/300][450/971]	eta 0:03:19 lr 0.000001968	time 0.3638 (0.3838)	tot_loss 0.3567 (0.4082)	mem 12194MB
Train: [24/300][500/971]	eta 0:03:00 lr 0.000001968	time 0.3702 (0.3829)	tot_loss 0.3845 (0.4084)	mem 12194MB
Train: [24/300][550/971]	eta 0:02:40 lr 0.000001967	time 0.3476 (0.3816)	tot_loss 0.3851 (0.4082)	mem 12194MB
Train: [24/300][600/971]	eta 0:02:21 lr 0.000001967	time 0.3512 (0.3805)	tot_loss 0.3443 (0.4075)	mem 12194MB
Train: [24/300][650/971]	eta 0:02:01 lr 0.000001967	time 0.3527 (0.3798)	tot_loss 0.3801 (0.4079)	mem 12194MB
Train: [24/300][700/971]	eta 0:01:42 lr 0.000001967	time 0.3496 (0.3789)	tot_loss 0.3819 (0.4077)	mem 12194MB
Train: [24/300][750/971]	eta 0:01:23 lr 0.000001967	time 0.3472 (0.3780)	tot_loss 0.3858 (0.4075)	mem 12194MB
Train: [24/300][800/971]	eta 0:01:04 lr 0.000001967	time 0.3475 (0.3776)	tot_loss 0.4176 (0.4077)	mem 12194MB
Train: [24/300][850/971]	eta 0:00:45 lr 0.000001967	time 0.3523 (0.3769)	tot_loss 0.4096 (0.4080)	mem 12194MB
Train: [24/300][900/971]	eta 0:00:26 lr 0.000001966	time 0.3528 (0.3765)	tot_loss 0.4490 (0.4087)	mem 12194MB
Train: [24/300][950/971]	eta 0:00:07 lr 0.000001966	time 0.3338 (0.3760)	tot_loss 0.4520 (0.4091)	mem 12194MB
EPOCH 24 training takes 0:06:04
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 54.902	
Test: [100/3923]	Acc@1: 49.010	
Test: [150/3923]	Acc@1: 50.662	
Test: [200/3923]	Acc@1: 50.498	
Test: [250/3923]	Acc@1: 51.394	
Test: [300/3923]	Acc@1: 49.668	
Test: [350/3923]	Acc@1: 49.715	
Test: [400/3923]	Acc@1: 50.249	
Test: [450/3923]	Acc@1: 50.111	
Test: [500/3923]	Acc@1: 49.900	
Test: [550/3923]	Acc@1: 50.181	
Test: [600/3923]	Acc@1: 50.416	
Test: [650/3923]	Acc@1: 50.307	
Test: [700/3923]	Acc@1: 50.285	
Test: [750/3923]	Acc@1: 49.867	
Test: [800/3923]	Acc@1: 49.750	
Test: [850/3923]	Acc@1: 49.706	
Test: [900/3923]	Acc@1: 49.168	
Test: [950/3923]	Acc@1: 48.738	
Test: [1000/3923]	Acc@1: 49.051	
Test: [1050/3923]	Acc@1: 49.096	
Test: [1100/3923]	Acc@1: 49.001	
Test: [1150/3923]	Acc@1: 49.001	
Test: [1200/3923]	Acc@1: 49.167	
Test: [1250/3923]	Acc@1: 49.161	
Test: [1300/3923]	Acc@1: 49.231	
Test: [1350/3923]	Acc@1: 49.445	
Test: [1400/3923]	Acc@1: 49.857	
Test: [1450/3923]	Acc@1: 49.759	
Test: [1500/3923]	Acc@1: 49.467	
Test: [1550/3923]	Acc@1: 49.645	
Test: [1600/3923]	Acc@1: 49.438	
Test: [1650/3923]	Acc@1: 49.455	
Test: [1700/3923]	Acc@1: 49.265	
Test: [1750/3923]	Acc@1: 49.315	
Test: [1800/3923]	Acc@1: 49.417	
Test: [1850/3923]	Acc@1: 49.298	
Test: [1900/3923]	Acc@1: 49.369	
Test: [1950/3923]	Acc@1: 49.359	
Test: [2000/3923]	Acc@1: 49.275	
Test: [2050/3923]	Acc@1: 49.171	
Test: [2100/3923]	Acc@1: 49.191	
Test: [2150/3923]	Acc@1: 49.256	
Test: [2200/3923]	Acc@1: 49.137	
Test: [2250/3923]	Acc@1: 49.267	
Test: [2300/3923]	Acc@1: 49.239	
Test: [2350/3923]	Acc@1: 49.213	
Test: [2400/3923]	Acc@1: 49.146	
Test: [2450/3923]	Acc@1: 49.347	
Test: [2500/3923]	Acc@1: 49.380	
Test: [2550/3923]	Acc@1: 49.255	
Test: [2600/3923]	Acc@1: 49.173	
Test: [2650/3923]	Acc@1: 49.132	
Test: [2700/3923]	Acc@1: 48.945	
Test: [2750/3923]	Acc@1: 49.000	
Test: [2800/3923]	Acc@1: 48.893	
Test: [2850/3923]	Acc@1: 48.860	
Test: [2900/3923]	Acc@1: 48.880	
Test: [2950/3923]	Acc@1: 48.899	
Test: [3000/3923]	Acc@1: 48.867	
Test: [3050/3923]	Acc@1: 48.853	
Test: [3100/3923]	Acc@1: 48.791	
Test: [3150/3923]	Acc@1: 48.810	
Test: [3200/3923]	Acc@1: 48.766	
Test: [3250/3923]	Acc@1: 48.877	
Test: [3300/3923]	Acc@1: 48.849	
Test: [3350/3923]	Acc@1: 48.941	
Test: [3400/3923]	Acc@1: 48.868	
Test: [3450/3923]	Acc@1: 48.826	
Test: [3500/3923]	Acc@1: 48.829	
Test: [3550/3923]	Acc@1: 48.930	
Test: [3600/3923]	Acc@1: 48.959	
Test: [3650/3923]	Acc@1: 48.945	
Test: [3700/3923]	Acc@1: 49.000	
Test: [3750/3923]	Acc@1: 49.067	
Test: [3800/3923]	Acc@1: 49.013	
Test: [3850/3923]	Acc@1: 49.013	
Test: [3900/3923]	Acc@1: 48.987	
 * Acc@1 49.070 Acc@5 94.723 UAR 38.511Accuracy of the network on the 7847 test videos: 49.1%
Max accuracy: 49.44%, Current UAR : 38.59%, Max UAR :38.75%Train: [25/300][0/971]	eta 1:22:09 lr 0.000001966	time 5.0765 (5.0765)	tot_loss 0.3894 (0.3894)	mem 12194MB
Train: [25/300][50/971]	eta 0:07:14 lr 0.000001966	time 0.3494 (0.4713)	tot_loss 0.4490 (0.4049)	mem 12194MB
Train: [25/300][100/971]	eta 0:06:09 lr 0.000001966	time 0.3549 (0.4246)	tot_loss 0.4629 (0.4031)	mem 12194MB
Train: [25/300][150/971]	eta 0:05:35 lr 0.000001966	time 0.3623 (0.4086)	tot_loss 0.3802 (0.4025)	mem 12194MB
Train: [25/300][200/971]	eta 0:05:08 lr 0.000001966	time 0.3543 (0.3996)	tot_loss 0.4640 (0.4043)	mem 12194MB
Train: [25/300][250/971]	eta 0:04:44 lr 0.000001966	time 0.3879 (0.3951)	tot_loss 0.4355 (0.4055)	mem 12194MB
Train: [25/300][300/971]	eta 0:04:22 lr 0.000001965	time 0.3660 (0.3915)	tot_loss 0.3880 (0.4045)	mem 12194MB
Train: [25/300][350/971]	eta 0:04:01 lr 0.000001965	time 0.3503 (0.3890)	tot_loss 0.4081 (0.4041)	mem 12194MB
Train: [25/300][400/971]	eta 0:03:41 lr 0.000001965	time 0.3609 (0.3871)	tot_loss 0.3815 (0.4053)	mem 12194MB
Train: [25/300][450/971]	eta 0:03:21 lr 0.000001965	time 0.3508 (0.3858)	tot_loss 0.4663 (0.4071)	mem 12194MB
Train: [25/300][500/971]	eta 0:03:01 lr 0.000001965	time 0.3467 (0.3850)	tot_loss 0.3389 (0.4070)	mem 12194MB
Train: [25/300][550/971]	eta 0:02:41 lr 0.000001965	time 0.3542 (0.3839)	tot_loss 0.4438 (0.4066)	mem 12194MB
Train: [25/300][600/971]	eta 0:02:22 lr 0.000001965	time 0.3670 (0.3833)	tot_loss 0.4369 (0.4075)	mem 12194MB
Train: [25/300][650/971]	eta 0:02:02 lr 0.000001964	time 0.3504 (0.3828)	tot_loss 0.4058 (0.4081)	mem 12194MB
Train: [25/300][700/971]	eta 0:01:43 lr 0.000001964	time 0.3535 (0.3819)	tot_loss 0.4134 (0.4086)	mem 12194MB
Train: [25/300][750/971]	eta 0:01:24 lr 0.000001964	time 0.3545 (0.3809)	tot_loss 0.3862 (0.4077)	mem 12194MB
Train: [25/300][800/971]	eta 0:01:05 lr 0.000001964	time 0.3534 (0.3804)	tot_loss 0.3861 (0.4079)	mem 12198MB
Train: [25/300][850/971]	eta 0:00:46 lr 0.000001964	time 0.3763 (0.3803)	tot_loss 0.4069 (0.4083)	mem 12198MB
Train: [25/300][900/971]	eta 0:00:27 lr 0.000001964	time 0.3684 (0.3815)	tot_loss 0.4735 (0.4083)	mem 12198MB
Train: [25/300][950/971]	eta 0:00:07 lr 0.000001964	time 0.3393 (0.3807)	tot_loss 0.4259 (0.4084)	mem 12198MB
EPOCH 25 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 37.255	
Test: [100/3923]	Acc@1: 41.089	
Test: [150/3923]	Acc@1: 41.060	
Test: [200/3923]	Acc@1: 43.781	
Test: [250/3923]	Acc@1: 45.418	
Test: [300/3923]	Acc@1: 46.346	
Test: [350/3923]	Acc@1: 46.866	
Test: [400/3923]	Acc@1: 47.756	
Test: [450/3923]	Acc@1: 47.450	
Test: [500/3923]	Acc@1: 47.305	
Test: [550/3923]	Acc@1: 48.457	
Test: [600/3923]	Acc@1: 48.835	
Test: [650/3923]	Acc@1: 48.694	
Test: [700/3923]	Acc@1: 48.859	
Test: [750/3923]	Acc@1: 48.735	
Test: [800/3923]	Acc@1: 48.377	
Test: [850/3923]	Acc@1: 48.061	
Test: [900/3923]	Acc@1: 47.947	
Test: [950/3923]	Acc@1: 47.634	
Test: [1000/3923]	Acc@1: 47.403	
Test: [1050/3923]	Acc@1: 47.907	
Test: [1100/3923]	Acc@1: 47.775	
Test: [1150/3923]	Acc@1: 47.741	
Test: [1200/3923]	Acc@1: 47.877	
Test: [1250/3923]	Acc@1: 48.201	
Test: [1300/3923]	Acc@1: 48.501	
Test: [1350/3923]	Acc@1: 48.483	
Test: [1400/3923]	Acc@1: 48.715	
Test: [1450/3923]	Acc@1: 48.553	
Test: [1500/3923]	Acc@1: 48.468	
Test: [1550/3923]	Acc@1: 48.839	
Test: [1600/3923]	Acc@1: 48.907	
Test: [1650/3923]	Acc@1: 49.122	
Test: [1700/3923]	Acc@1: 49.118	
Test: [1750/3923]	Acc@1: 49.058	
Test: [1800/3923]	Acc@1: 49.223	
Test: [1850/3923]	Acc@1: 49.433	
Test: [1900/3923]	Acc@1: 49.553	
Test: [1950/3923]	Acc@1: 49.692	
Test: [2000/3923]	Acc@1: 49.625	
Test: [2050/3923]	Acc@1: 49.537	
Test: [2100/3923]	Acc@1: 49.524	
Test: [2150/3923]	Acc@1: 49.628	
Test: [2200/3923]	Acc@1: 49.455	
Test: [2250/3923]	Acc@1: 49.311	
Test: [2300/3923]	Acc@1: 49.261	
Test: [2350/3923]	Acc@1: 49.277	
Test: [2400/3923]	Acc@1: 49.188	
Test: [2450/3923]	Acc@1: 49.143	
Test: [2500/3923]	Acc@1: 49.160	
Test: [2550/3923]	Acc@1: 49.040	
Test: [2600/3923]	Acc@1: 49.000	
Test: [2650/3923]	Acc@1: 49.057	
Test: [2700/3923]	Acc@1: 48.945	
Test: [2750/3923]	Acc@1: 48.855	
Test: [2800/3923]	Acc@1: 48.822	
Test: [2850/3923]	Acc@1: 48.790	
Test: [2900/3923]	Acc@1: 48.862	
Test: [2950/3923]	Acc@1: 48.729	
Test: [3000/3923]	Acc@1: 48.767	
Test: [3050/3923]	Acc@1: 48.738	
Test: [3100/3923]	Acc@1: 48.791	
Test: [3150/3923]	Acc@1: 48.842	
Test: [3200/3923]	Acc@1: 48.828	
Test: [3250/3923]	Acc@1: 48.816	
Test: [3300/3923]	Acc@1: 48.803	
Test: [3350/3923]	Acc@1: 48.791	
Test: [3400/3923]	Acc@1: 48.809	
Test: [3450/3923]	Acc@1: 48.783	
Test: [3500/3923]	Acc@1: 48.772	
Test: [3550/3923]	Acc@1: 48.634	
Test: [3600/3923]	Acc@1: 48.723	
Test: [3650/3923]	Acc@1: 48.672	
Test: [3700/3923]	Acc@1: 48.622	
Test: [3750/3923]	Acc@1: 48.680	
Test: [3800/3923]	Acc@1: 48.711	
Test: [3850/3923]	Acc@1: 48.624	
Test: [3900/3923]	Acc@1: 48.616	
 * Acc@1 48.573 Acc@5 94.494 UAR 35.905Accuracy of the network on the 7847 test videos: 48.6%
Max accuracy: 49.44%, Current UAR : 38.59%, Max UAR :38.75%Train: [26/300][0/971]	eta 1:03:27 lr 0.000001964	time 3.9217 (3.9217)	tot_loss 0.4150 (0.4150)	mem 12198MB
Train: [26/300][50/971]	eta 0:06:59 lr 0.000001963	time 0.3460 (0.4558)	tot_loss 0.4163 (0.4081)	mem 12198MB
Train: [26/300][100/971]	eta 0:05:59 lr 0.000001963	time 0.3469 (0.4129)	tot_loss 0.4575 (0.4127)	mem 12198MB
Train: [26/300][150/971]	eta 0:05:27 lr 0.000001963	time 0.3750 (0.3992)	tot_loss 0.4192 (0.4109)	mem 12198MB
Train: [26/300][200/971]	eta 0:05:04 lr 0.000001963	time 0.3865 (0.3954)	tot_loss 0.4280 (0.4090)	mem 12198MB
Train: [26/300][250/971]	eta 0:04:41 lr 0.000001963	time 0.3497 (0.3909)	tot_loss 0.3945 (0.4084)	mem 12198MB
Train: [26/300][300/971]	eta 0:04:20 lr 0.000001963	time 0.3510 (0.3875)	tot_loss 0.4251 (0.4079)	mem 12198MB
Train: [26/300][350/971]	eta 0:04:00 lr 0.000001963	time 0.3699 (0.3865)	tot_loss 0.3914 (0.4099)	mem 12198MB
Train: [26/300][400/971]	eta 0:03:40 lr 0.000001962	time 0.3566 (0.3862)	tot_loss 0.3376 (0.4100)	mem 12198MB
Train: [26/300][450/971]	eta 0:03:20 lr 0.000001962	time 0.3581 (0.3852)	tot_loss 0.4641 (0.4094)	mem 12198MB
Train: [26/300][500/971]	eta 0:03:00 lr 0.000001962	time 0.3530 (0.3841)	tot_loss 0.3940 (0.4079)	mem 12198MB
Train: [26/300][550/971]	eta 0:02:41 lr 0.000001962	time 0.3562 (0.3830)	tot_loss 0.4064 (0.4074)	mem 12198MB
Train: [26/300][600/971]	eta 0:02:21 lr 0.000001962	time 0.3807 (0.3823)	tot_loss 0.3915 (0.4075)	mem 12198MB
Train: [26/300][650/971]	eta 0:02:02 lr 0.000001962	time 0.3556 (0.3814)	tot_loss 0.4143 (0.4072)	mem 12198MB
Train: [26/300][700/971]	eta 0:01:43 lr 0.000001961	time 0.3461 (0.3805)	tot_loss 0.3249 (0.4078)	mem 12198MB
Train: [26/300][750/971]	eta 0:01:24 lr 0.000001961	time 0.3781 (0.3806)	tot_loss 0.4474 (0.4080)	mem 12198MB
Train: [26/300][800/971]	eta 0:01:05 lr 0.000001961	time 0.3486 (0.3802)	tot_loss 0.4721 (0.4079)	mem 12198MB
Train: [26/300][850/971]	eta 0:00:45 lr 0.000001961	time 0.3454 (0.3797)	tot_loss 0.4498 (0.4075)	mem 12198MB
Train: [26/300][900/971]	eta 0:00:26 lr 0.000001961	time 0.3782 (0.3797)	tot_loss 0.3832 (0.4076)	mem 12198MB
Train: [26/300][950/971]	eta 0:00:07 lr 0.000001961	time 0.3349 (0.3794)	tot_loss 0.4130 (0.4078)	mem 12198MB
EPOCH 26 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 53.922	
Test: [100/3923]	Acc@1: 50.000	
Test: [150/3923]	Acc@1: 50.662	
Test: [200/3923]	Acc@1: 50.249	
Test: [250/3923]	Acc@1: 48.406	
Test: [300/3923]	Acc@1: 47.010	
Test: [350/3923]	Acc@1: 48.860	
Test: [400/3923]	Acc@1: 47.880	
Test: [450/3923]	Acc@1: 48.115	
Test: [500/3923]	Acc@1: 48.703	
Test: [550/3923]	Acc@1: 47.913	
Test: [600/3923]	Acc@1: 47.754	
Test: [650/3923]	Acc@1: 48.618	
Test: [700/3923]	Acc@1: 48.859	
Test: [750/3923]	Acc@1: 48.535	
Test: [800/3923]	Acc@1: 48.814	
Test: [850/3923]	Acc@1: 48.884	
Test: [900/3923]	Acc@1: 49.501	
Test: [950/3923]	Acc@1: 49.685	
Test: [1000/3923]	Acc@1: 49.950	
Test: [1050/3923]	Acc@1: 49.572	
Test: [1100/3923]	Acc@1: 49.455	
Test: [1150/3923]	Acc@1: 49.696	
Test: [1200/3923]	Acc@1: 49.958	
Test: [1250/3923]	Acc@1: 50.280	
Test: [1300/3923]	Acc@1: 50.038	
Test: [1350/3923]	Acc@1: 50.074	
Test: [1400/3923]	Acc@1: 50.214	
Test: [1450/3923]	Acc@1: 50.069	
Test: [1500/3923]	Acc@1: 49.734	
Test: [1550/3923]	Acc@1: 49.871	
Test: [1600/3923]	Acc@1: 50.125	
Test: [1650/3923]	Acc@1: 50.061	
Test: [1700/3923]	Acc@1: 50.147	
Test: [1750/3923]	Acc@1: 50.314	
Test: [1800/3923]	Acc@1: 50.500	
Test: [1850/3923]	Acc@1: 50.486	
Test: [1900/3923]	Acc@1: 50.500	
Test: [1950/3923]	Acc@1: 50.538	
Test: [2000/3923]	Acc@1: 50.525	
Test: [2050/3923]	Acc@1: 50.536	
Test: [2100/3923]	Acc@1: 50.476	
Test: [2150/3923]	Acc@1: 50.325	
Test: [2200/3923]	Acc@1: 50.159	
Test: [2250/3923]	Acc@1: 50.155	
Test: [2300/3923]	Acc@1: 50.022	
Test: [2350/3923]	Acc@1: 49.872	
Test: [2400/3923]	Acc@1: 49.938	
Test: [2450/3923]	Acc@1: 50.122	
Test: [2500/3923]	Acc@1: 50.180	
Test: [2550/3923]	Acc@1: 50.176	
Test: [2600/3923]	Acc@1: 50.269	
Test: [2650/3923]	Acc@1: 50.189	
Test: [2700/3923]	Acc@1: 50.093	
Test: [2750/3923]	Acc@1: 50.164	
Test: [2800/3923]	Acc@1: 50.036	
Test: [2850/3923]	Acc@1: 50.035	
Test: [2900/3923]	Acc@1: 50.034	
Test: [2950/3923]	Acc@1: 50.102	
Test: [3000/3923]	Acc@1: 50.183	
Test: [3050/3923]	Acc@1: 50.131	
Test: [3100/3923]	Acc@1: 50.129	
Test: [3150/3923]	Acc@1: 50.159	
Test: [3200/3923]	Acc@1: 50.219	
Test: [3250/3923]	Acc@1: 50.123	
Test: [3300/3923]	Acc@1: 50.091	
Test: [3350/3923]	Acc@1: 49.955	
Test: [3400/3923]	Acc@1: 49.926	
Test: [3450/3923]	Acc@1: 49.986	
Test: [3500/3923]	Acc@1: 49.986	
Test: [3550/3923]	Acc@1: 50.056	
Test: [3600/3923]	Acc@1: 50.069	
Test: [3650/3923]	Acc@1: 49.986	
Test: [3700/3923]	Acc@1: 49.959	
Test: [3750/3923]	Acc@1: 49.973	
Test: [3800/3923]	Acc@1: 49.882	
Test: [3850/3923]	Acc@1: 49.935	
Test: [3900/3923]	Acc@1: 49.821	
 * Acc@1 49.847 Acc@5 94.864 UAR 38.465Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 49.85%, Current UAR : 38.47%, Max UAR :38.75%Train: [27/300][0/971]	eta 1:14:58 lr 0.000001961	time 4.6331 (4.6331)	tot_loss 0.3961 (0.3961)	mem 12198MB
Train: [27/300][50/971]	eta 0:07:18 lr 0.000001961	time 0.3518 (0.4762)	tot_loss 0.3661 (0.4001)	mem 12198MB
Train: [27/300][100/971]	eta 0:06:08 lr 0.000001960	time 0.3479 (0.4228)	tot_loss 0.4095 (0.4032)	mem 12198MB
Train: [27/300][150/971]	eta 0:05:33 lr 0.000001960	time 0.3611 (0.4064)	tot_loss 0.3744 (0.4033)	mem 12198MB
Train: [27/300][200/971]	eta 0:05:08 lr 0.000001960	time 0.3848 (0.4001)	tot_loss 0.4496 (0.4043)	mem 12198MB
Train: [27/300][250/971]	eta 0:04:44 lr 0.000001960	time 0.3559 (0.3945)	tot_loss 0.4342 (0.4049)	mem 12198MB
Train: [27/300][300/971]	eta 0:04:22 lr 0.000001960	time 0.3625 (0.3916)	tot_loss 0.3845 (0.4054)	mem 12198MB
Train: [27/300][350/971]	eta 0:04:02 lr 0.000001960	time 0.3829 (0.3904)	tot_loss 0.4318 (0.4052)	mem 12198MB
Train: [27/300][400/971]	eta 0:03:41 lr 0.000001959	time 0.3538 (0.3884)	tot_loss 0.3442 (0.4058)	mem 12198MB
Train: [27/300][450/971]	eta 0:03:21 lr 0.000001959	time 0.3533 (0.3870)	tot_loss 0.3350 (0.4052)	mem 12198MB
Train: [27/300][500/971]	eta 0:03:01 lr 0.000001959	time 0.3496 (0.3861)	tot_loss 0.4066 (0.4055)	mem 12198MB
Train: [27/300][550/971]	eta 0:02:42 lr 0.000001959	time 0.3749 (0.3853)	tot_loss 0.4072 (0.4058)	mem 12198MB
Train: [27/300][600/971]	eta 0:02:22 lr 0.000001959	time 0.3651 (0.3848)	tot_loss 0.4360 (0.4047)	mem 12198MB
Train: [27/300][650/971]	eta 0:02:03 lr 0.000001959	time 0.3879 (0.3850)	tot_loss 0.4180 (0.4048)	mem 12198MB
Train: [27/300][700/971]	eta 0:01:44 lr 0.000001959	time 0.3456 (0.3846)	tot_loss 0.3845 (0.4050)	mem 12198MB
Train: [27/300][750/971]	eta 0:01:24 lr 0.000001958	time 0.3462 (0.3837)	tot_loss 0.4240 (0.4049)	mem 12198MB
Train: [27/300][800/971]	eta 0:01:05 lr 0.000001958	time 0.3507 (0.3829)	tot_loss 0.4244 (0.4051)	mem 12198MB
Train: [27/300][850/971]	eta 0:00:46 lr 0.000001958	time 0.3531 (0.3823)	tot_loss 0.4327 (0.4053)	mem 12198MB
Train: [27/300][900/971]	eta 0:00:27 lr 0.000001958	time 0.3639 (0.3822)	tot_loss 0.4516 (0.4056)	mem 12198MB
Train: [27/300][950/971]	eta 0:00:08 lr 0.000001958	time 0.3300 (0.3818)	tot_loss 0.4101 (0.4054)	mem 12198MB
EPOCH 27 training takes 0:06:10
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 46.078	
Test: [100/3923]	Acc@1: 51.485	
Test: [150/3923]	Acc@1: 51.987	
Test: [200/3923]	Acc@1: 50.995	
Test: [250/3923]	Acc@1: 50.000	
Test: [300/3923]	Acc@1: 50.332	
Test: [350/3923]	Acc@1: 50.712	
Test: [400/3923]	Acc@1: 49.626	
Test: [450/3923]	Acc@1: 49.778	
Test: [500/3923]	Acc@1: 50.200	
Test: [550/3923]	Acc@1: 50.454	
Test: [600/3923]	Acc@1: 50.166	
Test: [650/3923]	Acc@1: 49.462	
Test: [700/3923]	Acc@1: 49.429	
Test: [750/3923]	Acc@1: 49.667	
Test: [800/3923]	Acc@1: 49.126	
Test: [850/3923]	Acc@1: 49.295	
Test: [900/3923]	Acc@1: 49.501	
Test: [950/3923]	Acc@1: 49.685	
Test: [1000/3923]	Acc@1: 49.101	
Test: [1050/3923]	Acc@1: 48.716	
Test: [1100/3923]	Acc@1: 48.547	
Test: [1150/3923]	Acc@1: 48.306	
Test: [1200/3923]	Acc@1: 48.460	
Test: [1250/3923]	Acc@1: 48.481	
Test: [1300/3923]	Acc@1: 48.578	
Test: [1350/3923]	Acc@1: 48.594	
Test: [1400/3923]	Acc@1: 48.787	
Test: [1450/3923]	Acc@1: 48.897	
Test: [1500/3923]	Acc@1: 48.967	
Test: [1550/3923]	Acc@1: 49.001	
Test: [1600/3923]	Acc@1: 49.250	
Test: [1650/3923]	Acc@1: 48.970	
Test: [1700/3923]	Acc@1: 48.824	
Test: [1750/3923]	Acc@1: 48.629	
Test: [1800/3923]	Acc@1: 48.279	
Test: [1850/3923]	Acc@1: 48.514	
Test: [1900/3923]	Acc@1: 48.659	
Test: [1950/3923]	Acc@1: 48.821	
Test: [2000/3923]	Acc@1: 48.976	
Test: [2050/3923]	Acc@1: 49.196	
Test: [2100/3923]	Acc@1: 49.310	
Test: [2150/3923]	Acc@1: 49.233	
Test: [2200/3923]	Acc@1: 49.250	
Test: [2250/3923]	Acc@1: 49.267	
Test: [2300/3923]	Acc@1: 49.478	
Test: [2350/3923]	Acc@1: 49.362	
Test: [2400/3923]	Acc@1: 49.584	
Test: [2450/3923]	Acc@1: 49.327	
Test: [2500/3923]	Acc@1: 49.320	
Test: [2550/3923]	Acc@1: 49.314	
Test: [2600/3923]	Acc@1: 49.308	
Test: [2650/3923]	Acc@1: 49.264	
Test: [2700/3923]	Acc@1: 49.260	
Test: [2750/3923]	Acc@1: 49.291	
Test: [2800/3923]	Acc@1: 49.357	
Test: [2850/3923]	Acc@1: 49.474	
Test: [2900/3923]	Acc@1: 49.466	
Test: [2950/3923]	Acc@1: 49.492	
Test: [3000/3923]	Acc@1: 49.517	
Test: [3050/3923]	Acc@1: 49.607	
Test: [3100/3923]	Acc@1: 49.581	
Test: [3150/3923]	Acc@1: 49.667	
Test: [3200/3923]	Acc@1: 49.813	
Test: [3250/3923]	Acc@1: 49.800	
Test: [3300/3923]	Acc@1: 49.667	
Test: [3350/3923]	Acc@1: 49.717	
Test: [3400/3923]	Acc@1: 49.765	
Test: [3450/3923]	Acc@1: 49.652	
Test: [3500/3923]	Acc@1: 49.657	
Test: [3550/3923]	Acc@1: 49.662	
Test: [3600/3923]	Acc@1: 49.708	
Test: [3650/3923]	Acc@1: 49.753	
Test: [3700/3923]	Acc@1: 49.689	
Test: [3750/3923]	Acc@1: 49.720	
Test: [3800/3923]	Acc@1: 49.763	
Test: [3850/3923]	Acc@1: 49.701	
Test: [3900/3923]	Acc@1: 49.680	
 * Acc@1 49.758 Acc@5 94.902 UAR 38.379Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 49.85%, Current UAR : 38.47%, Max UAR :38.75%Train: [28/300][0/971]	eta 1:23:03 lr 0.000001958	time 5.1319 (5.1319)	tot_loss 0.4005 (0.4005)	mem 12198MB
Train: [28/300][50/971]	eta 0:07:25 lr 0.000001958	time 0.3687 (0.4834)	tot_loss 0.4268 (0.4086)	mem 12198MB
Train: [28/300][100/971]	eta 0:06:15 lr 0.000001957	time 0.3570 (0.4306)	tot_loss 0.4575 (0.4101)	mem 12198MB
Train: [28/300][150/971]	eta 0:05:39 lr 0.000001957	time 0.3565 (0.4135)	tot_loss 0.3866 (0.4097)	mem 12198MB
Train: [28/300][200/971]	eta 0:05:11 lr 0.000001957	time 0.3639 (0.4042)	tot_loss 0.4074 (0.4072)	mem 12198MB
Train: [28/300][250/971]	eta 0:04:47 lr 0.000001957	time 0.4030 (0.3986)	tot_loss 0.3703 (0.4074)	mem 12198MB
Train: [28/300][300/971]	eta 0:04:25 lr 0.000001957	time 0.3569 (0.3950)	tot_loss 0.4411 (0.4061)	mem 12198MB
Train: [28/300][350/971]	eta 0:04:04 lr 0.000001957	time 0.3565 (0.3937)	tot_loss 0.3888 (0.4059)	mem 12198MB
Train: [28/300][400/971]	eta 0:03:43 lr 0.000001957	time 0.3785 (0.3919)	tot_loss 0.4317 (0.4061)	mem 12198MB
Train: [28/300][450/971]	eta 0:03:23 lr 0.000001956	time 0.3596 (0.3908)	tot_loss 0.4736 (0.4072)	mem 12198MB
Train: [28/300][500/971]	eta 0:03:03 lr 0.000001956	time 0.3487 (0.3900)	tot_loss 0.3949 (0.4067)	mem 12198MB
Train: [28/300][550/971]	eta 0:02:44 lr 0.000001956	time 0.3596 (0.3900)	tot_loss 0.4061 (0.4067)	mem 12198MB
Train: [28/300][600/971]	eta 0:02:24 lr 0.000001956	time 0.3474 (0.3889)	tot_loss 0.3065 (0.4058)	mem 12198MB
Train: [28/300][650/971]	eta 0:02:04 lr 0.000001956	time 0.3740 (0.3887)	tot_loss 0.3924 (0.4056)	mem 12198MB
Train: [28/300][700/971]	eta 0:01:45 lr 0.000001956	time 0.3900 (0.3878)	tot_loss 0.3931 (0.4053)	mem 12198MB
Train: [28/300][750/971]	eta 0:01:25 lr 0.000001955	time 0.3532 (0.3866)	tot_loss 0.3651 (0.4054)	mem 12198MB
Train: [28/300][800/971]	eta 0:01:06 lr 0.000001955	time 0.3518 (0.3864)	tot_loss 0.4213 (0.4054)	mem 12198MB
Train: [28/300][850/971]	eta 0:00:46 lr 0.000001955	time 0.3548 (0.3854)	tot_loss 0.3632 (0.4060)	mem 12198MB
Train: [28/300][900/971]	eta 0:00:27 lr 0.000001955	time 0.3505 (0.3847)	tot_loss 0.3664 (0.4058)	mem 12198MB
Train: [28/300][950/971]	eta 0:00:08 lr 0.000001955	time 0.3286 (0.3836)	tot_loss 0.3379 (0.4061)	mem 12198MB
EPOCH 28 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 47.059	
Test: [100/3923]	Acc@1: 46.040	
Test: [150/3923]	Acc@1: 47.351	
Test: [200/3923]	Acc@1: 46.517	
Test: [250/3923]	Acc@1: 46.614	
Test: [300/3923]	Acc@1: 46.013	
Test: [350/3923]	Acc@1: 48.291	
Test: [400/3923]	Acc@1: 47.756	
Test: [450/3923]	Acc@1: 47.783	
Test: [500/3923]	Acc@1: 47.904	
Test: [550/3923]	Acc@1: 47.913	
Test: [600/3923]	Acc@1: 47.338	
Test: [650/3923]	Acc@1: 46.467	
Test: [700/3923]	Acc@1: 46.862	
Test: [750/3923]	Acc@1: 47.137	
Test: [800/3923]	Acc@1: 47.253	
Test: [850/3923]	Acc@1: 47.121	
Test: [900/3923]	Acc@1: 46.837	
Test: [950/3923]	Acc@1: 46.845	
Test: [1000/3923]	Acc@1: 47.103	
Test: [1050/3923]	Acc@1: 47.288	
Test: [1100/3923]	Acc@1: 47.048	
Test: [1150/3923]	Acc@1: 47.263	
Test: [1200/3923]	Acc@1: 47.835	
Test: [1250/3923]	Acc@1: 48.241	
Test: [1300/3923]	Acc@1: 48.386	
Test: [1350/3923]	Acc@1: 48.075	
Test: [1400/3923]	Acc@1: 48.251	
Test: [1450/3923]	Acc@1: 48.208	
Test: [1500/3923]	Acc@1: 48.534	
Test: [1550/3923]	Acc@1: 48.420	
Test: [1600/3923]	Acc@1: 48.438	
Test: [1650/3923]	Acc@1: 48.577	
Test: [1700/3923]	Acc@1: 48.677	
Test: [1750/3923]	Acc@1: 48.572	
Test: [1800/3923]	Acc@1: 48.501	
Test: [1850/3923]	Acc@1: 48.568	
Test: [1900/3923]	Acc@1: 48.501	
Test: [1950/3923]	Acc@1: 48.514	
Test: [2000/3923]	Acc@1: 48.451	
Test: [2050/3923]	Acc@1: 48.391	
Test: [2100/3923]	Acc@1: 48.382	
Test: [2150/3923]	Acc@1: 48.257	
Test: [2200/3923]	Acc@1: 48.387	
Test: [2250/3923]	Acc@1: 48.467	
Test: [2300/3923]	Acc@1: 48.305	
Test: [2350/3923]	Acc@1: 48.086	
Test: [2400/3923]	Acc@1: 48.292	
Test: [2450/3923]	Acc@1: 48.368	
Test: [2500/3923]	Acc@1: 48.441	
Test: [2550/3923]	Acc@1: 48.510	
Test: [2600/3923]	Acc@1: 48.558	
Test: [2650/3923]	Acc@1: 48.548	
Test: [2700/3923]	Acc@1: 48.519	
Test: [2750/3923]	Acc@1: 48.619	
Test: [2800/3923]	Acc@1: 48.429	
Test: [2850/3923]	Acc@1: 48.492	
Test: [2900/3923]	Acc@1: 48.673	
Test: [2950/3923]	Acc@1: 48.645	
Test: [3000/3923]	Acc@1: 48.650	
Test: [3050/3923]	Acc@1: 48.689	
Test: [3100/3923]	Acc@1: 48.662	
Test: [3150/3923]	Acc@1: 48.635	
Test: [3200/3923]	Acc@1: 48.594	
Test: [3250/3923]	Acc@1: 48.616	
Test: [3300/3923]	Acc@1: 48.606	
Test: [3350/3923]	Acc@1: 48.493	
Test: [3400/3923]	Acc@1: 48.530	
Test: [3450/3923]	Acc@1: 48.522	
Test: [3500/3923]	Acc@1: 48.543	
Test: [3550/3923]	Acc@1: 48.479	
Test: [3600/3923]	Acc@1: 48.514	
Test: [3650/3923]	Acc@1: 48.494	
Test: [3700/3923]	Acc@1: 48.541	
Test: [3750/3923]	Acc@1: 48.667	
Test: [3800/3923]	Acc@1: 48.763	
Test: [3850/3923]	Acc@1: 48.767	
Test: [3900/3923]	Acc@1: 48.808	
 * Acc@1 48.776 Acc@5 94.940 UAR 38.763Accuracy of the network on the 7847 test videos: 48.8%
Max accuracy: 49.85%, Current UAR : 38.47%, Max UAR :38.76%Train: [29/300][0/971]	eta 1:16:52 lr 0.000001955	time 4.7498 (4.7498)	tot_loss 0.3831 (0.3831)	mem 12198MB
Train: [29/300][50/971]	eta 0:07:11 lr 0.000001955	time 0.3511 (0.4685)	tot_loss 0.4193 (0.4099)	mem 12198MB
Train: [29/300][100/971]	eta 0:06:11 lr 0.000001954	time 0.3507 (0.4263)	tot_loss 0.3975 (0.4048)	mem 12198MB
Train: [29/300][150/971]	eta 0:05:37 lr 0.000001954	time 0.3860 (0.4107)	tot_loss 0.3367 (0.4048)	mem 12198MB
Train: [29/300][200/971]	eta 0:05:10 lr 0.000001954	time 0.3653 (0.4022)	tot_loss 0.4085 (0.4063)	mem 12198MB
Train: [29/300][250/971]	eta 0:04:46 lr 0.000001954	time 0.3940 (0.3969)	tot_loss 0.4390 (0.4064)	mem 12198MB
Train: [29/300][300/971]	eta 0:04:25 lr 0.000001954	time 0.6013 (0.3957)	tot_loss 0.4058 (0.4059)	mem 12198MB
Train: [29/300][350/971]	eta 0:04:04 lr 0.000001954	time 0.3704 (0.3930)	tot_loss 0.4269 (0.4057)	mem 12198MB
Train: [29/300][400/971]	eta 0:03:43 lr 0.000001953	time 0.3588 (0.3910)	tot_loss 0.4134 (0.4048)	mem 12198MB
Train: [29/300][450/971]	eta 0:03:22 lr 0.000001953	time 0.3551 (0.3892)	tot_loss 0.4701 (0.4046)	mem 12198MB
Train: [29/300][500/971]	eta 0:03:02 lr 0.000001953	time 0.3557 (0.3880)	tot_loss 0.4053 (0.4043)	mem 12198MB
Train: [29/300][550/971]	eta 0:02:42 lr 0.000001953	time 0.3525 (0.3868)	tot_loss 0.3772 (0.4047)	mem 12198MB
Train: [29/300][600/971]	eta 0:02:23 lr 0.000001953	time 0.3527 (0.3857)	tot_loss 0.4100 (0.4047)	mem 12198MB
Train: [29/300][650/971]	eta 0:02:03 lr 0.000001953	time 0.3482 (0.3850)	tot_loss 0.3683 (0.4048)	mem 12198MB
Train: [29/300][700/971]	eta 0:01:44 lr 0.000001952	time 0.3583 (0.3842)	tot_loss 0.4181 (0.4047)	mem 12198MB
Train: [29/300][750/971]	eta 0:01:24 lr 0.000001952	time 0.3508 (0.3830)	tot_loss 0.3525 (0.4047)	mem 12198MB
Train: [29/300][800/971]	eta 0:01:05 lr 0.000001952	time 0.3666 (0.3822)	tot_loss 0.4314 (0.4048)	mem 12198MB
Train: [29/300][850/971]	eta 0:00:46 lr 0.000001952	time 0.3522 (0.3816)	tot_loss 0.3881 (0.4052)	mem 12198MB
Train: [29/300][900/971]	eta 0:00:27 lr 0.000001952	time 0.3517 (0.3811)	tot_loss 0.4154 (0.4051)	mem 12198MB
Train: [29/300][950/971]	eta 0:00:07 lr 0.000001952	time 0.3378 (0.3805)	tot_loss 0.4015 (0.4050)	mem 12198MB
EPOCH 29 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 53.922	
Test: [100/3923]	Acc@1: 55.941	
Test: [150/3923]	Acc@1: 52.649	
Test: [200/3923]	Acc@1: 50.995	
Test: [250/3923]	Acc@1: 50.398	
Test: [300/3923]	Acc@1: 50.000	
Test: [350/3923]	Acc@1: 49.288	
Test: [400/3923]	Acc@1: 49.501	
Test: [450/3923]	Acc@1: 49.335	
Test: [500/3923]	Acc@1: 48.703	
Test: [550/3923]	Acc@1: 48.730	
Test: [600/3923]	Acc@1: 48.586	
Test: [650/3923]	Acc@1: 49.078	
Test: [700/3923]	Acc@1: 48.930	
Test: [750/3923]	Acc@1: 48.935	
Test: [800/3923]	Acc@1: 48.939	
Test: [850/3923]	Acc@1: 48.414	
Test: [900/3923]	Acc@1: 48.613	
Test: [950/3923]	Acc@1: 48.738	
Test: [1000/3923]	Acc@1: 49.051	
Test: [1050/3923]	Acc@1: 49.334	
Test: [1100/3923]	Acc@1: 49.183	
Test: [1150/3923]	Acc@1: 49.131	
Test: [1200/3923]	Acc@1: 49.334	
Test: [1250/3923]	Acc@1: 50.040	
Test: [1300/3923]	Acc@1: 49.962	
Test: [1350/3923]	Acc@1: 49.963	
Test: [1400/3923]	Acc@1: 50.178	
Test: [1450/3923]	Acc@1: 49.966	
Test: [1500/3923]	Acc@1: 49.867	
Test: [1550/3923]	Acc@1: 49.807	
Test: [1600/3923]	Acc@1: 49.906	
Test: [1650/3923]	Acc@1: 50.151	
Test: [1700/3923]	Acc@1: 50.000	
Test: [1750/3923]	Acc@1: 50.114	
Test: [1800/3923]	Acc@1: 49.833	
Test: [1850/3923]	Acc@1: 49.622	
Test: [1900/3923]	Acc@1: 49.527	
Test: [1950/3923]	Acc@1: 49.692	
Test: [2000/3923]	Acc@1: 49.750	
Test: [2050/3923]	Acc@1: 49.732	
Test: [2100/3923]	Acc@1: 49.595	
Test: [2150/3923]	Acc@1: 49.582	
Test: [2200/3923]	Acc@1: 49.387	
Test: [2250/3923]	Acc@1: 49.311	
Test: [2300/3923]	Acc@1: 49.326	
Test: [2350/3923]	Acc@1: 49.383	
Test: [2400/3923]	Acc@1: 49.417	
Test: [2450/3923]	Acc@1: 49.470	
Test: [2500/3923]	Acc@1: 49.720	
Test: [2550/3923]	Acc@1: 49.745	
Test: [2600/3923]	Acc@1: 49.731	
Test: [2650/3923]	Acc@1: 49.981	
Test: [2700/3923]	Acc@1: 49.944	
Test: [2750/3923]	Acc@1: 50.109	
Test: [2800/3923]	Acc@1: 50.107	
Test: [2850/3923]	Acc@1: 50.035	
Test: [2900/3923]	Acc@1: 50.103	
Test: [2950/3923]	Acc@1: 50.000	
Test: [3000/3923]	Acc@1: 50.017	
Test: [3050/3923]	Acc@1: 50.066	
Test: [3100/3923]	Acc@1: 50.129	
Test: [3150/3923]	Acc@1: 50.032	
Test: [3200/3923]	Acc@1: 50.062	
Test: [3250/3923]	Acc@1: 49.938	
Test: [3300/3923]	Acc@1: 49.833	
Test: [3350/3923]	Acc@1: 49.776	
Test: [3400/3923]	Acc@1: 49.750	
Test: [3450/3923]	Acc@1: 49.652	
Test: [3500/3923]	Acc@1: 49.700	
Test: [3550/3923]	Acc@1: 49.634	
Test: [3600/3923]	Acc@1: 49.778	
Test: [3650/3923]	Acc@1: 49.849	
Test: [3700/3923]	Acc@1: 49.784	
Test: [3750/3923]	Acc@1: 49.733	
Test: [3800/3923]	Acc@1: 49.671	
Test: [3850/3923]	Acc@1: 49.688	
Test: [3900/3923]	Acc@1: 49.628	
 * Acc@1 49.618 Acc@5 94.672 UAR 37.854Accuracy of the network on the 7847 test videos: 49.6%
Max accuracy: 49.85%, Current UAR : 38.47%, Max UAR :38.76%Train: [30/300][0/971]	eta 1:21:28 lr 0.000001952	time 5.0349 (5.0349)	tot_loss 0.4449 (0.4449)	mem 12198MB
Train: [30/300][50/971]	eta 0:07:14 lr 0.000001951	time 0.3503 (0.4722)	tot_loss 0.4573 (0.4160)	mem 12198MB
Train: [30/300][100/971]	eta 0:06:08 lr 0.000001951	time 0.3524 (0.4228)	tot_loss 0.4115 (0.4107)	mem 12198MB
Train: [30/300][150/971]	eta 0:05:33 lr 0.000001951	time 0.3517 (0.4066)	tot_loss 0.4404 (0.4107)	mem 12198MB
Train: [30/300][200/971]	eta 0:05:07 lr 0.000001951	time 0.3624 (0.3983)	tot_loss 0.4128 (0.4075)	mem 12198MB
Train: [30/300][250/971]	eta 0:04:43 lr 0.000001951	time 0.3609 (0.3932)	tot_loss 0.4091 (0.4048)	mem 12198MB
Train: [30/300][300/971]	eta 0:04:22 lr 0.000001951	time 0.3590 (0.3906)	tot_loss 0.4222 (0.4045)	mem 12198MB
Train: [30/300][350/971]	eta 0:04:01 lr 0.000001950	time 0.3632 (0.3888)	tot_loss 0.4035 (0.4056)	mem 12198MB
Train: [30/300][400/971]	eta 0:03:41 lr 0.000001950	time 0.3515 (0.3871)	tot_loss 0.3980 (0.4058)	mem 12198MB
Train: [30/300][450/971]	eta 0:03:20 lr 0.000001950	time 0.3570 (0.3857)	tot_loss 0.3659 (0.4049)	mem 12198MB
Train: [30/300][500/971]	eta 0:03:01 lr 0.000001950	time 0.4303 (0.3853)	tot_loss 0.4057 (0.4041)	mem 12198MB
Train: [30/300][550/971]	eta 0:02:41 lr 0.000001950	time 0.3656 (0.3841)	tot_loss 0.3679 (0.4042)	mem 12198MB
Train: [30/300][600/971]	eta 0:02:22 lr 0.000001950	time 0.3702 (0.3833)	tot_loss 0.4193 (0.4044)	mem 12198MB
Train: [30/300][650/971]	eta 0:02:03 lr 0.000001949	time 0.3715 (0.3832)	tot_loss 0.4460 (0.4043)	mem 12198MB
Train: [30/300][700/971]	eta 0:01:43 lr 0.000001949	time 0.3485 (0.3828)	tot_loss 0.4186 (0.4048)	mem 12198MB
Train: [30/300][750/971]	eta 0:01:24 lr 0.000001949	time 0.3525 (0.3824)	tot_loss 0.4021 (0.4046)	mem 12198MB
Train: [30/300][800/971]	eta 0:01:05 lr 0.000001949	time 0.3424 (0.3823)	tot_loss 0.3731 (0.4046)	mem 12198MB
Train: [30/300][850/971]	eta 0:00:46 lr 0.000001949	time 0.3587 (0.3817)	tot_loss 0.4439 (0.4048)	mem 12198MB
Train: [30/300][900/971]	eta 0:00:27 lr 0.000001949	time 0.3566 (0.3818)	tot_loss 0.3491 (0.4046)	mem 12198MB
Train: [30/300][950/971]	eta 0:00:08 lr 0.000001948	time 0.3336 (0.3813)	tot_loss 0.4036 (0.4050)	mem 12198MB
EPOCH 30 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 51.485	
Test: [150/3923]	Acc@1: 49.669	
Test: [200/3923]	Acc@1: 50.746	
Test: [250/3923]	Acc@1: 49.801	
Test: [300/3923]	Acc@1: 50.332	
Test: [350/3923]	Acc@1: 50.570	
Test: [400/3923]	Acc@1: 50.374	
Test: [450/3923]	Acc@1: 50.000	
Test: [500/3923]	Acc@1: 50.100	
Test: [550/3923]	Acc@1: 50.363	
Test: [600/3923]	Acc@1: 49.667	
Test: [650/3923]	Acc@1: 49.462	
Test: [700/3923]	Acc@1: 50.143	
Test: [750/3923]	Acc@1: 50.333	
Test: [800/3923]	Acc@1: 49.501	
Test: [850/3923]	Acc@1: 49.824	
Test: [900/3923]	Acc@1: 49.334	
Test: [950/3923]	Acc@1: 49.001	
Test: [1000/3923]	Acc@1: 49.151	
Test: [1050/3923]	Acc@1: 49.286	
Test: [1100/3923]	Acc@1: 49.682	
Test: [1150/3923]	Acc@1: 49.652	
Test: [1200/3923]	Acc@1: 49.251	
Test: [1250/3923]	Acc@1: 49.121	
Test: [1300/3923]	Acc@1: 49.039	
Test: [1350/3923]	Acc@1: 49.223	
Test: [1400/3923]	Acc@1: 49.215	
Test: [1450/3923]	Acc@1: 49.173	
Test: [1500/3923]	Acc@1: 49.434	
Test: [1550/3923]	Acc@1: 49.420	
Test: [1600/3923]	Acc@1: 49.250	
Test: [1650/3923]	Acc@1: 49.364	
Test: [1700/3923]	Acc@1: 49.588	
Test: [1750/3923]	Acc@1: 49.714	
Test: [1800/3923]	Acc@1: 49.639	
Test: [1850/3923]	Acc@1: 49.460	
Test: [1900/3923]	Acc@1: 49.264	
Test: [1950/3923]	Acc@1: 49.129	
Test: [2000/3923]	Acc@1: 49.600	
Test: [2050/3923]	Acc@1: 49.683	
Test: [2100/3923]	Acc@1: 49.667	
Test: [2150/3923]	Acc@1: 49.605	
Test: [2200/3923]	Acc@1: 49.500	
Test: [2250/3923]	Acc@1: 49.556	
Test: [2300/3923]	Acc@1: 49.544	
Test: [2350/3923]	Acc@1: 49.490	
Test: [2400/3923]	Acc@1: 49.604	
Test: [2450/3923]	Acc@1: 49.531	
Test: [2500/3923]	Acc@1: 49.540	
Test: [2550/3923]	Acc@1: 49.510	
Test: [2600/3923]	Acc@1: 49.519	
Test: [2650/3923]	Acc@1: 49.491	
Test: [2700/3923]	Acc@1: 49.426	
Test: [2750/3923]	Acc@1: 49.473	
Test: [2800/3923]	Acc@1: 49.536	
Test: [2850/3923]	Acc@1: 49.579	
Test: [2900/3923]	Acc@1: 49.621	
Test: [2950/3923]	Acc@1: 49.610	
Test: [3000/3923]	Acc@1: 49.617	
Test: [3050/3923]	Acc@1: 49.639	
Test: [3100/3923]	Acc@1: 49.581	
Test: [3150/3923]	Acc@1: 49.714	
Test: [3200/3923]	Acc@1: 49.641	
Test: [3250/3923]	Acc@1: 49.600	
Test: [3300/3923]	Acc@1: 49.546	
Test: [3350/3923]	Acc@1: 49.552	
Test: [3400/3923]	Acc@1: 49.662	
Test: [3450/3923]	Acc@1: 49.739	
Test: [3500/3923]	Acc@1: 49.843	
Test: [3550/3923]	Acc@1: 49.859	
Test: [3600/3923]	Acc@1: 49.986	
Test: [3650/3923]	Acc@1: 49.945	
Test: [3700/3923]	Acc@1: 49.973	
Test: [3750/3923]	Acc@1: 49.947	
Test: [3800/3923]	Acc@1: 49.842	
Test: [3850/3923]	Acc@1: 49.831	
Test: [3900/3923]	Acc@1: 49.718	
 * Acc@1 49.681 Acc@5 94.137 UAR 38.435Accuracy of the network on the 7847 test videos: 49.7%
Max accuracy: 49.85%, Current UAR : 38.47%, Max UAR :38.76%Train: [31/300][0/971]	eta 1:11:31 lr 0.000001948	time 4.4192 (4.4192)	tot_loss 0.3915 (0.3915)	mem 12198MB
Train: [31/300][50/971]	eta 0:07:08 lr 0.000001948	time 0.3834 (0.4650)	tot_loss 0.3996 (0.4055)	mem 12198MB
Train: [31/300][100/971]	eta 0:06:09 lr 0.000001948	time 0.3557 (0.4237)	tot_loss 0.3944 (0.4053)	mem 12198MB
Train: [31/300][150/971]	eta 0:05:33 lr 0.000001948	time 0.3475 (0.4067)	tot_loss 0.4024 (0.4043)	mem 12198MB
Train: [31/300][200/971]	eta 0:05:07 lr 0.000001948	time 0.3596 (0.3987)	tot_loss 0.3571 (0.4032)	mem 12198MB
Train: [31/300][250/971]	eta 0:04:43 lr 0.000001947	time 0.3506 (0.3936)	tot_loss 0.3251 (0.4024)	mem 12198MB
Train: [31/300][300/971]	eta 0:04:21 lr 0.000001947	time 0.3520 (0.3904)	tot_loss 0.4602 (0.4006)	mem 12198MB
Train: [31/300][350/971]	eta 0:04:01 lr 0.000001947	time 0.3565 (0.3881)	tot_loss 0.4001 (0.4022)	mem 12198MB
Train: [31/300][400/971]	eta 0:03:40 lr 0.000001947	time 0.3543 (0.3862)	tot_loss 0.3381 (0.4024)	mem 12198MB
Train: [31/300][450/971]	eta 0:03:20 lr 0.000001947	time 0.3625 (0.3851)	tot_loss 0.3435 (0.4022)	mem 12198MB
Train: [31/300][500/971]	eta 0:03:00 lr 0.000001947	time 0.3679 (0.3837)	tot_loss 0.4513 (0.4025)	mem 12198MB
Train: [31/300][550/971]	eta 0:02:41 lr 0.000001946	time 0.3594 (0.3830)	tot_loss 0.4590 (0.4026)	mem 12198MB
Train: [31/300][600/971]	eta 0:02:22 lr 0.000001946	time 0.3914 (0.3831)	tot_loss 0.4160 (0.4025)	mem 12198MB
Train: [31/300][650/971]	eta 0:02:02 lr 0.000001946	time 0.3585 (0.3829)	tot_loss 0.4028 (0.4031)	mem 12198MB
Train: [31/300][700/971]	eta 0:01:43 lr 0.000001946	time 0.3502 (0.3824)	tot_loss 0.4086 (0.4032)	mem 12198MB
Train: [31/300][750/971]	eta 0:01:24 lr 0.000001946	time 0.3556 (0.3821)	tot_loss 0.3597 (0.4034)	mem 12198MB
Train: [31/300][800/971]	eta 0:01:05 lr 0.000001946	time 0.3488 (0.3819)	tot_loss 0.4196 (0.4035)	mem 12198MB
Train: [31/300][850/971]	eta 0:00:46 lr 0.000001945	time 0.3470 (0.3816)	tot_loss 0.4389 (0.4035)	mem 12198MB
Train: [31/300][900/971]	eta 0:00:27 lr 0.000001945	time 0.3625 (0.3815)	tot_loss 0.4304 (0.4029)	mem 12198MB
Train: [31/300][950/971]	eta 0:00:07 lr 0.000001945	time 0.3356 (0.3808)	tot_loss 0.4338 (0.4031)	mem 12198MB
EPOCH 31 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 56.863	
Test: [100/3923]	Acc@1: 50.000	
Test: [150/3923]	Acc@1: 48.013	
Test: [200/3923]	Acc@1: 46.020	
Test: [250/3923]	Acc@1: 47.809	
Test: [300/3923]	Acc@1: 50.166	
Test: [350/3923]	Acc@1: 51.282	
Test: [400/3923]	Acc@1: 51.995	
Test: [450/3923]	Acc@1: 51.774	
Test: [500/3923]	Acc@1: 52.595	
Test: [550/3923]	Acc@1: 52.722	
Test: [600/3923]	Acc@1: 52.496	
Test: [650/3923]	Acc@1: 52.535	
Test: [700/3923]	Acc@1: 51.926	
Test: [750/3923]	Acc@1: 51.997	
Test: [800/3923]	Acc@1: 51.373	
Test: [850/3923]	Acc@1: 50.999	
Test: [900/3923]	Acc@1: 50.999	
Test: [950/3923]	Acc@1: 50.683	
Test: [1000/3923]	Acc@1: 50.699	
Test: [1050/3923]	Acc@1: 50.809	
Test: [1100/3923]	Acc@1: 50.863	
Test: [1150/3923]	Acc@1: 51.086	
Test: [1200/3923]	Acc@1: 51.249	
Test: [1250/3923]	Acc@1: 51.079	
Test: [1300/3923]	Acc@1: 50.769	
Test: [1350/3923]	Acc@1: 50.888	
Test: [1400/3923]	Acc@1: 50.678	
Test: [1450/3923]	Acc@1: 50.758	
Test: [1500/3923]	Acc@1: 50.899	
Test: [1550/3923]	Acc@1: 50.903	
Test: [1600/3923]	Acc@1: 50.843	
Test: [1650/3923]	Acc@1: 51.030	
Test: [1700/3923]	Acc@1: 50.970	
Test: [1750/3923]	Acc@1: 50.914	
Test: [1800/3923]	Acc@1: 50.805	
Test: [1850/3923]	Acc@1: 50.999	
Test: [1900/3923]	Acc@1: 50.736	
Test: [1950/3923]	Acc@1: 50.564	
Test: [2000/3923]	Acc@1: 50.525	
Test: [2050/3923]	Acc@1: 50.658	
Test: [2100/3923]	Acc@1: 50.690	
Test: [2150/3923]	Acc@1: 50.744	
Test: [2200/3923]	Acc@1: 50.727	
Test: [2250/3923]	Acc@1: 50.600	
Test: [2300/3923]	Acc@1: 50.782	
Test: [2350/3923]	Acc@1: 50.489	
Test: [2400/3923]	Acc@1: 50.458	
Test: [2450/3923]	Acc@1: 50.184	
Test: [2500/3923]	Acc@1: 50.200	
Test: [2550/3923]	Acc@1: 50.431	
Test: [2600/3923]	Acc@1: 50.365	
Test: [2650/3923]	Acc@1: 50.358	
Test: [2700/3923]	Acc@1: 50.333	
Test: [2750/3923]	Acc@1: 50.309	
Test: [2800/3923]	Acc@1: 50.143	
Test: [2850/3923]	Acc@1: 50.018	
Test: [2900/3923]	Acc@1: 49.879	
Test: [2950/3923]	Acc@1: 49.797	
Test: [3000/3923]	Acc@1: 49.833	
Test: [3050/3923]	Acc@1: 49.738	
Test: [3100/3923]	Acc@1: 49.855	
Test: [3150/3923]	Acc@1: 49.746	
Test: [3200/3923]	Acc@1: 49.703	
Test: [3250/3923]	Acc@1: 49.600	
Test: [3300/3923]	Acc@1: 49.591	
Test: [3350/3923]	Acc@1: 49.433	
Test: [3400/3923]	Acc@1: 49.427	
Test: [3450/3923]	Acc@1: 49.507	
Test: [3500/3923]	Acc@1: 49.514	
Test: [3550/3923]	Acc@1: 49.465	
Test: [3600/3923]	Acc@1: 49.514	
Test: [3650/3923]	Acc@1: 49.617	
Test: [3700/3923]	Acc@1: 49.689	
Test: [3750/3923]	Acc@1: 49.653	
Test: [3800/3923]	Acc@1: 49.763	
Test: [3850/3923]	Acc@1: 49.792	
Test: [3900/3923]	Acc@1: 49.808	
 * Acc@1 49.847 Acc@5 94.825 UAR 38.554Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 49.85%, Current UAR : 38.55%, Max UAR :38.76%Train: [32/300][0/971]	eta 1:17:32 lr 0.000001945	time 4.7915 (4.7915)	tot_loss 0.4186 (0.4186)	mem 12198MB
Train: [32/300][50/971]	eta 0:07:15 lr 0.000001945	time 0.3606 (0.4730)	tot_loss 0.3944 (0.4022)	mem 12198MB
Train: [32/300][100/971]	eta 0:06:07 lr 0.000001945	time 0.3459 (0.4219)	tot_loss 0.3928 (0.3995)	mem 12198MB
Train: [32/300][150/971]	eta 0:05:32 lr 0.000001944	time 0.3559 (0.4052)	tot_loss 0.4424 (0.3973)	mem 12198MB
Train: [32/300][200/971]	eta 0:05:05 lr 0.000001944	time 0.3437 (0.3964)	tot_loss 0.4522 (0.3987)	mem 12198MB
Train: [32/300][250/971]	eta 0:04:42 lr 0.000001944	time 0.3517 (0.3922)	tot_loss 0.3679 (0.3997)	mem 12198MB
Train: [32/300][300/971]	eta 0:04:21 lr 0.000001944	time 0.3505 (0.3893)	tot_loss 0.3827 (0.3994)	mem 12198MB
Train: [32/300][350/971]	eta 0:03:59 lr 0.000001944	time 0.3555 (0.3863)	tot_loss 0.4436 (0.3998)	mem 12198MB
Train: [32/300][400/971]	eta 0:03:40 lr 0.000001944	time 0.3570 (0.3854)	tot_loss 0.3361 (0.3995)	mem 12198MB
Train: [32/300][450/971]	eta 0:03:20 lr 0.000001943	time 0.3590 (0.3839)	tot_loss 0.4125 (0.3994)	mem 12198MB
Train: [32/300][500/971]	eta 0:03:00 lr 0.000001943	time 0.3481 (0.3830)	tot_loss 0.4413 (0.3997)	mem 12198MB
Train: [32/300][550/971]	eta 0:02:40 lr 0.000001943	time 0.3531 (0.3823)	tot_loss 0.4042 (0.3996)	mem 12198MB
Train: [32/300][600/971]	eta 0:02:21 lr 0.000001943	time 0.3525 (0.3820)	tot_loss 0.3984 (0.3997)	mem 12198MB
Train: [32/300][650/971]	eta 0:02:02 lr 0.000001943	time 0.3697 (0.3812)	tot_loss 0.3708 (0.4003)	mem 12198MB
Train: [32/300][700/971]	eta 0:01:43 lr 0.000001942	time 0.3539 (0.3809)	tot_loss 0.3342 (0.4006)	mem 12198MB
Train: [32/300][750/971]	eta 0:01:24 lr 0.000001942	time 0.3518 (0.3806)	tot_loss 0.4002 (0.4005)	mem 12198MB
Train: [32/300][800/971]	eta 0:01:04 lr 0.000001942	time 0.3500 (0.3799)	tot_loss 0.3874 (0.4003)	mem 12198MB
Train: [32/300][850/971]	eta 0:00:45 lr 0.000001942	time 0.3917 (0.3794)	tot_loss 0.4264 (0.4007)	mem 12198MB
Train: [32/300][900/971]	eta 0:00:26 lr 0.000001942	time 0.3637 (0.3791)	tot_loss 0.4259 (0.4008)	mem 12198MB
Train: [32/300][950/971]	eta 0:00:07 lr 0.000001942	time 0.3397 (0.3788)	tot_loss 0.3185 (0.4009)	mem 12198MB
EPOCH 32 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 47.059	
Test: [100/3923]	Acc@1: 51.485	
Test: [150/3923]	Acc@1: 51.987	
Test: [200/3923]	Acc@1: 50.995	
Test: [250/3923]	Acc@1: 49.203	
Test: [300/3923]	Acc@1: 49.502	
Test: [350/3923]	Acc@1: 50.712	
Test: [400/3923]	Acc@1: 51.122	
Test: [450/3923]	Acc@1: 50.998	
Test: [500/3923]	Acc@1: 51.297	
Test: [550/3923]	Acc@1: 51.543	
Test: [600/3923]	Acc@1: 50.915	
Test: [650/3923]	Acc@1: 50.230	
Test: [700/3923]	Acc@1: 50.927	
Test: [750/3923]	Acc@1: 50.599	
Test: [800/3923]	Acc@1: 50.375	
Test: [850/3923]	Acc@1: 50.470	
Test: [900/3923]	Acc@1: 50.499	
Test: [950/3923]	Acc@1: 50.578	
Test: [1000/3923]	Acc@1: 50.350	
Test: [1050/3923]	Acc@1: 50.428	
Test: [1100/3923]	Acc@1: 50.045	
Test: [1150/3923]	Acc@1: 50.174	
Test: [1200/3923]	Acc@1: 50.167	
Test: [1250/3923]	Acc@1: 50.280	
Test: [1300/3923]	Acc@1: 50.115	
Test: [1350/3923]	Acc@1: 50.148	
Test: [1400/3923]	Acc@1: 50.286	
Test: [1450/3923]	Acc@1: 50.310	
Test: [1500/3923]	Acc@1: 50.266	
Test: [1550/3923]	Acc@1: 50.064	
Test: [1600/3923]	Acc@1: 50.187	
Test: [1650/3923]	Acc@1: 50.212	
Test: [1700/3923]	Acc@1: 50.353	
Test: [1750/3923]	Acc@1: 50.114	
Test: [1800/3923]	Acc@1: 50.333	
Test: [1850/3923]	Acc@1: 50.324	
Test: [1900/3923]	Acc@1: 50.289	
Test: [1950/3923]	Acc@1: 49.974	
Test: [2000/3923]	Acc@1: 50.075	
Test: [2050/3923]	Acc@1: 50.195	
Test: [2100/3923]	Acc@1: 50.143	
Test: [2150/3923]	Acc@1: 50.139	
Test: [2200/3923]	Acc@1: 50.091	
Test: [2250/3923]	Acc@1: 50.067	
Test: [2300/3923]	Acc@1: 50.087	
Test: [2350/3923]	Acc@1: 49.979	
Test: [2400/3923]	Acc@1: 50.000	
Test: [2450/3923]	Acc@1: 50.061	
Test: [2500/3923]	Acc@1: 50.120	
Test: [2550/3923]	Acc@1: 50.196	
Test: [2600/3923]	Acc@1: 50.115	
Test: [2650/3923]	Acc@1: 50.170	
Test: [2700/3923]	Acc@1: 50.130	
Test: [2750/3923]	Acc@1: 50.127	
Test: [2800/3923]	Acc@1: 49.964	
Test: [2850/3923]	Acc@1: 50.053	
Test: [2900/3923]	Acc@1: 50.103	
Test: [2950/3923]	Acc@1: 50.102	
Test: [3000/3923]	Acc@1: 50.083	
Test: [3050/3923]	Acc@1: 50.082	
Test: [3100/3923]	Acc@1: 50.081	
Test: [3150/3923]	Acc@1: 50.063	
Test: [3200/3923]	Acc@1: 50.016	
Test: [3250/3923]	Acc@1: 50.092	
Test: [3300/3923]	Acc@1: 50.212	
Test: [3350/3923]	Acc@1: 50.194	
Test: [3400/3923]	Acc@1: 50.279	
Test: [3450/3923]	Acc@1: 50.290	
Test: [3500/3923]	Acc@1: 50.300	
Test: [3550/3923]	Acc@1: 50.282	
Test: [3600/3923]	Acc@1: 50.250	
Test: [3650/3923]	Acc@1: 50.329	
Test: [3700/3923]	Acc@1: 50.162	
Test: [3750/3923]	Acc@1: 50.053	
Test: [3800/3923]	Acc@1: 50.026	
Test: [3850/3923]	Acc@1: 49.909	
Test: [3900/3923]	Acc@1: 49.974	
 * Acc@1 49.975 Acc@5 94.723 UAR 37.730Accuracy of the network on the 7847 test videos: 50.0%
Max accuracy: 49.97%, Current UAR : 37.73%, Max UAR :38.76%Train: [33/300][0/971]	eta 1:17:50 lr 0.000001941	time 4.8099 (4.8099)	tot_loss 0.3981 (0.3981)	mem 12198MB
Train: [33/300][50/971]	eta 0:07:23 lr 0.000001941	time 0.3461 (0.4818)	tot_loss 0.3719 (0.4075)	mem 12198MB
Train: [33/300][100/971]	eta 0:06:16 lr 0.000001941	time 0.3739 (0.4318)	tot_loss 0.3269 (0.4028)	mem 12198MB
Train: [33/300][150/971]	eta 0:05:40 lr 0.000001941	time 0.3537 (0.4147)	tot_loss 0.3753 (0.4027)	mem 12198MB
Train: [33/300][200/971]	eta 0:05:12 lr 0.000001941	time 0.3564 (0.4057)	tot_loss 0.4034 (0.4038)	mem 12198MB
Train: [33/300][250/971]	eta 0:04:48 lr 0.000001941	time 0.3647 (0.4000)	tot_loss 0.3975 (0.4028)	mem 12198MB
Train: [33/300][300/971]	eta 0:04:26 lr 0.000001940	time 0.3629 (0.3968)	tot_loss 0.4342 (0.4039)	mem 12198MB
Train: [33/300][350/971]	eta 0:04:05 lr 0.000001940	time 0.3728 (0.3961)	tot_loss 0.4479 (0.4041)	mem 12198MB
Train: [33/300][400/971]	eta 0:03:44 lr 0.000001940	time 0.3573 (0.3940)	tot_loss 0.4085 (0.4045)	mem 12198MB
Train: [33/300][450/971]	eta 0:03:24 lr 0.000001940	time 0.3569 (0.3928)	tot_loss 0.4544 (0.4045)	mem 12198MB
Train: [33/300][500/971]	eta 0:03:04 lr 0.000001940	time 0.3485 (0.3909)	tot_loss 0.3703 (0.4047)	mem 12198MB
Train: [33/300][550/971]	eta 0:02:44 lr 0.000001939	time 0.3656 (0.3898)	tot_loss 0.3868 (0.4040)	mem 12198MB
Train: [33/300][600/971]	eta 0:02:24 lr 0.000001939	time 0.3525 (0.3887)	tot_loss 0.4251 (0.4045)	mem 12198MB
Train: [33/300][650/971]	eta 0:02:04 lr 0.000001939	time 0.3572 (0.3874)	tot_loss 0.3868 (0.4041)	mem 12198MB
Train: [33/300][700/971]	eta 0:01:44 lr 0.000001939	time 0.3772 (0.3871)	tot_loss 0.3998 (0.4039)	mem 12198MB
Train: [33/300][750/971]	eta 0:01:25 lr 0.000001939	time 0.3581 (0.3866)	tot_loss 0.4050 (0.4038)	mem 12198MB
Train: [33/300][800/971]	eta 0:01:06 lr 0.000001939	time 0.3526 (0.3867)	tot_loss 0.4318 (0.4038)	mem 12198MB
Train: [33/300][850/971]	eta 0:00:46 lr 0.000001938	time 0.3531 (0.3858)	tot_loss 0.4321 (0.4040)	mem 12198MB
Train: [33/300][900/971]	eta 0:00:27 lr 0.000001938	time 0.3542 (0.3853)	tot_loss 0.4244 (0.4040)	mem 12198MB
Train: [33/300][950/971]	eta 0:00:08 lr 0.000001938	time 0.3438 (0.3847)	tot_loss 0.3699 (0.4045)	mem 12198MB
EPOCH 33 training takes 0:06:13
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 50.980	
Test: [100/3923]	Acc@1: 49.505	
Test: [150/3923]	Acc@1: 47.351	
Test: [200/3923]	Acc@1: 50.000	
Test: [250/3923]	Acc@1: 49.004	
Test: [300/3923]	Acc@1: 49.834	
Test: [350/3923]	Acc@1: 49.288	
Test: [400/3923]	Acc@1: 50.249	
Test: [450/3923]	Acc@1: 50.000	
Test: [500/3923]	Acc@1: 50.000	
Test: [550/3923]	Acc@1: 50.363	
Test: [600/3923]	Acc@1: 49.917	
Test: [650/3923]	Acc@1: 50.384	
Test: [700/3923]	Acc@1: 50.214	
Test: [750/3923]	Acc@1: 50.333	
Test: [800/3923]	Acc@1: 50.000	
Test: [850/3923]	Acc@1: 49.765	
Test: [900/3923]	Acc@1: 49.834	
Test: [950/3923]	Acc@1: 49.842	
Test: [1000/3923]	Acc@1: 49.800	
Test: [1050/3923]	Acc@1: 49.239	
Test: [1100/3923]	Acc@1: 49.001	
Test: [1150/3923]	Acc@1: 48.784	
Test: [1200/3923]	Acc@1: 49.084	
Test: [1250/3923]	Acc@1: 49.241	
Test: [1300/3923]	Acc@1: 49.500	
Test: [1350/3923]	Acc@1: 49.667	
Test: [1400/3923]	Acc@1: 49.358	
Test: [1450/3923]	Acc@1: 49.276	
Test: [1500/3923]	Acc@1: 49.667	
Test: [1550/3923]	Acc@1: 49.710	
Test: [1600/3923]	Acc@1: 49.688	
Test: [1650/3923]	Acc@1: 49.546	
Test: [1700/3923]	Acc@1: 49.765	
Test: [1750/3923]	Acc@1: 49.743	
Test: [1800/3923]	Acc@1: 49.584	
Test: [1850/3923]	Acc@1: 49.514	
Test: [1900/3923]	Acc@1: 49.605	
Test: [1950/3923]	Acc@1: 49.564	
Test: [2000/3923]	Acc@1: 49.475	
Test: [2050/3923]	Acc@1: 49.586	
Test: [2100/3923]	Acc@1: 49.667	
Test: [2150/3923]	Acc@1: 49.675	
Test: [2200/3923]	Acc@1: 49.546	
Test: [2250/3923]	Acc@1: 49.689	
Test: [2300/3923]	Acc@1: 49.761	
Test: [2350/3923]	Acc@1: 49.809	
Test: [2400/3923]	Acc@1: 49.813	
Test: [2450/3923]	Acc@1: 49.878	
Test: [2500/3923]	Acc@1: 49.780	
Test: [2550/3923]	Acc@1: 49.706	
Test: [2600/3923]	Acc@1: 49.635	
Test: [2650/3923]	Acc@1: 49.623	
Test: [2700/3923]	Acc@1: 49.759	
Test: [2750/3923]	Acc@1: 49.836	
Test: [2800/3923]	Acc@1: 49.750	
Test: [2850/3923]	Acc@1: 49.790	
Test: [2900/3923]	Acc@1: 49.724	
Test: [2950/3923]	Acc@1: 49.831	
Test: [3000/3923]	Acc@1: 49.900	
Test: [3050/3923]	Acc@1: 49.967	
Test: [3100/3923]	Acc@1: 50.032	
Test: [3150/3923]	Acc@1: 49.937	
Test: [3200/3923]	Acc@1: 49.891	
Test: [3250/3923]	Acc@1: 49.831	
Test: [3300/3923]	Acc@1: 49.894	
Test: [3350/3923]	Acc@1: 49.851	
Test: [3400/3923]	Acc@1: 49.956	
Test: [3450/3923]	Acc@1: 50.043	
Test: [3500/3923]	Acc@1: 50.143	
Test: [3550/3923]	Acc@1: 50.099	
Test: [3600/3923]	Acc@1: 50.125	
Test: [3650/3923]	Acc@1: 50.151	
Test: [3700/3923]	Acc@1: 50.122	
Test: [3750/3923]	Acc@1: 50.187	
Test: [3800/3923]	Acc@1: 50.184	
Test: [3850/3923]	Acc@1: 50.104	
Test: [3900/3923]	Acc@1: 50.128	
 * Acc@1 50.166 Acc@5 94.303 UAR 38.272Accuracy of the network on the 7847 test videos: 50.2%
Max accuracy: 50.17%, Current UAR : 38.27%, Max UAR :38.76%Train: [34/300][0/971]	eta 1:26:03 lr 0.000001938	time 5.3176 (5.3176)	tot_loss 0.4298 (0.4298)	mem 12198MB
Train: [34/300][50/971]	eta 0:07:22 lr 0.000001938	time 0.3547 (0.4800)	tot_loss 0.3850 (0.3995)	mem 12198MB
Train: [34/300][100/971]	eta 0:06:11 lr 0.000001938	time 0.3476 (0.4260)	tot_loss 0.3669 (0.4013)	mem 12198MB
Train: [34/300][150/971]	eta 0:05:35 lr 0.000001937	time 0.3519 (0.4092)	tot_loss 0.4502 (0.4015)	mem 12198MB
Train: [34/300][200/971]	eta 0:05:09 lr 0.000001937	time 0.3563 (0.4019)	tot_loss 0.4301 (0.4023)	mem 12198MB
Train: [34/300][250/971]	eta 0:04:45 lr 0.000001937	time 0.3606 (0.3965)	tot_loss 0.3806 (0.4024)	mem 12198MB
Train: [34/300][300/971]	eta 0:04:23 lr 0.000001937	time 0.3835 (0.3934)	tot_loss 0.4456 (0.4017)	mem 12198MB
Train: [34/300][350/971]	eta 0:04:03 lr 0.000001937	time 0.3696 (0.3914)	tot_loss 0.3457 (0.4010)	mem 12198MB
Train: [34/300][400/971]	eta 0:03:42 lr 0.000001936	time 0.3579 (0.3894)	tot_loss 0.4702 (0.3999)	mem 12198MB
Train: [34/300][450/971]	eta 0:03:22 lr 0.000001936	time 0.3570 (0.3880)	tot_loss 0.4116 (0.3997)	mem 12198MB
Train: [34/300][500/971]	eta 0:03:02 lr 0.000001936	time 0.3512 (0.3870)	tot_loss 0.4252 (0.3997)	mem 12198MB
Train: [34/300][550/971]	eta 0:02:42 lr 0.000001936	time 0.3543 (0.3863)	tot_loss 0.3402 (0.3997)	mem 12198MB
Train: [34/300][600/971]	eta 0:02:23 lr 0.000001936	time 0.3654 (0.3856)	tot_loss 0.4021 (0.4001)	mem 12198MB
Train: [34/300][650/971]	eta 0:02:03 lr 0.000001935	time 0.3633 (0.3848)	tot_loss 0.4887 (0.4003)	mem 12198MB
Train: [34/300][700/971]	eta 0:01:44 lr 0.000001935	time 0.3643 (0.3847)	tot_loss 0.3499 (0.4006)	mem 12198MB
Train: [34/300][750/971]	eta 0:01:24 lr 0.000001935	time 0.3641 (0.3842)	tot_loss 0.3010 (0.4002)	mem 12198MB
Train: [34/300][800/971]	eta 0:01:05 lr 0.000001935	time 0.3552 (0.3838)	tot_loss 0.4278 (0.4000)	mem 12198MB
Train: [34/300][850/971]	eta 0:00:46 lr 0.000001935	time 0.3586 (0.3832)	tot_loss 0.4035 (0.4001)	mem 12198MB
Train: [34/300][900/971]	eta 0:00:27 lr 0.000001935	time 0.3648 (0.3830)	tot_loss 0.3827 (0.4000)	mem 12198MB
Train: [34/300][950/971]	eta 0:00:08 lr 0.000001934	time 0.3402 (0.3824)	tot_loss 0.3601 (0.3995)	mem 12198MB
EPOCH 34 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 54.902	
Test: [100/3923]	Acc@1: 55.446	
Test: [150/3923]	Acc@1: 49.007	
Test: [200/3923]	Acc@1: 49.751	
Test: [250/3923]	Acc@1: 49.402	
Test: [300/3923]	Acc@1: 49.003	
Test: [350/3923]	Acc@1: 48.860	
Test: [400/3923]	Acc@1: 48.504	
Test: [450/3923]	Acc@1: 48.559	
Test: [500/3923]	Acc@1: 49.202	
Test: [550/3923]	Acc@1: 49.183	
Test: [600/3923]	Acc@1: 49.251	
Test: [650/3923]	Acc@1: 48.464	
Test: [700/3923]	Acc@1: 48.359	
Test: [750/3923]	Acc@1: 47.803	
Test: [800/3923]	Acc@1: 48.876	
Test: [850/3923]	Acc@1: 48.766	
Test: [900/3923]	Acc@1: 48.391	
Test: [950/3923]	Acc@1: 48.212	
Test: [1000/3923]	Acc@1: 48.102	
Test: [1050/3923]	Acc@1: 48.240	
Test: [1100/3923]	Acc@1: 48.456	
Test: [1150/3923]	Acc@1: 48.697	
Test: [1200/3923]	Acc@1: 48.918	
Test: [1250/3923]	Acc@1: 49.001	
Test: [1300/3923]	Acc@1: 48.847	
Test: [1350/3923]	Acc@1: 48.742	
Test: [1400/3923]	Acc@1: 48.465	
Test: [1450/3923]	Acc@1: 48.587	
Test: [1500/3923]	Acc@1: 48.634	
Test: [1550/3923]	Acc@1: 49.033	
Test: [1600/3923]	Acc@1: 48.782	
Test: [1650/3923]	Acc@1: 48.819	
Test: [1700/3923]	Acc@1: 48.618	
Test: [1750/3923]	Acc@1: 48.772	
Test: [1800/3923]	Acc@1: 48.917	
Test: [1850/3923]	Acc@1: 48.784	
Test: [1900/3923]	Acc@1: 48.790	
Test: [1950/3923]	Acc@1: 48.821	
Test: [2000/3923]	Acc@1: 48.876	
Test: [2050/3923]	Acc@1: 49.098	
Test: [2100/3923]	Acc@1: 49.167	
Test: [2150/3923]	Acc@1: 49.279	
Test: [2200/3923]	Acc@1: 49.409	
Test: [2250/3923]	Acc@1: 49.422	
Test: [2300/3923]	Acc@1: 49.261	
Test: [2350/3923]	Acc@1: 49.128	
Test: [2400/3923]	Acc@1: 49.105	
Test: [2450/3923]	Acc@1: 48.939	
Test: [2500/3923]	Acc@1: 48.980	
Test: [2550/3923]	Acc@1: 49.177	
Test: [2600/3923]	Acc@1: 49.366	
Test: [2650/3923]	Acc@1: 49.396	
Test: [2700/3923]	Acc@1: 49.463	
Test: [2750/3923]	Acc@1: 49.527	
Test: [2800/3923]	Acc@1: 49.572	
Test: [2850/3923]	Acc@1: 49.684	
Test: [2900/3923]	Acc@1: 49.810	
Test: [2950/3923]	Acc@1: 49.848	
Test: [3000/3923]	Acc@1: 49.950	
Test: [3050/3923]	Acc@1: 50.000	
Test: [3100/3923]	Acc@1: 50.097	
Test: [3150/3923]	Acc@1: 49.984	
Test: [3200/3923]	Acc@1: 50.031	
Test: [3250/3923]	Acc@1: 49.985	
Test: [3300/3923]	Acc@1: 49.970	
Test: [3350/3923]	Acc@1: 49.970	
Test: [3400/3923]	Acc@1: 50.059	
Test: [3450/3923]	Acc@1: 50.000	
Test: [3500/3923]	Acc@1: 49.971	
Test: [3550/3923]	Acc@1: 50.042	
Test: [3600/3923]	Acc@1: 50.014	
Test: [3650/3923]	Acc@1: 49.945	
Test: [3700/3923]	Acc@1: 49.919	
Test: [3750/3923]	Acc@1: 49.973	
Test: [3800/3923]	Acc@1: 49.974	
Test: [3850/3923]	Acc@1: 50.065	
Test: [3900/3923]	Acc@1: 50.064	
 * Acc@1 50.038 Acc@5 95.119 UAR 39.289Accuracy of the network on the 7847 test videos: 50.0%
Max accuracy: 50.17%, Current UAR : 38.27%, Max UAR :39.29%Train: [35/300][0/971]	eta 1:31:37 lr 0.000001934	time 5.6612 (5.6612)	tot_loss 0.4082 (0.4082)	mem 12198MB
Train: [35/300][50/971]	eta 0:07:31 lr 0.000001934	time 0.3756 (0.4908)	tot_loss 0.3828 (0.4097)	mem 12198MB
Train: [35/300][100/971]	eta 0:06:16 lr 0.000001934	time 0.3710 (0.4322)	tot_loss 0.3345 (0.4071)	mem 12198MB
Train: [35/300][150/971]	eta 0:05:39 lr 0.000001934	time 0.3535 (0.4135)	tot_loss 0.3449 (0.4049)	mem 12198MB
Train: [35/300][200/971]	eta 0:05:11 lr 0.000001933	time 0.3764 (0.4036)	tot_loss 0.3758 (0.4059)	mem 12198MB
Train: [35/300][250/971]	eta 0:04:47 lr 0.000001933	time 0.3546 (0.3994)	tot_loss 0.4015 (0.4053)	mem 12198MB
Train: [35/300][300/971]	eta 0:04:26 lr 0.000001933	time 0.3605 (0.3970)	tot_loss 0.4862 (0.4035)	mem 12198MB
Train: [35/300][350/971]	eta 0:04:06 lr 0.000001933	time 0.3846 (0.3961)	tot_loss 0.3997 (0.4038)	mem 12198MB
Train: [35/300][400/971]	eta 0:03:44 lr 0.000001933	time 0.3515 (0.3936)	tot_loss 0.3829 (0.4026)	mem 12198MB
Train: [35/300][450/971]	eta 0:03:23 lr 0.000001933	time 0.3600 (0.3910)	tot_loss 0.4612 (0.4020)	mem 12198MB
Train: [35/300][500/971]	eta 0:03:03 lr 0.000001932	time 0.3507 (0.3897)	tot_loss 0.4011 (0.4017)	mem 12198MB
Train: [35/300][550/971]	eta 0:02:43 lr 0.000001932	time 0.3840 (0.3879)	tot_loss 0.3969 (0.4017)	mem 12198MB
Train: [35/300][600/971]	eta 0:02:23 lr 0.000001932	time 0.3568 (0.3866)	tot_loss 0.4217 (0.4012)	mem 12198MB
Train: [35/300][650/971]	eta 0:02:03 lr 0.000001932	time 0.3510 (0.3861)	tot_loss 0.4121 (0.4008)	mem 12198MB
Train: [35/300][700/971]	eta 0:01:44 lr 0.000001932	time 0.3529 (0.3852)	tot_loss 0.3293 (0.4005)	mem 12198MB
Train: [35/300][750/971]	eta 0:01:24 lr 0.000001931	time 0.3596 (0.3843)	tot_loss 0.3406 (0.4004)	mem 12198MB
Train: [35/300][800/971]	eta 0:01:05 lr 0.000001931	time 0.3610 (0.3837)	tot_loss 0.4155 (0.3999)	mem 12198MB
Train: [35/300][850/971]	eta 0:00:46 lr 0.000001931	time 0.3858 (0.3841)	tot_loss 0.4351 (0.3998)	mem 12198MB
Train: [35/300][900/971]	eta 0:00:27 lr 0.000001931	time 0.3951 (0.3849)	tot_loss 0.3357 (0.3997)	mem 12198MB
Train: [35/300][950/971]	eta 0:00:08 lr 0.000001931	time 0.3395 (0.3842)	tot_loss 0.4085 (0.3996)	mem 12198MB
EPOCH 35 training takes 0:06:12
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 46.078	
Test: [100/3923]	Acc@1: 46.040	
Test: [150/3923]	Acc@1: 45.033	
Test: [200/3923]	Acc@1: 46.269	
Test: [250/3923]	Acc@1: 50.199	
Test: [300/3923]	Acc@1: 51.495	
Test: [350/3923]	Acc@1: 52.279	
Test: [400/3923]	Acc@1: 52.868	
Test: [450/3923]	Acc@1: 52.550	
Test: [500/3923]	Acc@1: 52.395	
Test: [550/3923]	Acc@1: 51.815	
Test: [600/3923]	Acc@1: 51.747	
Test: [650/3923]	Acc@1: 52.074	
Test: [700/3923]	Acc@1: 51.997	
Test: [750/3923]	Acc@1: 52.064	
Test: [800/3923]	Acc@1: 51.810	
Test: [850/3923]	Acc@1: 51.586	
Test: [900/3923]	Acc@1: 51.498	
Test: [950/3923]	Acc@1: 51.104	
Test: [1000/3923]	Acc@1: 51.648	
Test: [1050/3923]	Acc@1: 51.855	
Test: [1100/3923]	Acc@1: 51.726	
Test: [1150/3923]	Acc@1: 51.477	
Test: [1200/3923]	Acc@1: 51.332	
Test: [1250/3923]	Acc@1: 50.879	
Test: [1300/3923]	Acc@1: 50.922	
Test: [1350/3923]	Acc@1: 51.036	
Test: [1400/3923]	Acc@1: 50.999	
Test: [1450/3923]	Acc@1: 51.378	
Test: [1500/3923]	Acc@1: 51.566	
Test: [1550/3923]	Acc@1: 51.289	
Test: [1600/3923]	Acc@1: 50.968	
Test: [1650/3923]	Acc@1: 51.060	
Test: [1700/3923]	Acc@1: 51.117	
Test: [1750/3923]	Acc@1: 51.256	
Test: [1800/3923]	Acc@1: 51.138	
Test: [1850/3923]	Acc@1: 51.162	
Test: [1900/3923]	Acc@1: 51.052	
Test: [1950/3923]	Acc@1: 51.102	
Test: [2000/3923]	Acc@1: 51.124	
Test: [2050/3923]	Acc@1: 51.048	
Test: [2100/3923]	Acc@1: 51.071	
Test: [2150/3923]	Acc@1: 51.069	
Test: [2200/3923]	Acc@1: 51.113	
Test: [2250/3923]	Acc@1: 51.266	
Test: [2300/3923]	Acc@1: 51.282	
Test: [2350/3923]	Acc@1: 51.212	
Test: [2400/3923]	Acc@1: 51.291	
Test: [2450/3923]	Acc@1: 51.285	
Test: [2500/3923]	Acc@1: 51.160	
Test: [2550/3923]	Acc@1: 51.235	
Test: [2600/3923]	Acc@1: 51.365	
Test: [2650/3923]	Acc@1: 51.452	
Test: [2700/3923]	Acc@1: 51.425	
Test: [2750/3923]	Acc@1: 51.345	
Test: [2800/3923]	Acc@1: 51.339	
Test: [2850/3923]	Acc@1: 51.210	
Test: [2900/3923]	Acc@1: 51.362	
Test: [2950/3923]	Acc@1: 51.339	
Test: [3000/3923]	Acc@1: 51.233	
Test: [3050/3923]	Acc@1: 51.278	
Test: [3100/3923]	Acc@1: 51.354	
Test: [3150/3923]	Acc@1: 51.365	
Test: [3200/3923]	Acc@1: 51.406	
Test: [3250/3923]	Acc@1: 51.353	
Test: [3300/3923]	Acc@1: 51.348	
Test: [3350/3923]	Acc@1: 51.253	
Test: [3400/3923]	Acc@1: 51.176	
Test: [3450/3923]	Acc@1: 51.000	
Test: [3500/3923]	Acc@1: 51.100	
Test: [3550/3923]	Acc@1: 51.056	
Test: [3600/3923]	Acc@1: 51.014	
Test: [3650/3923]	Acc@1: 50.931	
Test: [3700/3923]	Acc@1: 50.986	
Test: [3750/3923]	Acc@1: 50.973	
Test: [3800/3923]	Acc@1: 51.026	
Test: [3850/3923]	Acc@1: 50.922	
Test: [3900/3923]	Acc@1: 50.884	
 * Acc@1 50.905 Acc@5 94.902 UAR 38.924Accuracy of the network on the 7847 test videos: 50.9%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :39.29%Train: [36/300][0/971]	eta 1:26:39 lr 0.000001930	time 5.3547 (5.3547)	tot_loss 0.3788 (0.3788)	mem 12198MB
Train: [36/300][50/971]	eta 0:07:23 lr 0.000001930	time 0.3841 (0.4815)	tot_loss 0.4229 (0.4010)	mem 12198MB
Train: [36/300][100/971]	eta 0:06:19 lr 0.000001930	time 0.3579 (0.4357)	tot_loss 0.4229 (0.3982)	mem 12198MB
Train: [36/300][150/971]	eta 0:05:43 lr 0.000001930	time 0.3871 (0.4185)	tot_loss 0.3695 (0.3978)	mem 12198MB
Train: [36/300][200/971]	eta 0:05:13 lr 0.000001930	time 0.3452 (0.4067)	tot_loss 0.3803 (0.3985)	mem 12198MB
Train: [36/300][250/971]	eta 0:04:49 lr 0.000001930	time 0.3595 (0.4017)	tot_loss 0.4620 (0.3988)	mem 12198MB
Train: [36/300][300/971]	eta 0:04:26 lr 0.000001929	time 0.3521 (0.3972)	tot_loss 0.4177 (0.3979)	mem 12198MB
Train: [36/300][350/971]	eta 0:04:04 lr 0.000001929	time 0.3719 (0.3940)	tot_loss 0.3762 (0.3991)	mem 12198MB
Train: [36/300][400/971]	eta 0:03:43 lr 0.000001929	time 0.3481 (0.3918)	tot_loss 0.4095 (0.3995)	mem 12198MB
Train: [36/300][450/971]	eta 0:03:24 lr 0.000001929	time 0.3887 (0.3924)	tot_loss 0.3867 (0.3993)	mem 12198MB
Train: [36/300][500/971]	eta 0:03:04 lr 0.000001929	time 0.3817 (0.3922)	tot_loss 0.4441 (0.3995)	mem 12198MB
Train: [36/300][550/971]	eta 0:02:44 lr 0.000001928	time 0.3561 (0.3903)	tot_loss 0.4176 (0.3993)	mem 12198MB
Train: [36/300][600/971]	eta 0:02:24 lr 0.000001928	time 0.4756 (0.3890)	tot_loss 0.3832 (0.3984)	mem 12198MB
Train: [36/300][650/971]	eta 0:02:04 lr 0.000001928	time 0.3538 (0.3875)	tot_loss 0.4165 (0.3981)	mem 12198MB
Train: [36/300][700/971]	eta 0:01:44 lr 0.000001928	time 0.3878 (0.3865)	tot_loss 0.4555 (0.3982)	mem 12198MB
Train: [36/300][750/971]	eta 0:01:25 lr 0.000001928	time 0.3538 (0.3856)	tot_loss 0.4440 (0.3984)	mem 12198MB
Train: [36/300][800/971]	eta 0:01:05 lr 0.000001927	time 0.3509 (0.3848)	tot_loss 0.4378 (0.3983)	mem 12198MB
Train: [36/300][850/971]	eta 0:00:46 lr 0.000001927	time 0.3530 (0.3840)	tot_loss 0.4250 (0.3982)	mem 12198MB
Train: [36/300][900/971]	eta 0:00:27 lr 0.000001927	time 0.3542 (0.3832)	tot_loss 0.3737 (0.3974)	mem 12198MB
Train: [36/300][950/971]	eta 0:00:08 lr 0.000001927	time 0.3374 (0.3822)	tot_loss 0.4206 (0.3974)	mem 12198MB
EPOCH 36 training takes 0:06:10
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 43.137	
Test: [100/3923]	Acc@1: 47.525	
Test: [150/3923]	Acc@1: 47.682	
Test: [200/3923]	Acc@1: 47.264	
Test: [250/3923]	Acc@1: 48.406	
Test: [300/3923]	Acc@1: 49.003	
Test: [350/3923]	Acc@1: 48.433	
Test: [400/3923]	Acc@1: 48.753	
Test: [450/3923]	Acc@1: 48.891	
Test: [500/3923]	Acc@1: 48.204	
Test: [550/3923]	Acc@1: 48.548	
Test: [600/3923]	Acc@1: 48.918	
Test: [650/3923]	Acc@1: 49.462	
Test: [700/3923]	Acc@1: 49.572	
Test: [750/3923]	Acc@1: 49.467	
Test: [800/3923]	Acc@1: 49.313	
Test: [850/3923]	Acc@1: 49.354	
Test: [900/3923]	Acc@1: 49.445	
Test: [950/3923]	Acc@1: 49.211	
Test: [1000/3923]	Acc@1: 49.650	
Test: [1050/3923]	Acc@1: 49.524	
Test: [1100/3923]	Acc@1: 49.591	
Test: [1150/3923]	Acc@1: 50.000	
Test: [1200/3923]	Acc@1: 49.833	
Test: [1250/3923]	Acc@1: 49.640	
Test: [1300/3923]	Acc@1: 49.577	
Test: [1350/3923]	Acc@1: 49.963	
Test: [1400/3923]	Acc@1: 50.214	
Test: [1450/3923]	Acc@1: 50.207	
Test: [1500/3923]	Acc@1: 50.200	
Test: [1550/3923]	Acc@1: 50.064	
Test: [1600/3923]	Acc@1: 50.062	
Test: [1650/3923]	Acc@1: 49.818	
Test: [1700/3923]	Acc@1: 49.971	
Test: [1750/3923]	Acc@1: 49.829	
Test: [1800/3923]	Acc@1: 49.556	
Test: [1850/3923]	Acc@1: 49.730	
Test: [1900/3923]	Acc@1: 49.947	
Test: [1950/3923]	Acc@1: 50.051	
Test: [2000/3923]	Acc@1: 50.150	
Test: [2050/3923]	Acc@1: 50.146	
Test: [2100/3923]	Acc@1: 50.238	
Test: [2150/3923]	Acc@1: 50.070	
Test: [2200/3923]	Acc@1: 50.000	
Test: [2250/3923]	Acc@1: 50.155	
Test: [2300/3923]	Acc@1: 50.109	
Test: [2350/3923]	Acc@1: 50.191	
Test: [2400/3923]	Acc@1: 50.271	
Test: [2450/3923]	Acc@1: 50.163	
Test: [2500/3923]	Acc@1: 50.160	
Test: [2550/3923]	Acc@1: 50.000	
Test: [2600/3923]	Acc@1: 50.038	
Test: [2650/3923]	Acc@1: 50.000	
Test: [2700/3923]	Acc@1: 49.870	
Test: [2750/3923]	Acc@1: 49.655	
Test: [2800/3923]	Acc@1: 49.500	
Test: [2850/3923]	Acc@1: 49.597	
Test: [2900/3923]	Acc@1: 49.552	
Test: [2950/3923]	Acc@1: 49.509	
Test: [3000/3923]	Acc@1: 49.517	
Test: [3050/3923]	Acc@1: 49.590	
Test: [3100/3923]	Acc@1: 49.629	
Test: [3150/3923]	Acc@1: 49.619	
Test: [3200/3923]	Acc@1: 49.531	
Test: [3250/3923]	Acc@1: 49.446	
Test: [3300/3923]	Acc@1: 49.621	
Test: [3350/3923]	Acc@1: 49.672	
Test: [3400/3923]	Acc@1: 49.588	
Test: [3450/3923]	Acc@1: 49.522	
Test: [3500/3923]	Acc@1: 49.486	
Test: [3550/3923]	Acc@1: 49.380	
Test: [3600/3923]	Acc@1: 49.417	
Test: [3650/3923]	Acc@1: 49.493	
Test: [3700/3923]	Acc@1: 49.635	
Test: [3750/3923]	Acc@1: 49.693	
Test: [3800/3923]	Acc@1: 49.605	
Test: [3850/3923]	Acc@1: 49.636	
Test: [3900/3923]	Acc@1: 49.692	
 * Acc@1 49.758 Acc@5 94.876 UAR 39.379Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :39.38%Train: [37/300][0/971]	eta 1:34:06 lr 0.000001927	time 5.8156 (5.8156)	tot_loss 0.4492 (0.4492)	mem 12198MB
Train: [37/300][50/971]	eta 0:07:21 lr 0.000001926	time 0.3539 (0.4799)	tot_loss 0.3915 (0.4004)	mem 12198MB
Train: [37/300][100/971]	eta 0:06:15 lr 0.000001926	time 0.3600 (0.4306)	tot_loss 0.3740 (0.4045)	mem 12198MB
Train: [37/300][150/971]	eta 0:05:38 lr 0.000001926	time 0.3735 (0.4125)	tot_loss 0.3693 (0.4021)	mem 12198MB
Train: [37/300][200/971]	eta 0:05:11 lr 0.000001926	time 0.3571 (0.4040)	tot_loss 0.3564 (0.4016)	mem 12198MB
Train: [37/300][250/971]	eta 0:04:47 lr 0.000001926	time 0.3568 (0.3981)	tot_loss 0.3745 (0.4013)	mem 12198MB
Train: [37/300][300/971]	eta 0:04:24 lr 0.000001925	time 0.3540 (0.3944)	tot_loss 0.4197 (0.4005)	mem 12198MB
Train: [37/300][350/971]	eta 0:04:03 lr 0.000001925	time 0.3542 (0.3916)	tot_loss 0.4676 (0.4015)	mem 12198MB
Train: [37/300][400/971]	eta 0:03:42 lr 0.000001925	time 0.3434 (0.3903)	tot_loss 0.4214 (0.4008)	mem 12198MB
Train: [37/300][450/971]	eta 0:03:22 lr 0.000001925	time 0.3754 (0.3890)	tot_loss 0.4345 (0.4000)	mem 12198MB
Train: [37/300][500/971]	eta 0:03:02 lr 0.000001925	time 0.3515 (0.3881)	tot_loss 0.4236 (0.3997)	mem 12198MB
Train: [37/300][550/971]	eta 0:02:42 lr 0.000001924	time 0.3688 (0.3870)	tot_loss 0.4159 (0.3999)	mem 12198MB
Train: [37/300][600/971]	eta 0:02:23 lr 0.000001924	time 0.3596 (0.3863)	tot_loss 0.3348 (0.3999)	mem 12198MB
Train: [37/300][650/971]	eta 0:02:03 lr 0.000001924	time 0.3531 (0.3852)	tot_loss 0.3564 (0.3993)	mem 12198MB
Train: [37/300][700/971]	eta 0:01:44 lr 0.000001924	time 0.3545 (0.3844)	tot_loss 0.3165 (0.3992)	mem 12198MB
Train: [37/300][750/971]	eta 0:01:24 lr 0.000001924	time 0.3600 (0.3843)	tot_loss 0.4100 (0.3992)	mem 12198MB
Train: [37/300][800/971]	eta 0:01:05 lr 0.000001923	time 0.3578 (0.3839)	tot_loss 0.3517 (0.3992)	mem 12198MB
Train: [37/300][850/971]	eta 0:00:46 lr 0.000001923	time 0.3525 (0.3833)	tot_loss 0.3466 (0.3991)	mem 12198MB
Train: [37/300][900/971]	eta 0:00:27 lr 0.000001923	time 0.3556 (0.3826)	tot_loss 0.3548 (0.3993)	mem 12198MB
Train: [37/300][950/971]	eta 0:00:08 lr 0.000001923	time 0.3406 (0.3824)	tot_loss 0.4317 (0.3995)	mem 12198MB
EPOCH 37 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 60.784	
Test: [100/3923]	Acc@1: 54.950	
Test: [150/3923]	Acc@1: 53.642	
Test: [200/3923]	Acc@1: 52.488	
Test: [250/3923]	Acc@1: 51.195	
Test: [300/3923]	Acc@1: 50.332	
Test: [350/3923]	Acc@1: 50.712	
Test: [400/3923]	Acc@1: 50.499	
Test: [450/3923]	Acc@1: 51.663	
Test: [500/3923]	Acc@1: 51.198	
Test: [550/3923]	Acc@1: 50.998	
Test: [600/3923]	Acc@1: 50.666	
Test: [650/3923]	Acc@1: 50.922	
Test: [700/3923]	Acc@1: 50.571	
Test: [750/3923]	Acc@1: 50.200	
Test: [800/3923]	Acc@1: 50.312	
Test: [850/3923]	Acc@1: 50.294	
Test: [900/3923]	Acc@1: 50.777	
Test: [950/3923]	Acc@1: 50.631	
Test: [1000/3923]	Acc@1: 50.450	
Test: [1050/3923]	Acc@1: 50.618	
Test: [1100/3923]	Acc@1: 50.590	
Test: [1150/3923]	Acc@1: 50.565	
Test: [1200/3923]	Acc@1: 50.291	
Test: [1250/3923]	Acc@1: 50.280	
Test: [1300/3923]	Acc@1: 50.461	
Test: [1350/3923]	Acc@1: 50.666	
Test: [1400/3923]	Acc@1: 50.642	
Test: [1450/3923]	Acc@1: 50.655	
Test: [1500/3923]	Acc@1: 50.366	
Test: [1550/3923]	Acc@1: 50.226	
Test: [1600/3923]	Acc@1: 50.468	
Test: [1650/3923]	Acc@1: 50.333	
Test: [1700/3923]	Acc@1: 50.235	
Test: [1750/3923]	Acc@1: 50.200	
Test: [1800/3923]	Acc@1: 50.333	
Test: [1850/3923]	Acc@1: 50.351	
Test: [1900/3923]	Acc@1: 50.342	
Test: [1950/3923]	Acc@1: 50.231	
Test: [2000/3923]	Acc@1: 50.350	
Test: [2050/3923]	Acc@1: 50.293	
Test: [2100/3923]	Acc@1: 50.357	
Test: [2150/3923]	Acc@1: 50.418	
Test: [2200/3923]	Acc@1: 50.432	
Test: [2250/3923]	Acc@1: 50.733	
Test: [2300/3923]	Acc@1: 50.652	
Test: [2350/3923]	Acc@1: 50.638	
Test: [2400/3923]	Acc@1: 50.729	
Test: [2450/3923]	Acc@1: 50.714	
Test: [2500/3923]	Acc@1: 50.700	
Test: [2550/3923]	Acc@1: 50.568	
Test: [2600/3923]	Acc@1: 50.442	
Test: [2650/3923]	Acc@1: 50.434	
Test: [2700/3923]	Acc@1: 50.315	
Test: [2750/3923]	Acc@1: 50.273	
Test: [2800/3923]	Acc@1: 50.161	
Test: [2850/3923]	Acc@1: 50.210	
Test: [2900/3923]	Acc@1: 50.103	
Test: [2950/3923]	Acc@1: 50.152	
Test: [3000/3923]	Acc@1: 50.167	
Test: [3050/3923]	Acc@1: 50.066	
Test: [3100/3923]	Acc@1: 50.129	
Test: [3150/3923]	Acc@1: 50.175	
Test: [3200/3923]	Acc@1: 50.125	
Test: [3250/3923]	Acc@1: 50.015	
Test: [3300/3923]	Acc@1: 49.970	
Test: [3350/3923]	Acc@1: 49.851	
Test: [3400/3923]	Acc@1: 49.926	
Test: [3450/3923]	Acc@1: 50.116	
Test: [3500/3923]	Acc@1: 50.114	
Test: [3550/3923]	Acc@1: 50.127	
Test: [3600/3923]	Acc@1: 50.222	
Test: [3650/3923]	Acc@1: 50.233	
Test: [3700/3923]	Acc@1: 50.216	
Test: [3750/3923]	Acc@1: 50.213	
Test: [3800/3923]	Acc@1: 50.184	
Test: [3850/3923]	Acc@1: 50.208	
Test: [3900/3923]	Acc@1: 50.192	
 * Acc@1 50.217 Acc@5 94.469 UAR 39.757Accuracy of the network on the 7847 test videos: 50.2%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :39.76%Train: [38/300][0/971]	eta 1:08:28 lr 0.000001923	time 4.2313 (4.2313)	tot_loss 0.3996 (0.3996)	mem 12198MB
Train: [38/300][50/971]	eta 0:07:10 lr 0.000001922	time 0.3479 (0.4679)	tot_loss 0.4107 (0.4036)	mem 12198MB
Train: [38/300][100/971]	eta 0:06:09 lr 0.000001922	time 0.3571 (0.4242)	tot_loss 0.4229 (0.3997)	mem 12198MB
Train: [38/300][150/971]	eta 0:05:35 lr 0.000001922	time 0.3545 (0.4083)	tot_loss 0.3970 (0.4006)	mem 12198MB
Train: [38/300][200/971]	eta 0:05:07 lr 0.000001922	time 0.3587 (0.3991)	tot_loss 0.3819 (0.4005)	mem 12198MB
Train: [38/300][250/971]	eta 0:04:43 lr 0.000001922	time 0.3571 (0.3937)	tot_loss 0.4039 (0.3974)	mem 12198MB
Train: [38/300][300/971]	eta 0:04:21 lr 0.000001921	time 0.3461 (0.3897)	tot_loss 0.4351 (0.3971)	mem 12198MB
Train: [38/300][350/971]	eta 0:04:00 lr 0.000001921	time 0.3584 (0.3869)	tot_loss 0.3054 (0.3975)	mem 12198MB
Train: [38/300][400/971]	eta 0:03:39 lr 0.000001921	time 0.3472 (0.3845)	tot_loss 0.3993 (0.3971)	mem 12198MB
Train: [38/300][450/971]	eta 0:03:19 lr 0.000001921	time 0.3577 (0.3834)	tot_loss 0.3705 (0.3966)	mem 12198MB
Train: [38/300][500/971]	eta 0:03:00 lr 0.000001921	time 0.3845 (0.3841)	tot_loss 0.4051 (0.3972)	mem 12198MB
Train: [38/300][550/971]	eta 0:02:41 lr 0.000001920	time 0.3541 (0.3846)	tot_loss 0.2967 (0.3973)	mem 12198MB
Train: [38/300][600/971]	eta 0:02:22 lr 0.000001920	time 0.3849 (0.3835)	tot_loss 0.3550 (0.3971)	mem 12198MB
Train: [38/300][650/971]	eta 0:02:03 lr 0.000001920	time 0.3530 (0.3835)	tot_loss 0.4030 (0.3971)	mem 12198MB
Train: [38/300][700/971]	eta 0:01:43 lr 0.000001920	time 0.3563 (0.3828)	tot_loss 0.4685 (0.3974)	mem 12198MB
Train: [38/300][750/971]	eta 0:01:24 lr 0.000001920	time 0.3813 (0.3825)	tot_loss 0.3161 (0.3965)	mem 12198MB
Train: [38/300][800/971]	eta 0:01:05 lr 0.000001919	time 0.3490 (0.3835)	tot_loss 0.4480 (0.3971)	mem 12198MB
Train: [38/300][850/971]	eta 0:00:46 lr 0.000001919	time 0.3514 (0.3826)	tot_loss 0.4223 (0.3974)	mem 12198MB
Train: [38/300][900/971]	eta 0:00:27 lr 0.000001919	time 0.3510 (0.3821)	tot_loss 0.4319 (0.3973)	mem 12198MB
Train: [38/300][950/971]	eta 0:00:08 lr 0.000001919	time 0.3363 (0.3813)	tot_loss 0.4212 (0.3972)	mem 12198MB
EPOCH 38 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 53.922	
Test: [100/3923]	Acc@1: 52.970	
Test: [150/3923]	Acc@1: 51.656	
Test: [200/3923]	Acc@1: 49.751	
Test: [250/3923]	Acc@1: 50.199	
Test: [300/3923]	Acc@1: 51.163	
Test: [350/3923]	Acc@1: 50.427	
Test: [400/3923]	Acc@1: 50.374	
Test: [450/3923]	Acc@1: 49.557	
Test: [500/3923]	Acc@1: 49.102	
Test: [550/3923]	Acc@1: 48.820	
Test: [600/3923]	Acc@1: 49.085	
Test: [650/3923]	Acc@1: 49.232	
Test: [700/3923]	Acc@1: 48.859	
Test: [750/3923]	Acc@1: 49.401	
Test: [800/3923]	Acc@1: 49.750	
Test: [850/3923]	Acc@1: 49.824	
Test: [900/3923]	Acc@1: 49.667	
Test: [950/3923]	Acc@1: 49.790	
Test: [1000/3923]	Acc@1: 49.550	
Test: [1050/3923]	Acc@1: 49.429	
Test: [1100/3923]	Acc@1: 48.910	
Test: [1150/3923]	Acc@1: 48.653	
Test: [1200/3923]	Acc@1: 48.543	
Test: [1250/3923]	Acc@1: 48.481	
Test: [1300/3923]	Acc@1: 48.386	
Test: [1350/3923]	Acc@1: 48.557	
Test: [1400/3923]	Acc@1: 48.715	
Test: [1450/3923]	Acc@1: 48.863	
Test: [1500/3923]	Acc@1: 49.167	
Test: [1550/3923]	Acc@1: 49.162	
Test: [1600/3923]	Acc@1: 49.032	
Test: [1650/3923]	Acc@1: 49.425	
Test: [1700/3923]	Acc@1: 49.618	
Test: [1750/3923]	Acc@1: 49.686	
Test: [1800/3923]	Acc@1: 49.778	
Test: [1850/3923]	Acc@1: 49.811	
Test: [1900/3923]	Acc@1: 49.947	
Test: [1950/3923]	Acc@1: 50.103	
Test: [2000/3923]	Acc@1: 50.050	
Test: [2050/3923]	Acc@1: 49.951	
Test: [2100/3923]	Acc@1: 49.810	
Test: [2150/3923]	Acc@1: 49.930	
Test: [2200/3923]	Acc@1: 49.977	
Test: [2250/3923]	Acc@1: 49.889	
Test: [2300/3923]	Acc@1: 49.913	
Test: [2350/3923]	Acc@1: 49.957	
Test: [2400/3923]	Acc@1: 49.792	
Test: [2450/3923]	Acc@1: 49.816	
Test: [2500/3923]	Acc@1: 49.920	
Test: [2550/3923]	Acc@1: 49.824	
Test: [2600/3923]	Acc@1: 49.750	
Test: [2650/3923]	Acc@1: 49.717	
Test: [2700/3923]	Acc@1: 49.796	
Test: [2750/3923]	Acc@1: 49.746	
Test: [2800/3923]	Acc@1: 49.643	
Test: [2850/3923]	Acc@1: 49.737	
Test: [2900/3923]	Acc@1: 49.793	
Test: [2950/3923]	Acc@1: 49.780	
Test: [3000/3923]	Acc@1: 49.850	
Test: [3050/3923]	Acc@1: 49.918	
Test: [3100/3923]	Acc@1: 49.903	
Test: [3150/3923]	Acc@1: 49.794	
Test: [3200/3923]	Acc@1: 49.766	
Test: [3250/3923]	Acc@1: 49.892	
Test: [3300/3923]	Acc@1: 49.894	
Test: [3350/3923]	Acc@1: 50.000	
Test: [3400/3923]	Acc@1: 49.838	
Test: [3450/3923]	Acc@1: 49.870	
Test: [3500/3923]	Acc@1: 49.871	
Test: [3550/3923]	Acc@1: 50.014	
Test: [3600/3923]	Acc@1: 49.931	
Test: [3650/3923]	Acc@1: 49.863	
Test: [3700/3923]	Acc@1: 49.892	
Test: [3750/3923]	Acc@1: 49.933	
Test: [3800/3923]	Acc@1: 49.908	
Test: [3850/3923]	Acc@1: 49.909	
Test: [3900/3923]	Acc@1: 49.859	
 * Acc@1 49.834 Acc@5 94.558 UAR 40.583Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :40.58%Train: [39/300][0/971]	eta 1:11:14 lr 0.000001919	time 4.4022 (4.4022)	tot_loss 0.3987 (0.3987)	mem 12198MB
Train: [39/300][50/971]	eta 0:07:08 lr 0.000001918	time 0.3450 (0.4652)	tot_loss 0.4049 (0.3891)	mem 12198MB
Train: [39/300][100/971]	eta 0:06:09 lr 0.000001918	time 0.3536 (0.4247)	tot_loss 0.4027 (0.3913)	mem 12198MB
Train: [39/300][150/971]	eta 0:05:35 lr 0.000001918	time 0.3562 (0.4087)	tot_loss 0.4274 (0.3934)	mem 12198MB
Train: [39/300][200/971]	eta 0:05:10 lr 0.000001918	time 0.3679 (0.4024)	tot_loss 0.3790 (0.3933)	mem 12198MB
Train: [39/300][250/971]	eta 0:04:46 lr 0.000001918	time 0.3534 (0.3970)	tot_loss 0.4575 (0.3950)	mem 12198MB
Train: [39/300][300/971]	eta 0:04:24 lr 0.000001917	time 0.3466 (0.3948)	tot_loss 0.4298 (0.3954)	mem 12198MB
Train: [39/300][350/971]	eta 0:04:03 lr 0.000001917	time 0.5255 (0.3919)	tot_loss 0.3548 (0.3963)	mem 12198MB
Train: [39/300][400/971]	eta 0:03:42 lr 0.000001917	time 0.3534 (0.3898)	tot_loss 0.3912 (0.3959)	mem 12198MB
Train: [39/300][450/971]	eta 0:03:21 lr 0.000001917	time 0.3466 (0.3876)	tot_loss 0.4197 (0.3958)	mem 12198MB
Train: [39/300][500/971]	eta 0:03:01 lr 0.000001916	time 0.3547 (0.3861)	tot_loss 0.4168 (0.3960)	mem 12198MB
Train: [39/300][550/971]	eta 0:02:42 lr 0.000001916	time 0.3696 (0.3851)	tot_loss 0.4024 (0.3961)	mem 12198MB
Train: [39/300][600/971]	eta 0:02:22 lr 0.000001916	time 0.3506 (0.3842)	tot_loss 0.3908 (0.3960)	mem 12198MB
Train: [39/300][650/971]	eta 0:02:02 lr 0.000001916	time 0.3413 (0.3827)	tot_loss 0.3800 (0.3965)	mem 12198MB
Train: [39/300][700/971]	eta 0:01:43 lr 0.000001916	time 0.3421 (0.3817)	tot_loss 0.3728 (0.3966)	mem 12198MB
Train: [39/300][750/971]	eta 0:01:24 lr 0.000001915	time 0.3620 (0.3811)	tot_loss 0.4398 (0.3972)	mem 12198MB
Train: [39/300][800/971]	eta 0:01:05 lr 0.000001915	time 0.3775 (0.3807)	tot_loss 0.4031 (0.3981)	mem 12198MB
Train: [39/300][850/971]	eta 0:00:46 lr 0.000001915	time 0.3540 (0.3810)	tot_loss 0.3700 (0.3978)	mem 12198MB
Train: [39/300][900/971]	eta 0:00:27 lr 0.000001915	time 0.3488 (0.3804)	tot_loss 0.3710 (0.3973)	mem 12198MB
Train: [39/300][950/971]	eta 0:00:07 lr 0.000001915	time 0.3431 (0.3798)	tot_loss 0.3264 (0.3972)	mem 12198MB
EPOCH 39 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 53.922	
Test: [100/3923]	Acc@1: 52.475	
Test: [150/3923]	Acc@1: 50.662	
Test: [200/3923]	Acc@1: 50.746	
Test: [250/3923]	Acc@1: 51.594	
Test: [300/3923]	Acc@1: 52.658	
Test: [350/3923]	Acc@1: 52.422	
Test: [400/3923]	Acc@1: 51.621	
Test: [450/3923]	Acc@1: 51.220	
Test: [500/3923]	Acc@1: 52.295	
Test: [550/3923]	Acc@1: 51.452	
Test: [600/3923]	Acc@1: 50.582	
Test: [650/3923]	Acc@1: 50.768	
Test: [700/3923]	Acc@1: 50.071	
Test: [750/3923]	Acc@1: 50.067	
Test: [800/3923]	Acc@1: 50.000	
Test: [850/3923]	Acc@1: 49.354	
Test: [900/3923]	Acc@1: 49.445	
Test: [950/3923]	Acc@1: 49.527	
Test: [1000/3923]	Acc@1: 49.451	
Test: [1050/3923]	Acc@1: 49.286	
Test: [1100/3923]	Acc@1: 49.410	
Test: [1150/3923]	Acc@1: 49.392	
Test: [1200/3923]	Acc@1: 49.625	
Test: [1250/3923]	Acc@1: 49.960	
Test: [1300/3923]	Acc@1: 50.154	
Test: [1350/3923]	Acc@1: 50.185	
Test: [1400/3923]	Acc@1: 50.178	
Test: [1450/3923]	Acc@1: 50.000	
Test: [1500/3923]	Acc@1: 49.800	
Test: [1550/3923]	Acc@1: 49.774	
Test: [1600/3923]	Acc@1: 50.000	
Test: [1650/3923]	Acc@1: 50.182	
Test: [1700/3923]	Acc@1: 50.323	
Test: [1750/3923]	Acc@1: 50.543	
Test: [1800/3923]	Acc@1: 50.500	
Test: [1850/3923]	Acc@1: 50.486	
Test: [1900/3923]	Acc@1: 50.447	
Test: [1950/3923]	Acc@1: 50.487	
Test: [2000/3923]	Acc@1: 50.425	
Test: [2050/3923]	Acc@1: 50.414	
Test: [2100/3923]	Acc@1: 50.405	
Test: [2150/3923]	Acc@1: 50.232	
Test: [2200/3923]	Acc@1: 50.432	
Test: [2250/3923]	Acc@1: 50.333	
Test: [2300/3923]	Acc@1: 50.369	
Test: [2350/3923]	Acc@1: 50.425	
Test: [2400/3923]	Acc@1: 50.229	
Test: [2450/3923]	Acc@1: 50.265	
Test: [2500/3923]	Acc@1: 50.280	
Test: [2550/3923]	Acc@1: 50.196	
Test: [2600/3923]	Acc@1: 50.135	
Test: [2650/3923]	Acc@1: 50.207	
Test: [2700/3923]	Acc@1: 50.074	
Test: [2750/3923]	Acc@1: 50.018	
Test: [2800/3923]	Acc@1: 50.107	
Test: [2850/3923]	Acc@1: 49.877	
Test: [2900/3923]	Acc@1: 49.966	
Test: [2950/3923]	Acc@1: 49.898	
Test: [3000/3923]	Acc@1: 49.817	
Test: [3050/3923]	Acc@1: 49.820	
Test: [3100/3923]	Acc@1: 49.790	
Test: [3150/3923]	Acc@1: 49.635	
Test: [3200/3923]	Acc@1: 49.625	
Test: [3250/3923]	Acc@1: 49.631	
Test: [3300/3923]	Acc@1: 49.591	
Test: [3350/3923]	Acc@1: 49.657	
Test: [3400/3923]	Acc@1: 49.677	
Test: [3450/3923]	Acc@1: 49.710	
Test: [3500/3923]	Acc@1: 49.629	
Test: [3550/3923]	Acc@1: 49.817	
Test: [3600/3923]	Acc@1: 49.889	
Test: [3650/3923]	Acc@1: 49.945	
Test: [3700/3923]	Acc@1: 49.892	
Test: [3750/3923]	Acc@1: 49.947	
Test: [3800/3923]	Acc@1: 49.934	
Test: [3850/3923]	Acc@1: 49.857	
Test: [3900/3923]	Acc@1: 50.013	
 * Acc@1 50.025 Acc@5 94.749 UAR 40.347Accuracy of the network on the 7847 test videos: 50.0%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :40.58%Train: [40/300][0/971]	eta 1:12:48 lr 0.000001914	time 4.4987 (4.4987)	tot_loss 0.3927 (0.3927)	mem 12198MB
Train: [40/300][50/971]	eta 0:07:03 lr 0.000001914	time 0.3644 (0.4602)	tot_loss 0.3702 (0.4017)	mem 12198MB
Train: [40/300][100/971]	eta 0:06:02 lr 0.000001914	time 0.3496 (0.4160)	tot_loss 0.3579 (0.3970)	mem 12198MB
Train: [40/300][150/971]	eta 0:05:28 lr 0.000001914	time 0.3433 (0.3996)	tot_loss 0.4063 (0.3960)	mem 12198MB
Train: [40/300][200/971]	eta 0:05:03 lr 0.000001914	time 0.3794 (0.3939)	tot_loss 0.3304 (0.3954)	mem 12198MB
Train: [40/300][250/971]	eta 0:04:42 lr 0.000001913	time 0.3511 (0.3916)	tot_loss 0.3819 (0.3959)	mem 12198MB
Train: [40/300][300/971]	eta 0:04:22 lr 0.000001913	time 0.3882 (0.3912)	tot_loss 0.3917 (0.3966)	mem 12198MB
Train: [40/300][350/971]	eta 0:04:01 lr 0.000001913	time 0.3481 (0.3885)	tot_loss 0.4434 (0.3969)	mem 12198MB
Train: [40/300][400/971]	eta 0:03:40 lr 0.000001913	time 0.3591 (0.3865)	tot_loss 0.3970 (0.3966)	mem 12198MB
Train: [40/300][450/971]	eta 0:03:20 lr 0.000001912	time 0.3510 (0.3851)	tot_loss 0.3315 (0.3961)	mem 12198MB
Train: [40/300][500/971]	eta 0:03:01 lr 0.000001912	time 0.3507 (0.3853)	tot_loss 0.3672 (0.3959)	mem 12198MB
Train: [40/300][550/971]	eta 0:02:41 lr 0.000001912	time 0.3520 (0.3842)	tot_loss 0.4204 (0.3965)	mem 12198MB
Train: [40/300][600/971]	eta 0:02:22 lr 0.000001912	time 0.3494 (0.3835)	tot_loss 0.3924 (0.3969)	mem 12198MB
Train: [40/300][650/971]	eta 0:02:02 lr 0.000001912	time 0.3533 (0.3829)	tot_loss 0.4617 (0.3971)	mem 12198MB
Train: [40/300][700/971]	eta 0:01:43 lr 0.000001911	time 0.3931 (0.3826)	tot_loss 0.4027 (0.3972)	mem 12198MB
Train: [40/300][750/971]	eta 0:01:24 lr 0.000001911	time 0.3405 (0.3821)	tot_loss 0.3724 (0.3970)	mem 12198MB
Train: [40/300][800/971]	eta 0:01:05 lr 0.000001911	time 0.3533 (0.3813)	tot_loss 0.3812 (0.3970)	mem 12198MB
Train: [40/300][850/971]	eta 0:00:46 lr 0.000001911	time 0.3585 (0.3806)	tot_loss 0.4097 (0.3970)	mem 12198MB
Train: [40/300][900/971]	eta 0:00:27 lr 0.000001910	time 0.3768 (0.3803)	tot_loss 0.3677 (0.3971)	mem 12198MB
Train: [40/300][950/971]	eta 0:00:07 lr 0.000001910	time 0.3429 (0.3802)	tot_loss 0.4203 (0.3977)	mem 12198MB
EPOCH 40 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 49.020	
Test: [100/3923]	Acc@1: 54.455	
Test: [150/3923]	Acc@1: 49.669	
Test: [200/3923]	Acc@1: 47.761	
Test: [250/3923]	Acc@1: 49.004	
Test: [300/3923]	Acc@1: 49.668	
Test: [350/3923]	Acc@1: 48.718	
Test: [400/3923]	Acc@1: 47.506	
Test: [450/3923]	Acc@1: 47.450	
Test: [500/3923]	Acc@1: 47.705	
Test: [550/3923]	Acc@1: 48.730	
Test: [600/3923]	Acc@1: 48.835	
Test: [650/3923]	Acc@1: 48.848	
Test: [700/3923]	Acc@1: 49.358	
Test: [750/3923]	Acc@1: 49.334	
Test: [800/3923]	Acc@1: 49.376	
Test: [850/3923]	Acc@1: 50.235	
Test: [900/3923]	Acc@1: 50.277	
Test: [950/3923]	Acc@1: 50.210	
Test: [1000/3923]	Acc@1: 50.250	
Test: [1050/3923]	Acc@1: 50.190	
Test: [1100/3923]	Acc@1: 49.909	
Test: [1150/3923]	Acc@1: 49.739	
Test: [1200/3923]	Acc@1: 49.958	
Test: [1250/3923]	Acc@1: 49.720	
Test: [1300/3923]	Acc@1: 49.731	
Test: [1350/3923]	Acc@1: 49.667	
Test: [1400/3923]	Acc@1: 49.286	
Test: [1450/3923]	Acc@1: 49.518	
Test: [1500/3923]	Acc@1: 49.534	
Test: [1550/3923]	Acc@1: 49.420	
Test: [1600/3923]	Acc@1: 49.469	
Test: [1650/3923]	Acc@1: 49.637	
Test: [1700/3923]	Acc@1: 49.706	
Test: [1750/3923]	Acc@1: 49.572	
Test: [1800/3923]	Acc@1: 49.806	
Test: [1850/3923]	Acc@1: 49.730	
Test: [1900/3923]	Acc@1: 49.737	
Test: [1950/3923]	Acc@1: 49.692	
Test: [2000/3923]	Acc@1: 49.750	
Test: [2050/3923]	Acc@1: 49.805	
Test: [2100/3923]	Acc@1: 49.810	
Test: [2150/3923]	Acc@1: 49.768	
Test: [2200/3923]	Acc@1: 49.750	
Test: [2250/3923]	Acc@1: 49.600	
Test: [2300/3923]	Acc@1: 49.544	
Test: [2350/3923]	Acc@1: 49.553	
Test: [2400/3923]	Acc@1: 49.729	
Test: [2450/3923]	Acc@1: 49.612	
Test: [2500/3923]	Acc@1: 49.600	
Test: [2550/3923]	Acc@1: 49.530	
Test: [2600/3923]	Acc@1: 49.616	
Test: [2650/3923]	Acc@1: 49.453	
Test: [2700/3923]	Acc@1: 49.500	
Test: [2750/3923]	Acc@1: 49.618	
Test: [2800/3923]	Acc@1: 49.643	
Test: [2850/3923]	Acc@1: 49.772	
Test: [2900/3923]	Acc@1: 49.810	
Test: [2950/3923]	Acc@1: 49.797	
Test: [3000/3923]	Acc@1: 49.733	
Test: [3050/3923]	Acc@1: 49.934	
Test: [3100/3923]	Acc@1: 50.016	
Test: [3150/3923]	Acc@1: 50.000	
Test: [3200/3923]	Acc@1: 49.953	
Test: [3250/3923]	Acc@1: 49.985	
Test: [3300/3923]	Acc@1: 50.000	
Test: [3350/3923]	Acc@1: 49.955	
Test: [3400/3923]	Acc@1: 49.971	
Test: [3450/3923]	Acc@1: 50.058	
Test: [3500/3923]	Acc@1: 50.057	
Test: [3550/3923]	Acc@1: 50.113	
Test: [3600/3923]	Acc@1: 50.069	
Test: [3650/3923]	Acc@1: 50.068	
Test: [3700/3923]	Acc@1: 50.122	
Test: [3750/3923]	Acc@1: 50.093	
Test: [3800/3923]	Acc@1: 49.987	
Test: [3850/3923]	Acc@1: 49.883	
Test: [3900/3923]	Acc@1: 49.974	
 * Acc@1 49.962 Acc@5 94.392 UAR 39.842Accuracy of the network on the 7847 test videos: 50.0%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :40.58%Train: [41/300][0/971]	eta 1:26:24 lr 0.000001910	time 5.3397 (5.3397)	tot_loss 0.4163 (0.4163)	mem 12198MB
Train: [41/300][50/971]	eta 0:07:25 lr 0.000001910	time 0.3558 (0.4835)	tot_loss 0.3960 (0.3988)	mem 12198MB
Train: [41/300][100/971]	eta 0:06:12 lr 0.000001910	time 0.3729 (0.4280)	tot_loss 0.3892 (0.3962)	mem 12198MB
Train: [41/300][150/971]	eta 0:05:37 lr 0.000001909	time 0.3671 (0.4109)	tot_loss 0.3679 (0.3976)	mem 12198MB
Train: [41/300][200/971]	eta 0:05:11 lr 0.000001909	time 0.3841 (0.4040)	tot_loss 0.3940 (0.3978)	mem 12198MB
Train: [41/300][250/971]	eta 0:04:46 lr 0.000001909	time 0.3515 (0.3971)	tot_loss 0.3834 (0.3976)	mem 12198MB
Train: [41/300][300/971]	eta 0:04:23 lr 0.000001909	time 0.3511 (0.3926)	tot_loss 0.3982 (0.3977)	mem 12198MB
Train: [41/300][350/971]	eta 0:04:02 lr 0.000001909	time 0.3516 (0.3898)	tot_loss 0.3648 (0.3960)	mem 12198MB
Train: [41/300][400/971]	eta 0:03:41 lr 0.000001908	time 0.3447 (0.3879)	tot_loss 0.4206 (0.3959)	mem 12198MB
Train: [41/300][450/971]	eta 0:03:20 lr 0.000001908	time 0.3579 (0.3856)	tot_loss 0.3844 (0.3961)	mem 12198MB
Train: [41/300][500/971]	eta 0:03:01 lr 0.000001908	time 0.3590 (0.3846)	tot_loss 0.3844 (0.3964)	mem 12198MB
Train: [41/300][550/971]	eta 0:02:41 lr 0.000001908	time 0.3589 (0.3833)	tot_loss 0.4804 (0.3962)	mem 12198MB
Train: [41/300][600/971]	eta 0:02:21 lr 0.000001907	time 0.3526 (0.3827)	tot_loss 0.3940 (0.3953)	mem 12198MB
Train: [41/300][650/971]	eta 0:02:02 lr 0.000001907	time 0.3491 (0.3817)	tot_loss 0.4485 (0.3943)	mem 12198MB
Train: [41/300][700/971]	eta 0:01:43 lr 0.000001907	time 0.3533 (0.3810)	tot_loss 0.3516 (0.3941)	mem 12198MB
Train: [41/300][750/971]	eta 0:01:24 lr 0.000001907	time 0.3536 (0.3802)	tot_loss 0.3770 (0.3940)	mem 12198MB
Train: [41/300][800/971]	eta 0:01:05 lr 0.000001907	time 0.3460 (0.3805)	tot_loss 0.4304 (0.3942)	mem 12198MB
Train: [41/300][850/971]	eta 0:00:45 lr 0.000001906	time 0.3586 (0.3799)	tot_loss 0.3946 (0.3941)	mem 12198MB
Train: [41/300][900/971]	eta 0:00:26 lr 0.000001906	time 0.3495 (0.3794)	tot_loss 0.4089 (0.3945)	mem 12198MB
Train: [41/300][950/971]	eta 0:00:07 lr 0.000001906	time 0.3354 (0.3790)	tot_loss 0.4244 (0.3945)	mem 12198MB
EPOCH 41 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 49.020	
Test: [100/3923]	Acc@1: 52.475	
Test: [150/3923]	Acc@1: 50.331	
Test: [200/3923]	Acc@1: 49.502	
Test: [250/3923]	Acc@1: 50.398	
Test: [300/3923]	Acc@1: 49.502	
Test: [350/3923]	Acc@1: 48.291	
Test: [400/3923]	Acc@1: 48.753	
Test: [450/3923]	Acc@1: 48.780	
Test: [500/3923]	Acc@1: 49.102	
Test: [550/3923]	Acc@1: 48.548	
Test: [600/3923]	Acc@1: 48.586	
Test: [650/3923]	Acc@1: 48.464	
Test: [700/3923]	Acc@1: 48.645	
Test: [750/3923]	Acc@1: 48.868	
Test: [800/3923]	Acc@1: 48.689	
Test: [850/3923]	Acc@1: 48.766	
Test: [900/3923]	Acc@1: 48.724	
Test: [950/3923]	Acc@1: 48.686	
Test: [1000/3923]	Acc@1: 48.501	
Test: [1050/3923]	Acc@1: 48.097	
Test: [1100/3923]	Acc@1: 48.138	
Test: [1150/3923]	Acc@1: 48.393	
Test: [1200/3923]	Acc@1: 48.376	
Test: [1250/3923]	Acc@1: 48.321	
Test: [1300/3923]	Acc@1: 48.271	
Test: [1350/3923]	Acc@1: 48.409	
Test: [1400/3923]	Acc@1: 48.358	
Test: [1450/3923]	Acc@1: 48.553	
Test: [1500/3923]	Acc@1: 48.601	
Test: [1550/3923]	Acc@1: 48.517	
Test: [1600/3923]	Acc@1: 48.563	
Test: [1650/3923]	Acc@1: 48.577	
Test: [1700/3923]	Acc@1: 48.501	
Test: [1750/3923]	Acc@1: 48.429	
Test: [1800/3923]	Acc@1: 48.640	
Test: [1850/3923]	Acc@1: 48.703	
Test: [1900/3923]	Acc@1: 48.711	
Test: [1950/3923]	Acc@1: 48.539	
Test: [2000/3923]	Acc@1: 48.601	
Test: [2050/3923]	Acc@1: 48.708	
Test: [2100/3923]	Acc@1: 48.739	
Test: [2150/3923]	Acc@1: 48.675	
Test: [2200/3923]	Acc@1: 48.682	
Test: [2250/3923]	Acc@1: 48.556	
Test: [2300/3923]	Acc@1: 48.588	
Test: [2350/3923]	Acc@1: 48.533	
Test: [2400/3923]	Acc@1: 48.542	
Test: [2450/3923]	Acc@1: 48.572	
Test: [2500/3923]	Acc@1: 48.521	
Test: [2550/3923]	Acc@1: 48.589	
Test: [2600/3923]	Acc@1: 48.424	
Test: [2650/3923]	Acc@1: 48.510	
Test: [2700/3923]	Acc@1: 48.519	
Test: [2750/3923]	Acc@1: 48.637	
Test: [2800/3923]	Acc@1: 48.483	
Test: [2850/3923]	Acc@1: 48.597	
Test: [2900/3923]	Acc@1: 48.828	
Test: [2950/3923]	Acc@1: 48.933	
Test: [3000/3923]	Acc@1: 49.067	
Test: [3050/3923]	Acc@1: 49.115	
Test: [3100/3923]	Acc@1: 49.129	
Test: [3150/3923]	Acc@1: 49.175	
Test: [3200/3923]	Acc@1: 49.110	
Test: [3250/3923]	Acc@1: 49.093	
Test: [3300/3923]	Acc@1: 49.228	
Test: [3350/3923]	Acc@1: 49.164	
Test: [3400/3923]	Acc@1: 49.162	
Test: [3450/3923]	Acc@1: 49.189	
Test: [3500/3923]	Acc@1: 49.272	
Test: [3550/3923]	Acc@1: 49.240	
Test: [3600/3923]	Acc@1: 49.236	
Test: [3650/3923]	Acc@1: 49.206	
Test: [3700/3923]	Acc@1: 49.189	
Test: [3750/3923]	Acc@1: 49.094	
Test: [3800/3923]	Acc@1: 49.040	
Test: [3850/3923]	Acc@1: 49.130	
Test: [3900/3923]	Acc@1: 49.180	
 * Acc@1 49.146 Acc@5 94.647 UAR 39.535Accuracy of the network on the 7847 test videos: 49.1%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :40.58%Train: [42/300][0/971]	eta 1:19:54 lr 0.000001906	time 4.9376 (4.9376)	tot_loss 0.4203 (0.4203)	mem 12198MB
Train: [42/300][50/971]	eta 0:07:13 lr 0.000001906	time 0.3470 (0.4709)	tot_loss 0.3920 (0.3983)	mem 12198MB
Train: [42/300][100/971]	eta 0:06:09 lr 0.000001905	time 0.3902 (0.4240)	tot_loss 0.3475 (0.3967)	mem 12198MB
Train: [42/300][150/971]	eta 0:05:34 lr 0.000001905	time 0.3526 (0.4077)	tot_loss 0.4199 (0.3968)	mem 12198MB
Train: [42/300][200/971]	eta 0:05:09 lr 0.000001905	time 0.3531 (0.4011)	tot_loss 0.4131 (0.3960)	mem 12198MB
Train: [42/300][250/971]	eta 0:04:44 lr 0.000001905	time 0.3592 (0.3943)	tot_loss 0.3383 (0.3965)	mem 12198MB
Train: [42/300][300/971]	eta 0:04:22 lr 0.000001904	time 0.3496 (0.3919)	tot_loss 0.3498 (0.3969)	mem 12198MB
Train: [42/300][350/971]	eta 0:04:02 lr 0.000001904	time 0.3798 (0.3908)	tot_loss 0.4543 (0.3963)	mem 12198MB
Train: [42/300][400/971]	eta 0:03:41 lr 0.000001904	time 0.3610 (0.3881)	tot_loss 0.4480 (0.3948)	mem 12198MB
Train: [42/300][450/971]	eta 0:03:21 lr 0.000001904	time 0.3505 (0.3867)	tot_loss 0.3293 (0.3945)	mem 12198MB
Train: [42/300][500/971]	eta 0:03:01 lr 0.000001903	time 0.3697 (0.3864)	tot_loss 0.4408 (0.3941)	mem 12198MB
Train: [42/300][550/971]	eta 0:02:42 lr 0.000001903	time 0.3538 (0.3851)	tot_loss 0.4197 (0.3939)	mem 12198MB
Train: [42/300][600/971]	eta 0:02:22 lr 0.000001903	time 0.3815 (0.3841)	tot_loss 0.4107 (0.3939)	mem 12198MB
Train: [42/300][650/971]	eta 0:02:03 lr 0.000001903	time 0.3528 (0.3840)	tot_loss 0.3737 (0.3941)	mem 12198MB
Train: [42/300][700/971]	eta 0:01:44 lr 0.000001903	time 0.3930 (0.3839)	tot_loss 0.4800 (0.3940)	mem 12198MB
Train: [42/300][750/971]	eta 0:01:25 lr 0.000001902	time 0.3596 (0.3850)	tot_loss 0.4241 (0.3945)	mem 12198MB
Train: [42/300][800/971]	eta 0:01:05 lr 0.000001902	time 0.3608 (0.3843)	tot_loss 0.3657 (0.3947)	mem 12198MB
Train: [42/300][850/971]	eta 0:00:46 lr 0.000001902	time 0.3695 (0.3840)	tot_loss 0.3944 (0.3943)	mem 12198MB
Train: [42/300][900/971]	eta 0:00:27 lr 0.000001902	time 0.3686 (0.3837)	tot_loss 0.3782 (0.3946)	mem 12198MB
Train: [42/300][950/971]	eta 0:00:08 lr 0.000001901	time 0.3362 (0.3829)	tot_loss 0.3822 (0.3951)	mem 12198MB
EPOCH 42 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 52.941	
Test: [100/3923]	Acc@1: 52.475	
Test: [150/3923]	Acc@1: 52.649	
Test: [200/3923]	Acc@1: 52.239	
Test: [250/3923]	Acc@1: 53.386	
Test: [300/3923]	Acc@1: 52.658	
Test: [350/3923]	Acc@1: 52.564	
Test: [400/3923]	Acc@1: 52.494	
Test: [450/3923]	Acc@1: 51.441	
Test: [500/3923]	Acc@1: 50.499	
Test: [550/3923]	Acc@1: 50.998	
Test: [600/3923]	Acc@1: 50.915	
Test: [650/3923]	Acc@1: 50.691	
Test: [700/3923]	Acc@1: 51.070	
Test: [750/3923]	Acc@1: 51.265	
Test: [800/3923]	Acc@1: 51.623	
Test: [850/3923]	Acc@1: 51.586	
Test: [900/3923]	Acc@1: 51.942	
Test: [950/3923]	Acc@1: 51.998	
Test: [1000/3923]	Acc@1: 51.998	
Test: [1050/3923]	Acc@1: 52.426	
Test: [1100/3923]	Acc@1: 52.407	
Test: [1150/3923]	Acc@1: 51.781	
Test: [1200/3923]	Acc@1: 51.873	
Test: [1250/3923]	Acc@1: 51.359	
Test: [1300/3923]	Acc@1: 51.268	
Test: [1350/3923]	Acc@1: 51.406	
Test: [1400/3923]	Acc@1: 51.178	
Test: [1450/3923]	Acc@1: 51.241	
Test: [1500/3923]	Acc@1: 51.266	
Test: [1550/3923]	Acc@1: 51.096	
Test: [1600/3923]	Acc@1: 51.031	
Test: [1650/3923]	Acc@1: 50.909	
Test: [1700/3923]	Acc@1: 50.764	
Test: [1750/3923]	Acc@1: 50.657	
Test: [1800/3923]	Acc@1: 50.639	
Test: [1850/3923]	Acc@1: 50.621	
Test: [1900/3923]	Acc@1: 50.500	
Test: [1950/3923]	Acc@1: 50.436	
Test: [2000/3923]	Acc@1: 50.350	
Test: [2050/3923]	Acc@1: 50.390	
Test: [2100/3923]	Acc@1: 50.143	
Test: [2150/3923]	Acc@1: 50.000	
Test: [2200/3923]	Acc@1: 50.204	
Test: [2250/3923]	Acc@1: 50.200	
Test: [2300/3923]	Acc@1: 50.217	
Test: [2350/3923]	Acc@1: 50.255	
Test: [2400/3923]	Acc@1: 50.396	
Test: [2450/3923]	Acc@1: 50.408	
Test: [2500/3923]	Acc@1: 50.380	
Test: [2550/3923]	Acc@1: 50.255	
Test: [2600/3923]	Acc@1: 50.365	
Test: [2650/3923]	Acc@1: 50.472	
Test: [2700/3923]	Acc@1: 50.555	
Test: [2750/3923]	Acc@1: 50.527	
Test: [2800/3923]	Acc@1: 50.625	
Test: [2850/3923]	Acc@1: 50.631	
Test: [2900/3923]	Acc@1: 50.724	
Test: [2950/3923]	Acc@1: 50.762	
Test: [3000/3923]	Acc@1: 50.666	
Test: [3050/3923]	Acc@1: 50.852	
Test: [3100/3923]	Acc@1: 50.806	
Test: [3150/3923]	Acc@1: 50.793	
Test: [3200/3923]	Acc@1: 50.734	
Test: [3250/3923]	Acc@1: 50.677	
Test: [3300/3923]	Acc@1: 50.697	
Test: [3350/3923]	Acc@1: 50.597	
Test: [3400/3923]	Acc@1: 50.485	
Test: [3450/3923]	Acc@1: 50.464	
Test: [3500/3923]	Acc@1: 50.528	
Test: [3550/3923]	Acc@1: 50.535	
Test: [3600/3923]	Acc@1: 50.583	
Test: [3650/3923]	Acc@1: 50.603	
Test: [3700/3923]	Acc@1: 50.540	
Test: [3750/3923]	Acc@1: 50.467	
Test: [3800/3923]	Acc@1: 50.487	
Test: [3850/3923]	Acc@1: 50.636	
Test: [3900/3923]	Acc@1: 50.538	
 * Acc@1 50.586 Acc@5 94.341 UAR 40.013Accuracy of the network on the 7847 test videos: 50.6%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :40.58%Train: [43/300][0/971]	eta 1:24:41 lr 0.000001901	time 5.2334 (5.2334)	tot_loss 0.4345 (0.4345)	mem 12198MB
Train: [43/300][50/971]	eta 0:07:20 lr 0.000001901	time 0.3693 (0.4778)	tot_loss 0.4462 (0.3985)	mem 12198MB
Train: [43/300][100/971]	eta 0:06:12 lr 0.000001901	time 0.3642 (0.4282)	tot_loss 0.4258 (0.4022)	mem 12198MB
Train: [43/300][150/971]	eta 0:05:39 lr 0.000001901	time 0.3523 (0.4135)	tot_loss 0.3312 (0.3990)	mem 12198MB
Train: [43/300][200/971]	eta 0:05:11 lr 0.000001900	time 0.3490 (0.4034)	tot_loss 0.3624 (0.3988)	mem 12198MB
Train: [43/300][250/971]	eta 0:04:46 lr 0.000001900	time 0.3551 (0.3975)	tot_loss 0.3986 (0.3983)	mem 12198MB
Train: [43/300][300/971]	eta 0:04:24 lr 0.000001900	time 0.3468 (0.3940)	tot_loss 0.3460 (0.3983)	mem 12198MB
Train: [43/300][350/971]	eta 0:04:02 lr 0.000001900	time 0.3442 (0.3899)	tot_loss 0.4422 (0.3987)	mem 12198MB
Train: [43/300][400/971]	eta 0:03:41 lr 0.000001899	time 0.3553 (0.3882)	tot_loss 0.4485 (0.3993)	mem 12198MB
Train: [43/300][450/971]	eta 0:03:21 lr 0.000001899	time 0.3566 (0.3865)	tot_loss 0.3877 (0.3988)	mem 12198MB
Train: [43/300][500/971]	eta 0:03:01 lr 0.000001899	time 0.3547 (0.3855)	tot_loss 0.3865 (0.3986)	mem 12198MB
Train: [43/300][550/971]	eta 0:02:41 lr 0.000001899	time 0.3519 (0.3845)	tot_loss 0.4401 (0.3984)	mem 12198MB
Train: [43/300][600/971]	eta 0:02:22 lr 0.000001899	time 0.3633 (0.3836)	tot_loss 0.4103 (0.3973)	mem 12198MB
Train: [43/300][650/971]	eta 0:02:02 lr 0.000001898	time 0.3603 (0.3829)	tot_loss 0.3905 (0.3975)	mem 12198MB
Train: [43/300][700/971]	eta 0:01:43 lr 0.000001898	time 0.3519 (0.3821)	tot_loss 0.3640 (0.3971)	mem 12198MB
Train: [43/300][750/971]	eta 0:01:24 lr 0.000001898	time 0.3533 (0.3816)	tot_loss 0.3420 (0.3969)	mem 12198MB
Train: [43/300][800/971]	eta 0:01:05 lr 0.000001898	time 0.3603 (0.3813)	tot_loss 0.3708 (0.3965)	mem 12198MB
Train: [43/300][850/971]	eta 0:00:46 lr 0.000001897	time 0.3585 (0.3809)	tot_loss 0.3927 (0.3960)	mem 12198MB
Train: [43/300][900/971]	eta 0:00:27 lr 0.000001897	time 0.4091 (0.3806)	tot_loss 0.3070 (0.3963)	mem 12198MB
Train: [43/300][950/971]	eta 0:00:07 lr 0.000001897	time 0.3339 (0.3801)	tot_loss 0.3730 (0.3960)	mem 12198MB
EPOCH 43 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 60.784	
Test: [100/3923]	Acc@1: 54.950	
Test: [150/3923]	Acc@1: 52.980	
Test: [200/3923]	Acc@1: 51.244	
Test: [250/3923]	Acc@1: 50.598	
Test: [300/3923]	Acc@1: 51.827	
Test: [350/3923]	Acc@1: 50.712	
Test: [400/3923]	Acc@1: 49.875	
Test: [450/3923]	Acc@1: 49.667	
Test: [500/3923]	Acc@1: 49.401	
Test: [550/3923]	Acc@1: 48.820	
Test: [600/3923]	Acc@1: 49.251	
Test: [650/3923]	Acc@1: 50.230	
Test: [700/3923]	Acc@1: 50.143	
Test: [750/3923]	Acc@1: 49.933	
Test: [800/3923]	Acc@1: 50.250	
Test: [850/3923]	Acc@1: 50.470	
Test: [900/3923]	Acc@1: 50.666	
Test: [950/3923]	Acc@1: 50.526	
Test: [1000/3923]	Acc@1: 50.350	
Test: [1050/3923]	Acc@1: 50.190	
Test: [1100/3923]	Acc@1: 50.500	
Test: [1150/3923]	Acc@1: 50.695	
Test: [1200/3923]	Acc@1: 50.708	
Test: [1250/3923]	Acc@1: 50.639	
Test: [1300/3923]	Acc@1: 50.692	
Test: [1350/3923]	Acc@1: 50.629	
Test: [1400/3923]	Acc@1: 50.714	
Test: [1450/3923]	Acc@1: 50.620	
Test: [1500/3923]	Acc@1: 50.766	
Test: [1550/3923]	Acc@1: 50.613	
Test: [1600/3923]	Acc@1: 50.750	
Test: [1650/3923]	Acc@1: 50.697	
Test: [1700/3923]	Acc@1: 50.882	
Test: [1750/3923]	Acc@1: 50.771	
Test: [1800/3923]	Acc@1: 50.777	
Test: [1850/3923]	Acc@1: 50.729	
Test: [1900/3923]	Acc@1: 50.789	
Test: [1950/3923]	Acc@1: 50.641	
Test: [2000/3923]	Acc@1: 50.675	
Test: [2050/3923]	Acc@1: 50.731	
Test: [2100/3923]	Acc@1: 50.619	
Test: [2150/3923]	Acc@1: 50.628	
Test: [2200/3923]	Acc@1: 50.591	
Test: [2250/3923]	Acc@1: 50.511	
Test: [2300/3923]	Acc@1: 50.522	
Test: [2350/3923]	Acc@1: 50.553	
Test: [2400/3923]	Acc@1: 50.479	
Test: [2450/3923]	Acc@1: 50.551	
Test: [2500/3923]	Acc@1: 50.600	
Test: [2550/3923]	Acc@1: 50.608	
Test: [2600/3923]	Acc@1: 50.654	
Test: [2650/3923]	Acc@1: 50.641	
Test: [2700/3923]	Acc@1: 50.666	
Test: [2750/3923]	Acc@1: 50.672	
Test: [2800/3923]	Acc@1: 50.500	
Test: [2850/3923]	Acc@1: 50.544	
Test: [2900/3923]	Acc@1: 50.465	
Test: [2950/3923]	Acc@1: 50.457	
Test: [3000/3923]	Acc@1: 50.367	
Test: [3050/3923]	Acc@1: 50.475	
Test: [3100/3923]	Acc@1: 50.500	
Test: [3150/3923]	Acc@1: 50.555	
Test: [3200/3923]	Acc@1: 50.578	
Test: [3250/3923]	Acc@1: 50.554	
Test: [3300/3923]	Acc@1: 50.621	
Test: [3350/3923]	Acc@1: 50.686	
Test: [3400/3923]	Acc@1: 50.573	
Test: [3450/3923]	Acc@1: 50.594	
Test: [3500/3923]	Acc@1: 50.543	
Test: [3550/3923]	Acc@1: 50.479	
Test: [3600/3923]	Acc@1: 50.583	
Test: [3650/3923]	Acc@1: 50.493	
Test: [3700/3923]	Acc@1: 50.405	
Test: [3750/3923]	Acc@1: 50.493	
Test: [3800/3923]	Acc@1: 50.658	
Test: [3850/3923]	Acc@1: 50.584	
Test: [3900/3923]	Acc@1: 50.461	
 * Acc@1 50.497 Acc@5 94.558 UAR 41.086Accuracy of the network on the 7847 test videos: 50.5%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :41.09%Train: [44/300][0/971]	eta 1:27:20 lr 0.000001897	time 5.3970 (5.3970)	tot_loss 0.4362 (0.4362)	mem 12198MB
Train: [44/300][50/971]	eta 0:07:21 lr 0.000001897	time 0.3606 (0.4789)	tot_loss 0.3926 (0.3944)	mem 12198MB
Train: [44/300][100/971]	eta 0:06:15 lr 0.000001896	time 0.3565 (0.4307)	tot_loss 0.3958 (0.3930)	mem 12198MB
Train: [44/300][150/971]	eta 0:05:38 lr 0.000001896	time 0.3547 (0.4124)	tot_loss 0.4273 (0.3955)	mem 12198MB
Train: [44/300][200/971]	eta 0:05:10 lr 0.000001896	time 0.3653 (0.4026)	tot_loss 0.3553 (0.3937)	mem 12198MB
Train: [44/300][250/971]	eta 0:04:46 lr 0.000001896	time 0.3882 (0.3967)	tot_loss 0.4233 (0.3932)	mem 12198MB
Train: [44/300][300/971]	eta 0:04:24 lr 0.000001895	time 0.3495 (0.3940)	tot_loss 0.4342 (0.3939)	mem 12198MB
Train: [44/300][350/971]	eta 0:04:02 lr 0.000001895	time 0.3545 (0.3908)	tot_loss 0.2764 (0.3930)	mem 12198MB
Train: [44/300][400/971]	eta 0:03:41 lr 0.000001895	time 0.3492 (0.3886)	tot_loss 0.4060 (0.3916)	mem 12198MB
Train: [44/300][450/971]	eta 0:03:21 lr 0.000001895	time 0.3537 (0.3869)	tot_loss 0.3762 (0.3919)	mem 12198MB
Train: [44/300][500/971]	eta 0:03:01 lr 0.000001894	time 0.3591 (0.3853)	tot_loss 0.4331 (0.3918)	mem 12198MB
Train: [44/300][550/971]	eta 0:02:41 lr 0.000001894	time 0.3543 (0.3840)	tot_loss 0.4445 (0.3922)	mem 12198MB
Train: [44/300][600/971]	eta 0:02:22 lr 0.000001894	time 0.3454 (0.3832)	tot_loss 0.3114 (0.3924)	mem 12198MB
Train: [44/300][650/971]	eta 0:02:02 lr 0.000001894	time 0.3649 (0.3825)	tot_loss 0.3809 (0.3928)	mem 12198MB
Train: [44/300][700/971]	eta 0:01:43 lr 0.000001893	time 0.3515 (0.3818)	tot_loss 0.3459 (0.3925)	mem 12198MB
Train: [44/300][750/971]	eta 0:01:24 lr 0.000001893	time 0.3473 (0.3812)	tot_loss 0.4613 (0.3926)	mem 12198MB
Train: [44/300][800/971]	eta 0:01:05 lr 0.000001893	time 0.3507 (0.3807)	tot_loss 0.4081 (0.3928)	mem 12198MB
Train: [44/300][850/971]	eta 0:00:45 lr 0.000001893	time 0.3455 (0.3801)	tot_loss 0.3800 (0.3926)	mem 12198MB
Train: [44/300][900/971]	eta 0:00:26 lr 0.000001892	time 0.3631 (0.3797)	tot_loss 0.4422 (0.3931)	mem 12198MB
Train: [44/300][950/971]	eta 0:00:07 lr 0.000001892	time 0.3307 (0.3788)	tot_loss 0.4297 (0.3932)	mem 12198MB
EPOCH 44 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 50.000	
Test: [100/3923]	Acc@1: 52.970	
Test: [150/3923]	Acc@1: 54.305	
Test: [200/3923]	Acc@1: 52.736	
Test: [250/3923]	Acc@1: 52.191	
Test: [300/3923]	Acc@1: 51.495	
Test: [350/3923]	Acc@1: 52.849	
Test: [400/3923]	Acc@1: 53.117	
Test: [450/3923]	Acc@1: 53.326	
Test: [500/3923]	Acc@1: 54.092	
Test: [550/3923]	Acc@1: 53.902	
Test: [600/3923]	Acc@1: 53.328	
Test: [650/3923]	Acc@1: 53.379	
Test: [700/3923]	Acc@1: 53.067	
Test: [750/3923]	Acc@1: 52.929	
Test: [800/3923]	Acc@1: 52.497	
Test: [850/3923]	Acc@1: 52.761	
Test: [900/3923]	Acc@1: 52.442	
Test: [950/3923]	Acc@1: 52.524	
Test: [1000/3923]	Acc@1: 52.098	
Test: [1050/3923]	Acc@1: 52.141	
Test: [1100/3923]	Acc@1: 52.089	
Test: [1150/3923]	Acc@1: 52.042	
Test: [1200/3923]	Acc@1: 52.581	
Test: [1250/3923]	Acc@1: 52.598	
Test: [1300/3923]	Acc@1: 52.690	
Test: [1350/3923]	Acc@1: 52.369	
Test: [1400/3923]	Acc@1: 52.177	
Test: [1450/3923]	Acc@1: 51.999	
Test: [1500/3923]	Acc@1: 52.065	
Test: [1550/3923]	Acc@1: 51.934	
Test: [1600/3923]	Acc@1: 51.780	
Test: [1650/3923]	Acc@1: 51.817	
Test: [1700/3923]	Acc@1: 52.058	
Test: [1750/3923]	Acc@1: 51.799	
Test: [1800/3923]	Acc@1: 51.555	
Test: [1850/3923]	Acc@1: 51.621	
Test: [1900/3923]	Acc@1: 51.420	
Test: [1950/3923]	Acc@1: 51.512	
Test: [2000/3923]	Acc@1: 51.349	
Test: [2050/3923]	Acc@1: 51.414	
Test: [2100/3923]	Acc@1: 51.356	
Test: [2150/3923]	Acc@1: 51.371	
Test: [2200/3923]	Acc@1: 51.227	
Test: [2250/3923]	Acc@1: 51.177	
Test: [2300/3923]	Acc@1: 51.108	
Test: [2350/3923]	Acc@1: 51.021	
Test: [2400/3923]	Acc@1: 50.979	
Test: [2450/3923]	Acc@1: 50.979	
Test: [2500/3923]	Acc@1: 50.800	
Test: [2550/3923]	Acc@1: 50.823	
Test: [2600/3923]	Acc@1: 50.903	
Test: [2650/3923]	Acc@1: 50.849	
Test: [2700/3923]	Acc@1: 50.981	
Test: [2750/3923]	Acc@1: 50.927	
Test: [2800/3923]	Acc@1: 50.910	
Test: [2850/3923]	Acc@1: 50.929	
Test: [2900/3923]	Acc@1: 50.931	
Test: [2950/3923]	Acc@1: 50.796	
Test: [3000/3923]	Acc@1: 50.866	
Test: [3050/3923]	Acc@1: 50.852	
Test: [3100/3923]	Acc@1: 51.000	
Test: [3150/3923]	Acc@1: 51.000	
Test: [3200/3923]	Acc@1: 50.906	
Test: [3250/3923]	Acc@1: 50.892	
Test: [3300/3923]	Acc@1: 50.742	
Test: [3350/3923]	Acc@1: 50.791	
Test: [3400/3923]	Acc@1: 50.764	
Test: [3450/3923]	Acc@1: 50.855	
Test: [3500/3923]	Acc@1: 50.785	
Test: [3550/3923]	Acc@1: 50.789	
Test: [3600/3923]	Acc@1: 50.611	
Test: [3650/3923]	Acc@1: 50.644	
Test: [3700/3923]	Acc@1: 50.608	
Test: [3750/3923]	Acc@1: 50.640	
Test: [3800/3923]	Acc@1: 50.592	
Test: [3850/3923]	Acc@1: 50.532	
Test: [3900/3923]	Acc@1: 50.474	
 * Acc@1 50.459 Acc@5 93.869 UAR 40.765Accuracy of the network on the 7847 test videos: 50.5%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :41.09%Train: [45/300][0/971]	eta 1:15:41 lr 0.000001892	time 4.6774 (4.6774)	tot_loss 0.3990 (0.3990)	mem 12198MB
Train: [45/300][50/971]	eta 0:07:18 lr 0.000001892	time 0.3600 (0.4756)	tot_loss 0.4124 (0.3944)	mem 12198MB
Train: [45/300][100/971]	eta 0:06:13 lr 0.000001892	time 0.3486 (0.4293)	tot_loss 0.4162 (0.3926)	mem 12198MB
Train: [45/300][150/971]	eta 0:05:38 lr 0.000001891	time 0.3623 (0.4126)	tot_loss 0.4311 (0.3944)	mem 12198MB
Train: [45/300][200/971]	eta 0:05:11 lr 0.000001891	time 0.3552 (0.4034)	tot_loss 0.3692 (0.3909)	mem 12198MB
Train: [45/300][250/971]	eta 0:04:46 lr 0.000001891	time 0.3658 (0.3977)	tot_loss 0.4161 (0.3903)	mem 12198MB
Train: [45/300][300/971]	eta 0:04:24 lr 0.000001891	time 0.3526 (0.3936)	tot_loss 0.4538 (0.3901)	mem 12198MB
Train: [45/300][350/971]	eta 0:04:02 lr 0.000001890	time 0.3485 (0.3903)	tot_loss 0.3876 (0.3900)	mem 12198MB
Train: [45/300][400/971]	eta 0:03:41 lr 0.000001890	time 0.3531 (0.3885)	tot_loss 0.4358 (0.3902)	mem 12198MB
Train: [45/300][450/971]	eta 0:03:21 lr 0.000001890	time 0.3427 (0.3867)	tot_loss 0.4094 (0.3916)	mem 12198MB
Train: [45/300][500/971]	eta 0:03:01 lr 0.000001890	time 0.3545 (0.3849)	tot_loss 0.4151 (0.3914)	mem 12198MB
Train: [45/300][550/971]	eta 0:02:41 lr 0.000001889	time 0.3494 (0.3837)	tot_loss 0.4062 (0.3909)	mem 12198MB
Train: [45/300][600/971]	eta 0:02:22 lr 0.000001889	time 0.3874 (0.3832)	tot_loss 0.3694 (0.3902)	mem 12198MB
Train: [45/300][650/971]	eta 0:02:02 lr 0.000001889	time 0.3472 (0.3823)	tot_loss 0.4013 (0.3908)	mem 12198MB
Train: [45/300][700/971]	eta 0:01:43 lr 0.000001889	time 0.3538 (0.3818)	tot_loss 0.3131 (0.3911)	mem 12198MB
Train: [45/300][750/971]	eta 0:01:24 lr 0.000001888	time 0.3542 (0.3810)	tot_loss 0.4274 (0.3908)	mem 12198MB
Train: [45/300][800/971]	eta 0:01:05 lr 0.000001888	time 0.3498 (0.3806)	tot_loss 0.4264 (0.3908)	mem 12198MB
Train: [45/300][850/971]	eta 0:00:46 lr 0.000001888	time 0.3552 (0.3802)	tot_loss 0.4262 (0.3909)	mem 12198MB
Train: [45/300][900/971]	eta 0:00:26 lr 0.000001888	time 0.3567 (0.3798)	tot_loss 0.3739 (0.3915)	mem 12198MB
Train: [45/300][950/971]	eta 0:00:07 lr 0.000001887	time 0.3346 (0.3793)	tot_loss 0.3763 (0.3912)	mem 12198MB
EPOCH 45 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 50.000	
Test: [100/3923]	Acc@1: 47.030	
Test: [150/3923]	Acc@1: 48.344	
Test: [200/3923]	Acc@1: 48.756	
Test: [250/3923]	Acc@1: 48.805	
Test: [300/3923]	Acc@1: 48.505	
Test: [350/3923]	Acc@1: 50.427	
Test: [400/3923]	Acc@1: 51.122	
Test: [450/3923]	Acc@1: 51.109	
Test: [500/3923]	Acc@1: 51.796	
Test: [550/3923]	Acc@1: 51.089	
Test: [600/3923]	Acc@1: 51.248	
Test: [650/3923]	Acc@1: 50.845	
Test: [700/3923]	Acc@1: 50.571	
Test: [750/3923]	Acc@1: 50.333	
Test: [800/3923]	Acc@1: 50.936	
Test: [850/3923]	Acc@1: 50.764	
Test: [900/3923]	Acc@1: 51.221	
Test: [950/3923]	Acc@1: 51.367	
Test: [1000/3923]	Acc@1: 51.349	
Test: [1050/3923]	Acc@1: 50.904	
Test: [1100/3923]	Acc@1: 51.045	
Test: [1150/3923]	Acc@1: 50.956	
Test: [1200/3923]	Acc@1: 50.958	
Test: [1250/3923]	Acc@1: 51.159	
Test: [1300/3923]	Acc@1: 50.884	
Test: [1350/3923]	Acc@1: 50.777	
Test: [1400/3923]	Acc@1: 50.642	
Test: [1450/3923]	Acc@1: 50.793	
Test: [1500/3923]	Acc@1: 50.933	
Test: [1550/3923]	Acc@1: 50.838	
Test: [1600/3923]	Acc@1: 50.906	
Test: [1650/3923]	Acc@1: 50.909	
Test: [1700/3923]	Acc@1: 50.882	
Test: [1750/3923]	Acc@1: 50.714	
Test: [1800/3923]	Acc@1: 50.500	
Test: [1850/3923]	Acc@1: 50.621	
Test: [1900/3923]	Acc@1: 50.684	
Test: [1950/3923]	Acc@1: 50.743	
Test: [2000/3923]	Acc@1: 50.575	
Test: [2050/3923]	Acc@1: 50.488	
Test: [2100/3923]	Acc@1: 50.262	
Test: [2150/3923]	Acc@1: 50.256	
Test: [2200/3923]	Acc@1: 50.045	
Test: [2250/3923]	Acc@1: 50.089	
Test: [2300/3923]	Acc@1: 49.978	
Test: [2350/3923]	Acc@1: 49.979	
Test: [2400/3923]	Acc@1: 50.000	
Test: [2450/3923]	Acc@1: 49.878	
Test: [2500/3923]	Acc@1: 49.940	
Test: [2550/3923]	Acc@1: 49.941	
Test: [2600/3923]	Acc@1: 50.000	
Test: [2650/3923]	Acc@1: 49.981	
Test: [2700/3923]	Acc@1: 50.000	
Test: [2750/3923]	Acc@1: 50.145	
Test: [2800/3923]	Acc@1: 50.125	
Test: [2850/3923]	Acc@1: 50.123	
Test: [2900/3923]	Acc@1: 50.121	
Test: [2950/3923]	Acc@1: 50.136	
Test: [3000/3923]	Acc@1: 50.300	
Test: [3050/3923]	Acc@1: 50.295	
Test: [3100/3923]	Acc@1: 50.161	
Test: [3150/3923]	Acc@1: 50.175	
Test: [3200/3923]	Acc@1: 50.031	
Test: [3250/3923]	Acc@1: 50.031	
Test: [3300/3923]	Acc@1: 49.924	
Test: [3350/3923]	Acc@1: 49.970	
Test: [3400/3923]	Acc@1: 50.059	
Test: [3450/3923]	Acc@1: 50.174	
Test: [3500/3923]	Acc@1: 50.214	
Test: [3550/3923]	Acc@1: 50.338	
Test: [3600/3923]	Acc@1: 50.389	
Test: [3650/3923]	Acc@1: 50.383	
Test: [3700/3923]	Acc@1: 50.459	
Test: [3750/3923]	Acc@1: 50.480	
Test: [3800/3923]	Acc@1: 50.500	
Test: [3850/3923]	Acc@1: 50.454	
Test: [3900/3923]	Acc@1: 50.449	
 * Acc@1 50.421 Acc@5 94.316 UAR 38.972Accuracy of the network on the 7847 test videos: 50.4%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :41.09%Train: [46/300][0/971]	eta 1:30:00 lr 0.000001887	time 5.5616 (5.5616)	tot_loss 0.3829 (0.3829)	mem 12198MB
Train: [46/300][50/971]	eta 0:07:20 lr 0.000001887	time 0.3422 (0.4779)	tot_loss 0.4278 (0.3936)	mem 12198MB
Train: [46/300][100/971]	eta 0:06:13 lr 0.000001887	time 0.3523 (0.4290)	tot_loss 0.4077 (0.3943)	mem 12198MB
Train: [46/300][150/971]	eta 0:05:38 lr 0.000001887	time 0.3982 (0.4118)	tot_loss 0.4342 (0.3945)	mem 12198MB
Train: [46/300][200/971]	eta 0:05:10 lr 0.000001886	time 0.3518 (0.4030)	tot_loss 0.3998 (0.3936)	mem 12198MB
Train: [46/300][250/971]	eta 0:04:47 lr 0.000001886	time 0.3625 (0.3986)	tot_loss 0.4061 (0.3941)	mem 12198MB
Train: [46/300][300/971]	eta 0:04:24 lr 0.000001886	time 0.3407 (0.3948)	tot_loss 0.4091 (0.3938)	mem 12198MB
Train: [46/300][350/971]	eta 0:04:03 lr 0.000001886	time 0.3688 (0.3918)	tot_loss 0.3908 (0.3937)	mem 12198MB
Train: [46/300][400/971]	eta 0:03:42 lr 0.000001885	time 0.3543 (0.3900)	tot_loss 0.3536 (0.3931)	mem 12198MB
Train: [46/300][450/971]	eta 0:03:22 lr 0.000001885	time 0.3490 (0.3880)	tot_loss 0.4354 (0.3924)	mem 12198MB
Train: [46/300][500/971]	eta 0:03:02 lr 0.000001885	time 0.3467 (0.3867)	tot_loss 0.4092 (0.3931)	mem 12198MB
Train: [46/300][550/971]	eta 0:02:42 lr 0.000001885	time 0.3536 (0.3855)	tot_loss 0.4087 (0.3927)	mem 12198MB
Train: [46/300][600/971]	eta 0:02:22 lr 0.000001884	time 0.3515 (0.3849)	tot_loss 0.3675 (0.3922)	mem 12198MB
Train: [46/300][650/971]	eta 0:02:03 lr 0.000001884	time 0.3492 (0.3842)	tot_loss 0.3947 (0.3917)	mem 12198MB
Train: [46/300][700/971]	eta 0:01:44 lr 0.000001884	time 0.3609 (0.3838)	tot_loss 0.3995 (0.3923)	mem 12198MB
Train: [46/300][750/971]	eta 0:01:24 lr 0.000001884	time 0.3572 (0.3835)	tot_loss 0.3973 (0.3924)	mem 12198MB
Train: [46/300][800/971]	eta 0:01:05 lr 0.000001883	time 0.3715 (0.3831)	tot_loss 0.3638 (0.3926)	mem 12198MB
Train: [46/300][850/971]	eta 0:00:46 lr 0.000001883	time 0.3672 (0.3829)	tot_loss 0.3002 (0.3923)	mem 12198MB
Train: [46/300][900/971]	eta 0:00:27 lr 0.000001883	time 0.3537 (0.3826)	tot_loss 0.4224 (0.3926)	mem 12198MB
Train: [46/300][950/971]	eta 0:00:08 lr 0.000001883	time 0.3383 (0.3823)	tot_loss 0.3127 (0.3927)	mem 12198MB
EPOCH 46 training takes 0:06:10
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 52.941	
Test: [100/3923]	Acc@1: 52.475	
Test: [150/3923]	Acc@1: 52.980	
Test: [200/3923]	Acc@1: 51.244	
Test: [250/3923]	Acc@1: 51.793	
Test: [300/3923]	Acc@1: 52.326	
Test: [350/3923]	Acc@1: 53.276	
Test: [400/3923]	Acc@1: 52.743	
Test: [450/3923]	Acc@1: 52.661	
Test: [500/3923]	Acc@1: 51.697	
Test: [550/3923]	Acc@1: 51.633	
Test: [600/3923]	Acc@1: 51.414	
Test: [650/3923]	Acc@1: 51.536	
Test: [700/3923]	Acc@1: 51.569	
Test: [750/3923]	Acc@1: 51.265	
Test: [800/3923]	Acc@1: 50.687	
Test: [850/3923]	Acc@1: 49.941	
Test: [900/3923]	Acc@1: 50.055	
Test: [950/3923]	Acc@1: 50.210	
Test: [1000/3923]	Acc@1: 50.300	
Test: [1050/3923]	Acc@1: 50.143	
Test: [1100/3923]	Acc@1: 49.773	
Test: [1150/3923]	Acc@1: 49.696	
Test: [1200/3923]	Acc@1: 49.625	
Test: [1250/3923]	Acc@1: 49.680	
Test: [1300/3923]	Acc@1: 49.462	
Test: [1350/3923]	Acc@1: 49.371	
Test: [1400/3923]	Acc@1: 49.714	
Test: [1450/3923]	Acc@1: 49.897	
Test: [1500/3923]	Acc@1: 49.900	
Test: [1550/3923]	Acc@1: 50.032	
Test: [1600/3923]	Acc@1: 50.156	
Test: [1650/3923]	Acc@1: 50.212	
Test: [1700/3923]	Acc@1: 50.235	
Test: [1750/3923]	Acc@1: 50.200	
Test: [1800/3923]	Acc@1: 50.333	
Test: [1850/3923]	Acc@1: 50.108	
Test: [1900/3923]	Acc@1: 50.158	
Test: [1950/3923]	Acc@1: 50.410	
Test: [2000/3923]	Acc@1: 50.325	
Test: [2050/3923]	Acc@1: 50.341	
Test: [2100/3923]	Acc@1: 50.571	
Test: [2150/3923]	Acc@1: 50.465	
Test: [2200/3923]	Acc@1: 50.454	
Test: [2250/3923]	Acc@1: 50.511	
Test: [2300/3923]	Acc@1: 50.369	
Test: [2350/3923]	Acc@1: 50.489	
Test: [2400/3923]	Acc@1: 50.562	
Test: [2450/3923]	Acc@1: 50.388	
Test: [2500/3923]	Acc@1: 50.240	
Test: [2550/3923]	Acc@1: 50.196	
Test: [2600/3923]	Acc@1: 50.365	
Test: [2650/3923]	Acc@1: 50.434	
Test: [2700/3923]	Acc@1: 50.389	
Test: [2750/3923]	Acc@1: 50.291	
Test: [2800/3923]	Acc@1: 50.196	
Test: [2850/3923]	Acc@1: 50.158	
Test: [2900/3923]	Acc@1: 50.276	
Test: [2950/3923]	Acc@1: 50.203	
Test: [3000/3923]	Acc@1: 50.117	
Test: [3050/3923]	Acc@1: 50.164	
Test: [3100/3923]	Acc@1: 50.064	
Test: [3150/3923]	Acc@1: 50.032	
Test: [3200/3923]	Acc@1: 50.047	
Test: [3250/3923]	Acc@1: 50.000	
Test: [3300/3923]	Acc@1: 50.151	
Test: [3350/3923]	Acc@1: 50.149	
Test: [3400/3923]	Acc@1: 50.206	
Test: [3450/3923]	Acc@1: 50.087	
Test: [3500/3923]	Acc@1: 50.086	
Test: [3550/3923]	Acc@1: 50.127	
Test: [3600/3923]	Acc@1: 50.083	
Test: [3650/3923]	Acc@1: 50.178	
Test: [3700/3923]	Acc@1: 50.189	
Test: [3750/3923]	Acc@1: 50.067	
Test: [3800/3923]	Acc@1: 50.000	
Test: [3850/3923]	Acc@1: 49.987	
Test: [3900/3923]	Acc@1: 49.923	
 * Acc@1 49.949 Acc@5 94.112 UAR 40.464Accuracy of the network on the 7847 test videos: 49.9%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :41.09%Train: [47/300][0/971]	eta 1:04:47 lr 0.000001883	time 4.0038 (4.0038)	tot_loss 0.3526 (0.3526)	mem 12198MB
Train: [47/300][50/971]	eta 0:07:10 lr 0.000001882	time 0.3529 (0.4672)	tot_loss 0.3740 (0.3879)	mem 12198MB
Train: [47/300][100/971]	eta 0:06:07 lr 0.000001882	time 0.3537 (0.4220)	tot_loss 0.3340 (0.3885)	mem 12198MB
Train: [47/300][150/971]	eta 0:05:33 lr 0.000001882	time 0.3549 (0.4056)	tot_loss 0.4086 (0.3883)	mem 12198MB
Train: [47/300][200/971]	eta 0:05:06 lr 0.000001881	time 0.3552 (0.3973)	tot_loss 0.4241 (0.3895)	mem 12198MB
Train: [47/300][250/971]	eta 0:04:43 lr 0.000001881	time 0.3940 (0.3928)	tot_loss 0.3160 (0.3907)	mem 12198MB
Train: [47/300][300/971]	eta 0:04:21 lr 0.000001881	time 0.3480 (0.3898)	tot_loss 0.3477 (0.3898)	mem 12198MB
Train: [47/300][350/971]	eta 0:04:00 lr 0.000001881	time 0.3741 (0.3877)	tot_loss 0.3792 (0.3889)	mem 12198MB
Train: [47/300][400/971]	eta 0:03:40 lr 0.000001880	time 0.3652 (0.3863)	tot_loss 0.3201 (0.3891)	mem 12198MB
Train: [47/300][450/971]	eta 0:03:20 lr 0.000001880	time 0.3675 (0.3846)	tot_loss 0.4002 (0.3891)	mem 12198MB
Train: [47/300][500/971]	eta 0:03:00 lr 0.000001880	time 0.3545 (0.3836)	tot_loss 0.4146 (0.3893)	mem 12198MB
Train: [47/300][550/971]	eta 0:02:41 lr 0.000001880	time 0.3549 (0.3831)	tot_loss 0.4097 (0.3894)	mem 12198MB
Train: [47/300][600/971]	eta 0:02:21 lr 0.000001879	time 0.3636 (0.3827)	tot_loss 0.4055 (0.3894)	mem 12198MB
Train: [47/300][650/971]	eta 0:02:02 lr 0.000001879	time 0.3584 (0.3823)	tot_loss 0.3961 (0.3898)	mem 12198MB
Train: [47/300][700/971]	eta 0:01:43 lr 0.000001879	time 0.3566 (0.3819)	tot_loss 0.4624 (0.3904)	mem 12198MB
Train: [47/300][750/971]	eta 0:01:24 lr 0.000001879	time 0.3784 (0.3815)	tot_loss 0.4196 (0.3904)	mem 12198MB
Train: [47/300][800/971]	eta 0:01:05 lr 0.000001878	time 0.3780 (0.3814)	tot_loss 0.3898 (0.3908)	mem 12198MB
Train: [47/300][850/971]	eta 0:00:46 lr 0.000001878	time 0.3720 (0.3811)	tot_loss 0.4378 (0.3905)	mem 12198MB
Train: [47/300][900/971]	eta 0:00:27 lr 0.000001878	time 0.3466 (0.3811)	tot_loss 0.4430 (0.3905)	mem 12198MB
Train: [47/300][950/971]	eta 0:00:07 lr 0.000001878	time 0.3427 (0.3807)	tot_loss 0.4131 (0.3904)	mem 12198MB
EPOCH 47 training takes 0:06:09
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 52.941	
Test: [100/3923]	Acc@1: 48.515	
Test: [150/3923]	Acc@1: 46.026	
Test: [200/3923]	Acc@1: 46.766	
Test: [250/3923]	Acc@1: 47.809	
Test: [300/3923]	Acc@1: 49.003	
Test: [350/3923]	Acc@1: 48.860	
Test: [400/3923]	Acc@1: 48.753	
Test: [450/3923]	Acc@1: 49.113	
Test: [500/3923]	Acc@1: 49.401	
Test: [550/3923]	Acc@1: 49.183	
Test: [600/3923]	Acc@1: 49.834	
Test: [650/3923]	Acc@1: 49.770	
Test: [700/3923]	Acc@1: 49.572	
Test: [750/3923]	Acc@1: 49.601	
Test: [800/3923]	Acc@1: 50.125	
Test: [850/3923]	Acc@1: 49.941	
Test: [900/3923]	Acc@1: 50.111	
Test: [950/3923]	Acc@1: 50.158	
Test: [1000/3923]	Acc@1: 50.050	
Test: [1050/3923]	Acc@1: 50.143	
Test: [1100/3923]	Acc@1: 50.363	
Test: [1150/3923]	Acc@1: 50.348	
Test: [1200/3923]	Acc@1: 50.208	
Test: [1250/3923]	Acc@1: 50.520	
Test: [1300/3923]	Acc@1: 50.461	
Test: [1350/3923]	Acc@1: 50.444	
Test: [1400/3923]	Acc@1: 50.535	
Test: [1450/3923]	Acc@1: 50.586	
Test: [1500/3923]	Acc@1: 50.566	
Test: [1550/3923]	Acc@1: 50.355	
Test: [1600/3923]	Acc@1: 50.250	
Test: [1650/3923]	Acc@1: 50.333	
Test: [1700/3923]	Acc@1: 50.323	
Test: [1750/3923]	Acc@1: 50.200	
Test: [1800/3923]	Acc@1: 50.250	
Test: [1850/3923]	Acc@1: 50.243	
Test: [1900/3923]	Acc@1: 50.263	
Test: [1950/3923]	Acc@1: 50.282	
Test: [2000/3923]	Acc@1: 50.175	
Test: [2050/3923]	Acc@1: 50.024	
Test: [2100/3923]	Acc@1: 50.167	
Test: [2150/3923]	Acc@1: 50.046	
Test: [2200/3923]	Acc@1: 49.841	
Test: [2250/3923]	Acc@1: 49.822	
Test: [2300/3923]	Acc@1: 49.870	
Test: [2350/3923]	Acc@1: 49.851	
Test: [2400/3923]	Acc@1: 49.875	
Test: [2450/3923]	Acc@1: 49.878	
Test: [2500/3923]	Acc@1: 49.980	
Test: [2550/3923]	Acc@1: 49.980	
Test: [2600/3923]	Acc@1: 50.173	
Test: [2650/3923]	Acc@1: 50.057	
Test: [2700/3923]	Acc@1: 50.241	
Test: [2750/3923]	Acc@1: 50.327	
Test: [2800/3923]	Acc@1: 50.196	
Test: [2850/3923]	Acc@1: 50.263	
Test: [2900/3923]	Acc@1: 50.293	
Test: [2950/3923]	Acc@1: 50.119	
Test: [3000/3923]	Acc@1: 49.900	
Test: [3050/3923]	Acc@1: 50.016	
Test: [3100/3923]	Acc@1: 50.016	
Test: [3150/3923]	Acc@1: 50.048	
Test: [3200/3923]	Acc@1: 49.984	
Test: [3250/3923]	Acc@1: 49.969	
Test: [3300/3923]	Acc@1: 50.045	
Test: [3350/3923]	Acc@1: 50.030	
Test: [3400/3923]	Acc@1: 49.897	
Test: [3450/3923]	Acc@1: 49.855	
Test: [3500/3923]	Acc@1: 49.857	
Test: [3550/3923]	Acc@1: 49.930	
Test: [3600/3923]	Acc@1: 49.958	
Test: [3650/3923]	Acc@1: 49.973	
Test: [3700/3923]	Acc@1: 49.932	
Test: [3750/3923]	Acc@1: 49.933	
Test: [3800/3923]	Acc@1: 50.013	
Test: [3850/3923]	Acc@1: 50.039	
Test: [3900/3923]	Acc@1: 50.026	
 * Acc@1 50.038 Acc@5 94.685 UAR 40.783Accuracy of the network on the 7847 test videos: 50.0%
Max accuracy: 50.90%, Current UAR : 38.92%, Max UAR :41.09%Train: [48/300][0/971]	eta 1:18:46 lr 0.000001878	time 4.8679 (4.8679)	tot_loss 0.3554 (0.3554)	mem 12198MB
Train: [48/300][50/971]	eta 0:07:04 lr 0.000001877	time 0.3589 (0.4608)	tot_loss 0.4399 (0.3823)	mem 12198MB
Train: [48/300][100/971]	eta 0:06:04 lr 0.000001877	time 0.3563 (0.4180)	tot_loss 0.3883 (0.3886)	mem 12198MB
Train: [48/300][150/971]	eta 0:05:30 lr 0.000001877	time 0.3510 (0.4028)	tot_loss 0.3779 (0.3903)	mem 12198MB
Train: [48/300][200/971]	eta 0:05:05 lr 0.000001877	time 0.3452 (0.3959)	tot_loss 0.3989 (0.3868)	mem 12198MB
Train: [48/300][250/971]	eta 0:04:42 lr 0.000001876	time 0.3733 (0.3923)	tot_loss 0.2864 (0.3880)	mem 12198MB
Train: [48/300][300/971]	eta 0:04:21 lr 0.000001876	time 0.3680 (0.3896)	tot_loss 0.3705 (0.3878)	mem 12198MB
Train: [48/300][350/971]	eta 0:04:01 lr 0.000001876	time 0.3596 (0.3881)	tot_loss 0.3168 (0.3881)	mem 12198MB
Train: [48/300][400/971]	eta 0:03:40 lr 0.000001875	time 0.3839 (0.3865)	tot_loss 0.4338 (0.3893)	mem 12198MB
Train: [48/300][450/971]	eta 0:03:20 lr 0.000001875	time 0.3492 (0.3845)	tot_loss 0.3668 (0.3889)	mem 12198MB
Train: [48/300][500/971]	eta 0:03:00 lr 0.000001875	time 0.3605 (0.3838)	tot_loss 0.4351 (0.3896)	mem 12198MB
Train: [48/300][550/971]	eta 0:02:41 lr 0.000001875	time 0.3493 (0.3830)	tot_loss 0.3362 (0.3894)	mem 12198MB
Train: [48/300][600/971]	eta 0:02:21 lr 0.000001874	time 0.3634 (0.3819)	tot_loss 0.4200 (0.3894)	mem 12198MB
Train: [48/300][650/971]	eta 0:02:02 lr 0.000001874	time 0.3663 (0.3816)	tot_loss 0.3385 (0.3899)	mem 12198MB
Train: [48/300][700/971]	eta 0:01:43 lr 0.000001874	time 0.3475 (0.3809)	tot_loss 0.4256 (0.3903)	mem 12198MB
Train: [48/300][750/971]	eta 0:01:23 lr 0.000001874	time 0.3604 (0.3800)	tot_loss 0.3242 (0.3896)	mem 12198MB
Train: [48/300][800/971]	eta 0:01:04 lr 0.000001873	time 0.3906 (0.3795)	tot_loss 0.4006 (0.3895)	mem 12198MB
Train: [48/300][850/971]	eta 0:00:45 lr 0.000001873	time 0.3462 (0.3789)	tot_loss 0.4193 (0.3898)	mem 12198MB
Train: [48/300][900/971]	eta 0:00:26 lr 0.000001873	time 0.3472 (0.3794)	tot_loss 0.4117 (0.3895)	mem 12198MB
Train: [48/300][950/971]	eta 0:00:07 lr 0.000001873	time 0.3295 (0.3787)	tot_loss 0.3830 (0.3900)	mem 12198MB
EPOCH 48 training takes 0:06:07
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 48.039	
Test: [100/3923]	Acc@1: 50.000	
Test: [150/3923]	Acc@1: 48.675	
Test: [200/3923]	Acc@1: 50.000	
Test: [250/3923]	Acc@1: 50.797	
Test: [300/3923]	Acc@1: 50.831	
Test: [350/3923]	Acc@1: 50.142	
Test: [400/3923]	Acc@1: 50.998	
Test: [450/3923]	Acc@1: 50.998	
Test: [500/3923]	Acc@1: 51.098	
Test: [550/3923]	Acc@1: 51.270	
Test: [600/3923]	Acc@1: 51.498	
Test: [650/3923]	Acc@1: 51.459	
Test: [700/3923]	Acc@1: 51.284	
Test: [750/3923]	Acc@1: 50.999	
Test: [800/3923]	Acc@1: 51.498	
Test: [850/3923]	Acc@1: 51.234	
Test: [900/3923]	Acc@1: 51.498	
Test: [950/3923]	Acc@1: 51.262	
Test: [1000/3923]	Acc@1: 51.299	
Test: [1050/3923]	Acc@1: 51.427	
Test: [1100/3923]	Acc@1: 51.181	
Test: [1150/3923]	Acc@1: 51.520	
Test: [1200/3923]	Acc@1: 51.582	
Test: [1250/3923]	Acc@1: 51.719	
Test: [1300/3923]	Acc@1: 51.768	
Test: [1350/3923]	Acc@1: 51.554	
Test: [1400/3923]	Acc@1: 51.713	
Test: [1450/3923]	Acc@1: 51.585	
Test: [1500/3923]	Acc@1: 51.699	
Test: [1550/3923]	Acc@1: 51.773	
Test: [1600/3923]	Acc@1: 51.593	
Test: [1650/3923]	Acc@1: 51.545	
Test: [1700/3923]	Acc@1: 51.558	
Test: [1750/3923]	Acc@1: 51.628	
Test: [1800/3923]	Acc@1: 51.638	
Test: [1850/3923]	Acc@1: 51.837	
Test: [1900/3923]	Acc@1: 51.736	
Test: [1950/3923]	Acc@1: 51.666	
Test: [2000/3923]	Acc@1: 51.674	
Test: [2050/3923]	Acc@1: 51.536	
Test: [2100/3923]	Acc@1: 51.475	
Test: [2150/3923]	Acc@1: 51.278	
Test: [2200/3923]	Acc@1: 51.249	
Test: [2250/3923]	Acc@1: 51.222	
Test: [2300/3923]	Acc@1: 51.347	
Test: [2350/3923]	Acc@1: 51.212	
Test: [2400/3923]	Acc@1: 51.354	
Test: [2450/3923]	Acc@1: 51.469	
Test: [2500/3923]	Acc@1: 51.479	
Test: [2550/3923]	Acc@1: 51.294	
Test: [2600/3923]	Acc@1: 51.250	
Test: [2650/3923]	Acc@1: 51.433	
Test: [2700/3923]	Acc@1: 51.518	
Test: [2750/3923]	Acc@1: 51.545	
Test: [2800/3923]	Acc@1: 51.410	
Test: [2850/3923]	Acc@1: 51.333	
Test: [2900/3923]	Acc@1: 51.465	
Test: [2950/3923]	Acc@1: 51.457	
Test: [3000/3923]	Acc@1: 51.400	
Test: [3050/3923]	Acc@1: 51.360	
Test: [3100/3923]	Acc@1: 51.387	
Test: [3150/3923]	Acc@1: 51.254	
Test: [3200/3923]	Acc@1: 51.265	
Test: [3250/3923]	Acc@1: 51.107	
Test: [3300/3923]	Acc@1: 51.091	
Test: [3350/3923]	Acc@1: 51.119	
Test: [3400/3923]	Acc@1: 51.103	
Test: [3450/3923]	Acc@1: 51.087	
Test: [3500/3923]	Acc@1: 51.143	
Test: [3550/3923]	Acc@1: 51.155	
Test: [3600/3923]	Acc@1: 51.152	
Test: [3650/3923]	Acc@1: 51.150	
Test: [3700/3923]	Acc@1: 51.054	
Test: [3750/3923]	Acc@1: 51.093	
Test: [3800/3923]	Acc@1: 51.118	
Test: [3850/3923]	Acc@1: 51.078	
Test: [3900/3923]	Acc@1: 51.077	
 * Acc@1 51.083 Acc@5 94.456 UAR 40.324Accuracy of the network on the 7847 test videos: 51.1%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.09%Train: [49/300][0/971]	eta 1:12:13 lr 0.000001873	time 4.4627 (4.4627)	tot_loss 0.4235 (0.4235)	mem 12198MB
Train: [49/300][50/971]	eta 0:07:18 lr 0.000001872	time 0.3538 (0.4757)	tot_loss 0.3451 (0.3884)	mem 12198MB
Train: [49/300][100/971]	eta 0:06:11 lr 0.000001872	time 0.3555 (0.4264)	tot_loss 0.3452 (0.3902)	mem 12198MB
Train: [49/300][150/971]	eta 0:05:37 lr 0.000001872	time 0.3753 (0.4115)	tot_loss 0.4090 (0.3906)	mem 12198MB
Train: [49/300][200/971]	eta 0:05:10 lr 0.000001871	time 0.3533 (0.4024)	tot_loss 0.3064 (0.3902)	mem 12198MB
Train: [49/300][250/971]	eta 0:04:46 lr 0.000001871	time 0.3556 (0.3968)	tot_loss 0.4371 (0.3913)	mem 12198MB
Train: [49/300][300/971]	eta 0:04:23 lr 0.000001871	time 0.3608 (0.3929)	tot_loss 0.3203 (0.3916)	mem 12198MB
Train: [49/300][350/971]	eta 0:04:02 lr 0.000001871	time 0.3601 (0.3908)	tot_loss 0.3956 (0.3903)	mem 12198MB
Train: [49/300][400/971]	eta 0:03:42 lr 0.000001870	time 0.3570 (0.3889)	tot_loss 0.4130 (0.3912)	mem 12198MB
Train: [49/300][450/971]	eta 0:03:21 lr 0.000001870	time 0.3493 (0.3873)	tot_loss 0.4327 (0.3898)	mem 12198MB
Train: [49/300][500/971]	eta 0:03:01 lr 0.000001870	time 0.3531 (0.3861)	tot_loss 0.4143 (0.3890)	mem 12198MB
Train: [49/300][550/971]	eta 0:02:42 lr 0.000001870	time 0.4023 (0.3850)	tot_loss 0.4038 (0.3896)	mem 12198MB
Train: [49/300][600/971]	eta 0:02:22 lr 0.000001869	time 0.3475 (0.3842)	tot_loss 0.4160 (0.3895)	mem 12198MB
Train: [49/300][650/971]	eta 0:02:02 lr 0.000001869	time 0.3501 (0.3831)	tot_loss 0.3435 (0.3893)	mem 12198MB
Train: [49/300][700/971]	eta 0:01:43 lr 0.000001869	time 0.3681 (0.3824)	tot_loss 0.3432 (0.3889)	mem 12198MB
Train: [49/300][750/971]	eta 0:01:24 lr 0.000001869	time 0.3526 (0.3815)	tot_loss 0.4084 (0.3894)	mem 12198MB
Train: [49/300][800/971]	eta 0:01:05 lr 0.000001868	time 0.3522 (0.3808)	tot_loss 0.4162 (0.3898)	mem 12198MB
Train: [49/300][850/971]	eta 0:00:46 lr 0.000001868	time 0.3560 (0.3804)	tot_loss 0.3220 (0.3900)	mem 12198MB
Train: [49/300][900/971]	eta 0:00:26 lr 0.000001868	time 0.3494 (0.3799)	tot_loss 0.3830 (0.3903)	mem 12198MB
Train: [49/300][950/971]	eta 0:00:07 lr 0.000001867	time 0.3390 (0.3794)	tot_loss 0.3476 (0.3902)	mem 12198MB
EPOCH 49 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 50.000	
Test: [100/3923]	Acc@1: 49.505	
Test: [150/3923]	Acc@1: 49.007	
Test: [200/3923]	Acc@1: 48.756	
Test: [250/3923]	Acc@1: 48.606	
Test: [300/3923]	Acc@1: 48.837	
Test: [350/3923]	Acc@1: 49.288	
Test: [400/3923]	Acc@1: 50.000	
Test: [450/3923]	Acc@1: 49.667	
Test: [500/3923]	Acc@1: 49.401	
Test: [550/3923]	Acc@1: 49.456	
Test: [600/3923]	Acc@1: 49.168	
Test: [650/3923]	Acc@1: 49.309	
Test: [700/3923]	Acc@1: 49.215	
Test: [750/3923]	Acc@1: 49.734	
Test: [800/3923]	Acc@1: 50.250	
Test: [850/3923]	Acc@1: 50.176	
Test: [900/3923]	Acc@1: 50.277	
Test: [950/3923]	Acc@1: 50.000	
Test: [1000/3923]	Acc@1: 49.850	
Test: [1050/3923]	Acc@1: 50.000	
Test: [1100/3923]	Acc@1: 50.000	
Test: [1150/3923]	Acc@1: 50.391	
Test: [1200/3923]	Acc@1: 50.583	
Test: [1250/3923]	Acc@1: 50.120	
Test: [1300/3923]	Acc@1: 49.962	
Test: [1350/3923]	Acc@1: 50.111	
Test: [1400/3923]	Acc@1: 50.143	
Test: [1450/3923]	Acc@1: 49.966	
Test: [1500/3923]	Acc@1: 49.867	
Test: [1550/3923]	Acc@1: 50.097	
Test: [1600/3923]	Acc@1: 50.156	
Test: [1650/3923]	Acc@1: 50.061	
Test: [1700/3923]	Acc@1: 50.206	
Test: [1750/3923]	Acc@1: 50.200	
Test: [1800/3923]	Acc@1: 50.278	
Test: [1850/3923]	Acc@1: 50.405	
Test: [1900/3923]	Acc@1: 50.421	
Test: [1950/3923]	Acc@1: 50.564	
Test: [2000/3923]	Acc@1: 50.525	
Test: [2050/3923]	Acc@1: 50.634	
Test: [2100/3923]	Acc@1: 50.666	
Test: [2150/3923]	Acc@1: 50.581	
Test: [2200/3923]	Acc@1: 50.409	
Test: [2250/3923]	Acc@1: 50.333	
Test: [2300/3923]	Acc@1: 50.500	
Test: [2350/3923]	Acc@1: 50.638	
Test: [2400/3923]	Acc@1: 50.541	
Test: [2450/3923]	Acc@1: 50.428	
Test: [2500/3923]	Acc@1: 50.460	
Test: [2550/3923]	Acc@1: 50.568	
Test: [2600/3923]	Acc@1: 50.538	
Test: [2650/3923]	Acc@1: 50.358	
Test: [2700/3923]	Acc@1: 50.296	
Test: [2750/3923]	Acc@1: 50.345	
Test: [2800/3923]	Acc@1: 50.286	
Test: [2850/3923]	Acc@1: 50.368	
Test: [2900/3923]	Acc@1: 50.517	
Test: [2950/3923]	Acc@1: 50.525	
Test: [3000/3923]	Acc@1: 50.550	
Test: [3050/3923]	Acc@1: 50.459	
Test: [3100/3923]	Acc@1: 50.468	
Test: [3150/3923]	Acc@1: 50.413	
Test: [3200/3923]	Acc@1: 50.391	
Test: [3250/3923]	Acc@1: 50.185	
Test: [3300/3923]	Acc@1: 50.136	
Test: [3350/3923]	Acc@1: 50.254	
Test: [3400/3923]	Acc@1: 50.162	
Test: [3450/3923]	Acc@1: 50.058	
Test: [3500/3923]	Acc@1: 50.171	
Test: [3550/3923]	Acc@1: 50.197	
Test: [3600/3923]	Acc@1: 50.222	
Test: [3650/3923]	Acc@1: 50.164	
Test: [3700/3923]	Acc@1: 49.959	
Test: [3750/3923]	Acc@1: 49.933	
Test: [3800/3923]	Acc@1: 49.868	
Test: [3850/3923]	Acc@1: 49.857	
Test: [3900/3923]	Acc@1: 49.859	
 * Acc@1 49.822 Acc@5 94.405 UAR 41.107Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [50/300][0/971]	eta 1:21:42 lr 0.000001867	time 5.0494 (5.0494)	tot_loss 0.4256 (0.4256)	mem 12198MB
Train: [50/300][50/971]	eta 0:07:15 lr 0.000001867	time 0.3463 (0.4728)	tot_loss 0.3293 (0.3964)	mem 12198MB
Train: [50/300][100/971]	eta 0:06:09 lr 0.000001867	time 0.3505 (0.4242)	tot_loss 0.3970 (0.3913)	mem 12198MB
Train: [50/300][150/971]	eta 0:05:35 lr 0.000001867	time 0.3535 (0.4080)	tot_loss 0.3956 (0.3914)	mem 12198MB
Train: [50/300][200/971]	eta 0:05:07 lr 0.000001866	time 0.3548 (0.3994)	tot_loss 0.3260 (0.3909)	mem 12198MB
Train: [50/300][250/971]	eta 0:04:44 lr 0.000001866	time 0.3605 (0.3941)	tot_loss 0.3857 (0.3904)	mem 12198MB
Train: [50/300][300/971]	eta 0:04:22 lr 0.000001866	time 0.3935 (0.3915)	tot_loss 0.3155 (0.3918)	mem 12198MB
Train: [50/300][350/971]	eta 0:04:01 lr 0.000001866	time 0.3626 (0.3891)	tot_loss 0.4162 (0.3916)	mem 12198MB
Train: [50/300][400/971]	eta 0:03:41 lr 0.000001865	time 0.3781 (0.3875)	tot_loss 0.4219 (0.3907)	mem 12198MB
Train: [50/300][450/971]	eta 0:03:20 lr 0.000001865	time 0.3696 (0.3858)	tot_loss 0.3464 (0.3909)	mem 12198MB
Train: [50/300][500/971]	eta 0:03:01 lr 0.000001865	time 0.3507 (0.3848)	tot_loss 0.4096 (0.3910)	mem 12198MB
Train: [50/300][550/971]	eta 0:02:41 lr 0.000001864	time 0.3629 (0.3834)	tot_loss 0.3931 (0.3906)	mem 12198MB
Train: [50/300][600/971]	eta 0:02:21 lr 0.000001864	time 0.3481 (0.3827)	tot_loss 0.4134 (0.3903)	mem 12198MB
Train: [50/300][650/971]	eta 0:02:02 lr 0.000001864	time 0.3580 (0.3822)	tot_loss 0.4435 (0.3907)	mem 12198MB
Train: [50/300][700/971]	eta 0:01:43 lr 0.000001864	time 0.3561 (0.3815)	tot_loss 0.3580 (0.3910)	mem 12198MB
Train: [50/300][750/971]	eta 0:01:24 lr 0.000001863	time 0.3570 (0.3811)	tot_loss 0.3659 (0.3903)	mem 12198MB
Train: [50/300][800/971]	eta 0:01:05 lr 0.000001863	time 0.3635 (0.3811)	tot_loss 0.3365 (0.3901)	mem 12198MB
Train: [50/300][850/971]	eta 0:00:46 lr 0.000001863	time 0.3518 (0.3810)	tot_loss 0.4049 (0.3902)	mem 12198MB
Train: [50/300][900/971]	eta 0:00:27 lr 0.000001863	time 0.3644 (0.3807)	tot_loss 0.3552 (0.3902)	mem 12198MB
Train: [50/300][950/971]	eta 0:00:07 lr 0.000001862	time 0.3435 (0.3803)	tot_loss 0.4253 (0.3902)	mem 12198MB
EPOCH 50 training takes 0:06:08
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 48.039	
Test: [100/3923]	Acc@1: 48.020	
Test: [150/3923]	Acc@1: 49.338	
Test: [200/3923]	Acc@1: 49.005	
Test: [250/3923]	Acc@1: 49.402	
Test: [300/3923]	Acc@1: 50.166	
Test: [350/3923]	Acc@1: 50.142	
Test: [400/3923]	Acc@1: 49.501	
Test: [450/3923]	Acc@1: 49.002	
Test: [500/3923]	Acc@1: 48.802	
Test: [550/3923]	Acc@1: 49.365	
Test: [600/3923]	Acc@1: 49.917	
Test: [650/3923]	Acc@1: 50.000	
Test: [700/3923]	Acc@1: 49.572	
Test: [750/3923]	Acc@1: 49.334	
Test: [800/3923]	Acc@1: 49.001	
Test: [850/3923]	Acc@1: 48.884	
Test: [900/3923]	Acc@1: 49.390	
Test: [950/3923]	Acc@1: 49.632	
Test: [1000/3923]	Acc@1: 49.600	
Test: [1050/3923]	Acc@1: 49.572	
Test: [1100/3923]	Acc@1: 49.728	
Test: [1150/3923]	Acc@1: 50.174	
Test: [1200/3923]	Acc@1: 50.250	
Test: [1250/3923]	Acc@1: 50.440	
Test: [1300/3923]	Acc@1: 50.461	
Test: [1350/3923]	Acc@1: 50.555	
Test: [1400/3923]	Acc@1: 50.357	
Test: [1450/3923]	Acc@1: 50.241	
Test: [1500/3923]	Acc@1: 50.033	
Test: [1550/3923]	Acc@1: 50.064	
Test: [1600/3923]	Acc@1: 50.125	
Test: [1650/3923]	Acc@1: 50.061	
Test: [1700/3923]	Acc@1: 50.000	
Test: [1750/3923]	Acc@1: 50.114	
Test: [1800/3923]	Acc@1: 50.028	
Test: [1850/3923]	Acc@1: 50.027	
Test: [1900/3923]	Acc@1: 50.000	
Test: [1950/3923]	Acc@1: 50.103	
Test: [2000/3923]	Acc@1: 50.325	
Test: [2050/3923]	Acc@1: 50.244	
Test: [2100/3923]	Acc@1: 50.357	
Test: [2150/3923]	Acc@1: 50.325	
Test: [2200/3923]	Acc@1: 50.159	
Test: [2250/3923]	Acc@1: 50.222	
Test: [2300/3923]	Acc@1: 50.435	
Test: [2350/3923]	Acc@1: 50.276	
Test: [2400/3923]	Acc@1: 50.479	
Test: [2450/3923]	Acc@1: 50.408	
Test: [2500/3923]	Acc@1: 50.340	
Test: [2550/3923]	Acc@1: 50.294	
Test: [2600/3923]	Acc@1: 50.269	
Test: [2650/3923]	Acc@1: 50.113	
Test: [2700/3923]	Acc@1: 50.241	
Test: [2750/3923]	Acc@1: 50.145	
Test: [2800/3923]	Acc@1: 50.089	
Test: [2850/3923]	Acc@1: 50.088	
Test: [2900/3923]	Acc@1: 50.017	
Test: [2950/3923]	Acc@1: 50.068	
Test: [3000/3923]	Acc@1: 50.100	
Test: [3050/3923]	Acc@1: 50.082	
Test: [3100/3923]	Acc@1: 50.081	
Test: [3150/3923]	Acc@1: 49.984	
Test: [3200/3923]	Acc@1: 49.891	
Test: [3250/3923]	Acc@1: 49.923	
Test: [3300/3923]	Acc@1: 49.849	
Test: [3350/3923]	Acc@1: 49.910	
Test: [3400/3923]	Acc@1: 49.956	
Test: [3450/3923]	Acc@1: 49.913	
Test: [3500/3923]	Acc@1: 49.914	
Test: [3550/3923]	Acc@1: 49.916	
Test: [3600/3923]	Acc@1: 50.000	
Test: [3650/3923]	Acc@1: 50.000	
Test: [3700/3923]	Acc@1: 49.986	
Test: [3750/3923]	Acc@1: 49.893	
Test: [3800/3923]	Acc@1: 49.934	
Test: [3850/3923]	Acc@1: 49.961	
Test: [3900/3923]	Acc@1: 50.026	
 * Acc@1 50.102 Acc@5 94.226 UAR 40.492Accuracy of the network on the 7847 test videos: 50.1%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [51/300][0/971]	eta 1:26:02 lr 0.000001862	time 5.3166 (5.3166)	tot_loss 0.4330 (0.4330)	mem 12198MB
Train: [51/300][50/971]	eta 0:07:13 lr 0.000001862	time 0.3758 (0.4709)	tot_loss 0.4481 (0.3843)	mem 12198MB
Train: [51/300][100/971]	eta 0:06:12 lr 0.000001862	time 0.3528 (0.4279)	tot_loss 0.3554 (0.3887)	mem 12198MB
Train: [51/300][150/971]	eta 0:05:37 lr 0.000001861	time 0.3529 (0.4107)	tot_loss 0.3862 (0.3888)	mem 12198MB
Train: [51/300][200/971]	eta 0:05:10 lr 0.000001861	time 0.3458 (0.4023)	tot_loss 0.3853 (0.3899)	mem 12198MB
Train: [51/300][250/971]	eta 0:04:45 lr 0.000001861	time 0.3529 (0.3962)	tot_loss 0.4392 (0.3905)	mem 12198MB
Train: [51/300][300/971]	eta 0:04:23 lr 0.000001861	time 0.3594 (0.3932)	tot_loss 0.4469 (0.3909)	mem 12198MB
Train: [51/300][350/971]	eta 0:04:02 lr 0.000001860	time 0.3567 (0.3906)	tot_loss 0.4413 (0.3914)	mem 12198MB
Train: [51/300][400/971]	eta 0:03:42 lr 0.000001860	time 0.3484 (0.3898)	tot_loss 0.4160 (0.3911)	mem 12198MB
Train: [51/300][450/971]	eta 0:03:23 lr 0.000001860	time 0.5310 (0.3903)	tot_loss 0.3508 (0.3916)	mem 12198MB
Train: [51/300][500/971]	eta 0:03:03 lr 0.000001859	time 0.3688 (0.3894)	tot_loss 0.4081 (0.3906)	mem 12198MB
Train: [51/300][550/971]	eta 0:02:43 lr 0.000001859	time 0.3886 (0.3887)	tot_loss 0.4029 (0.3910)	mem 12198MB
Train: [51/300][600/971]	eta 0:02:23 lr 0.000001859	time 0.3526 (0.3875)	tot_loss 0.3844 (0.3904)	mem 12198MB
Train: [51/300][650/971]	eta 0:02:04 lr 0.000001859	time 0.3534 (0.3865)	tot_loss 0.3626 (0.3900)	mem 12198MB
Train: [51/300][700/971]	eta 0:01:44 lr 0.000001858	time 0.3590 (0.3856)	tot_loss 0.4224 (0.3894)	mem 12198MB
Train: [51/300][750/971]	eta 0:01:24 lr 0.000001858	time 0.3578 (0.3846)	tot_loss 0.3539 (0.3887)	mem 12198MB
Train: [51/300][800/971]	eta 0:01:05 lr 0.000001858	time 0.3626 (0.3841)	tot_loss 0.3693 (0.3890)	mem 12198MB
Train: [51/300][850/971]	eta 0:00:46 lr 0.000001857	time 0.3538 (0.3835)	tot_loss 0.3438 (0.3891)	mem 12198MB
Train: [51/300][900/971]	eta 0:00:27 lr 0.000001857	time 0.3687 (0.3831)	tot_loss 0.4084 (0.3890)	mem 12198MB
Train: [51/300][950/971]	eta 0:00:08 lr 0.000001857	time 0.3361 (0.3821)	tot_loss 0.4173 (0.3894)	mem 12198MB
EPOCH 51 training takes 0:06:10
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 38.235	
Test: [100/3923]	Acc@1: 41.089	
Test: [150/3923]	Acc@1: 42.715	
Test: [200/3923]	Acc@1: 45.274	
Test: [250/3923]	Acc@1: 45.618	
Test: [300/3923]	Acc@1: 46.013	
Test: [350/3923]	Acc@1: 46.439	
Test: [400/3923]	Acc@1: 46.883	
Test: [450/3923]	Acc@1: 47.118	
Test: [500/3923]	Acc@1: 48.802	
Test: [550/3923]	Acc@1: 49.002	
Test: [600/3923]	Acc@1: 49.501	
Test: [650/3923]	Acc@1: 49.309	
Test: [700/3923]	Acc@1: 49.786	
Test: [750/3923]	Acc@1: 49.667	
Test: [800/3923]	Acc@1: 49.750	
Test: [850/3923]	Acc@1: 49.530	
Test: [900/3923]	Acc@1: 49.834	
Test: [950/3923]	Acc@1: 49.947	
Test: [1000/3923]	Acc@1: 49.700	
Test: [1050/3923]	Acc@1: 49.572	
Test: [1100/3923]	Acc@1: 49.364	
Test: [1150/3923]	Acc@1: 49.392	
Test: [1200/3923]	Acc@1: 49.292	
Test: [1250/3923]	Acc@1: 49.201	
Test: [1300/3923]	Acc@1: 49.424	
Test: [1350/3923]	Acc@1: 49.260	
Test: [1400/3923]	Acc@1: 49.429	
Test: [1450/3923]	Acc@1: 49.518	
Test: [1500/3923]	Acc@1: 49.567	
Test: [1550/3923]	Acc@1: 49.355	
Test: [1600/3923]	Acc@1: 49.563	
Test: [1650/3923]	Acc@1: 49.606	
Test: [1700/3923]	Acc@1: 49.324	
Test: [1750/3923]	Acc@1: 49.286	
Test: [1800/3923]	Acc@1: 49.112	
Test: [1850/3923]	Acc@1: 49.190	
Test: [1900/3923]	Acc@1: 49.342	
Test: [1950/3923]	Acc@1: 49.385	
Test: [2000/3923]	Acc@1: 49.700	
Test: [2050/3923]	Acc@1: 49.756	
Test: [2100/3923]	Acc@1: 49.643	
Test: [2150/3923]	Acc@1: 49.489	
Test: [2200/3923]	Acc@1: 49.568	
Test: [2250/3923]	Acc@1: 49.756	
Test: [2300/3923]	Acc@1: 49.674	
Test: [2350/3923]	Acc@1: 49.745	
Test: [2400/3923]	Acc@1: 49.750	
Test: [2450/3923]	Acc@1: 49.592	
Test: [2500/3923]	Acc@1: 49.620	
Test: [2550/3923]	Acc@1: 49.706	
Test: [2600/3923]	Acc@1: 49.558	
Test: [2650/3923]	Acc@1: 49.585	
Test: [2700/3923]	Acc@1: 49.759	
Test: [2750/3923]	Acc@1: 49.764	
Test: [2800/3923]	Acc@1: 49.875	
Test: [2850/3923]	Acc@1: 49.947	
Test: [2900/3923]	Acc@1: 49.914	
Test: [2950/3923]	Acc@1: 49.881	
Test: [3000/3923]	Acc@1: 49.883	
Test: [3050/3923]	Acc@1: 49.836	
Test: [3100/3923]	Acc@1: 49.855	
Test: [3150/3923]	Acc@1: 49.984	
Test: [3200/3923]	Acc@1: 49.922	
Test: [3250/3923]	Acc@1: 49.954	
Test: [3300/3923]	Acc@1: 49.909	
Test: [3350/3923]	Acc@1: 49.925	
Test: [3400/3923]	Acc@1: 50.000	
Test: [3450/3923]	Acc@1: 50.014	
Test: [3500/3923]	Acc@1: 49.971	
Test: [3550/3923]	Acc@1: 49.916	
Test: [3600/3923]	Acc@1: 49.875	
Test: [3650/3923]	Acc@1: 49.904	
Test: [3700/3923]	Acc@1: 49.932	
Test: [3750/3923]	Acc@1: 49.853	
Test: [3800/3923]	Acc@1: 49.855	
Test: [3850/3923]	Acc@1: 49.870	
Test: [3900/3923]	Acc@1: 49.795	
 * Acc@1 49.783 Acc@5 93.564 UAR 39.173Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [52/300][0/971]	eta 1:31:55 lr 0.000001857	time 5.6804 (5.6804)	tot_loss 0.4119 (0.4119)	mem 12198MB
Train: [52/300][50/971]	eta 0:07:27 lr 0.000001857	time 0.3555 (0.4860)	tot_loss 0.3172 (0.3895)	mem 12198MB
Train: [52/300][100/971]	eta 0:06:22 lr 0.000001856	time 0.3547 (0.4387)	tot_loss 0.4092 (0.3918)	mem 12198MB
Train: [52/300][150/971]	eta 0:05:46 lr 0.000001856	time 0.3931 (0.4220)	tot_loss 0.3078 (0.3868)	mem 12198MB
Train: [52/300][200/971]	eta 0:05:18 lr 0.000001856	time 0.3532 (0.4137)	tot_loss 0.3357 (0.3866)	mem 12198MB
Train: [52/300][250/971]	eta 0:04:53 lr 0.000001855	time 0.3733 (0.4071)	tot_loss 0.3918 (0.3857)	mem 12198MB
Train: [52/300][300/971]	eta 0:04:29 lr 0.000001855	time 0.3510 (0.4009)	tot_loss 0.2965 (0.3857)	mem 12198MB
Train: [52/300][350/971]	eta 0:04:06 lr 0.000001855	time 0.3535 (0.3973)	tot_loss 0.4101 (0.3862)	mem 12198MB
Train: [52/300][400/971]	eta 0:03:45 lr 0.000001855	time 0.3525 (0.3945)	tot_loss 0.3596 (0.3865)	mem 12198MB
Train: [52/300][450/971]	eta 0:03:24 lr 0.000001854	time 0.3574 (0.3930)	tot_loss 0.4511 (0.3880)	mem 12198MB
Train: [52/300][500/971]	eta 0:03:04 lr 0.000001854	time 0.3507 (0.3915)	tot_loss 0.3875 (0.3879)	mem 12198MB
Train: [52/300][550/971]	eta 0:02:44 lr 0.000001854	time 0.3550 (0.3897)	tot_loss 0.3751 (0.3869)	mem 12198MB
Train: [52/300][600/971]	eta 0:02:24 lr 0.000001853	time 0.3657 (0.3886)	tot_loss 0.4129 (0.3865)	mem 12198MB
Train: [52/300][650/971]	eta 0:02:04 lr 0.000001853	time 0.3542 (0.3878)	tot_loss 0.3392 (0.3856)	mem 12198MB
Train: [52/300][700/971]	eta 0:01:44 lr 0.000001853	time 0.3572 (0.3871)	tot_loss 0.3247 (0.3858)	mem 12198MB
Train: [52/300][750/971]	eta 0:01:25 lr 0.000001853	time 0.3572 (0.3862)	tot_loss 0.4413 (0.3858)	mem 12198MB
Train: [52/300][800/971]	eta 0:01:05 lr 0.000001852	time 0.3904 (0.3856)	tot_loss 0.3326 (0.3857)	mem 12198MB
Train: [52/300][850/971]	eta 0:00:46 lr 0.000001852	time 0.4115 (0.3852)	tot_loss 0.4330 (0.3858)	mem 12198MB
Train: [52/300][900/971]	eta 0:00:27 lr 0.000001852	time 0.3606 (0.3845)	tot_loss 0.3663 (0.3863)	mem 12198MB
Train: [52/300][950/971]	eta 0:00:08 lr 0.000001852	time 0.4877 (0.3840)	tot_loss 0.3400 (0.3862)	mem 12198MB
EPOCH 52 training takes 0:06:12
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 52.941	
Test: [100/3923]	Acc@1: 55.446	
Test: [150/3923]	Acc@1: 52.980	
Test: [200/3923]	Acc@1: 52.985	
Test: [250/3923]	Acc@1: 53.984	
Test: [300/3923]	Acc@1: 53.488	
Test: [350/3923]	Acc@1: 51.567	
Test: [400/3923]	Acc@1: 51.995	
Test: [450/3923]	Acc@1: 52.439	
Test: [500/3923]	Acc@1: 52.196	
Test: [550/3923]	Acc@1: 52.087	
Test: [600/3923]	Acc@1: 51.581	
Test: [650/3923]	Acc@1: 51.382	
Test: [700/3923]	Acc@1: 52.068	
Test: [750/3923]	Acc@1: 51.531	
Test: [800/3923]	Acc@1: 51.436	
Test: [850/3923]	Acc@1: 50.881	
Test: [900/3923]	Acc@1: 50.999	
Test: [950/3923]	Acc@1: 51.367	
Test: [1000/3923]	Acc@1: 51.548	
Test: [1050/3923]	Acc@1: 50.856	
Test: [1100/3923]	Acc@1: 50.863	
Test: [1150/3923]	Acc@1: 51.129	
Test: [1200/3923]	Acc@1: 50.624	
Test: [1250/3923]	Acc@1: 50.520	
Test: [1300/3923]	Acc@1: 50.730	
Test: [1350/3923]	Acc@1: 50.851	
Test: [1400/3923]	Acc@1: 50.857	
Test: [1450/3923]	Acc@1: 50.965	
Test: [1500/3923]	Acc@1: 51.133	
Test: [1550/3923]	Acc@1: 51.547	
Test: [1600/3923]	Acc@1: 51.499	
Test: [1650/3923]	Acc@1: 51.575	
Test: [1700/3923]	Acc@1: 51.558	
Test: [1750/3923]	Acc@1: 51.742	
Test: [1800/3923]	Acc@1: 51.805	
Test: [1850/3923]	Acc@1: 51.783	
Test: [1900/3923]	Acc@1: 51.473	
Test: [1950/3923]	Acc@1: 51.256	
Test: [2000/3923]	Acc@1: 51.149	
Test: [2050/3923]	Acc@1: 51.121	
Test: [2100/3923]	Acc@1: 51.047	
Test: [2150/3923]	Acc@1: 50.953	
Test: [2200/3923]	Acc@1: 50.750	
Test: [2250/3923]	Acc@1: 50.822	
Test: [2300/3923]	Acc@1: 50.761	
Test: [2350/3923]	Acc@1: 50.702	
Test: [2400/3923]	Acc@1: 50.562	
Test: [2450/3923]	Acc@1: 50.571	
Test: [2500/3923]	Acc@1: 50.580	
Test: [2550/3923]	Acc@1: 50.627	
Test: [2600/3923]	Acc@1: 50.654	
Test: [2650/3923]	Acc@1: 50.566	
Test: [2700/3923]	Acc@1: 50.500	
Test: [2750/3923]	Acc@1: 50.454	
Test: [2800/3923]	Acc@1: 50.357	
Test: [2850/3923]	Acc@1: 50.263	
Test: [2900/3923]	Acc@1: 50.259	
Test: [2950/3923]	Acc@1: 50.254	
Test: [3000/3923]	Acc@1: 50.300	
Test: [3050/3923]	Acc@1: 50.262	
Test: [3100/3923]	Acc@1: 50.258	
Test: [3150/3923]	Acc@1: 50.270	
Test: [3200/3923]	Acc@1: 50.187	
Test: [3250/3923]	Acc@1: 50.092	
Test: [3300/3923]	Acc@1: 50.030	
Test: [3350/3923]	Acc@1: 50.060	
Test: [3400/3923]	Acc@1: 49.912	
Test: [3450/3923]	Acc@1: 49.942	
Test: [3500/3923]	Acc@1: 49.971	
Test: [3550/3923]	Acc@1: 50.042	
Test: [3600/3923]	Acc@1: 50.056	
Test: [3650/3923]	Acc@1: 50.082	
Test: [3700/3923]	Acc@1: 50.054	
Test: [3750/3923]	Acc@1: 50.053	
Test: [3800/3923]	Acc@1: 50.013	
Test: [3850/3923]	Acc@1: 49.857	
Test: [3900/3923]	Acc@1: 49.962	
 * Acc@1 49.936 Acc@5 94.354 UAR 39.595Accuracy of the network on the 7847 test videos: 49.9%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [53/300][0/971]	eta 1:12:10 lr 0.000001851	time 4.4599 (4.4599)	tot_loss 0.3664 (0.3664)	mem 12198MB
Train: [53/300][50/971]	eta 0:07:19 lr 0.000001851	time 0.3475 (0.4777)	tot_loss 0.3756 (0.3870)	mem 12198MB
Train: [53/300][100/971]	eta 0:06:14 lr 0.000001851	time 0.3779 (0.4302)	tot_loss 0.3809 (0.3890)	mem 12198MB
Train: [53/300][150/971]	eta 0:05:37 lr 0.000001851	time 0.3529 (0.4110)	tot_loss 0.3300 (0.3842)	mem 12198MB
Train: [53/300][200/971]	eta 0:05:10 lr 0.000001850	time 0.3642 (0.4024)	tot_loss 0.3747 (0.3863)	mem 12198MB
Train: [53/300][250/971]	eta 0:04:46 lr 0.000001850	time 0.3465 (0.3970)	tot_loss 0.3317 (0.3837)	mem 12198MB
Train: [53/300][300/971]	eta 0:04:24 lr 0.000001850	time 0.3548 (0.3938)	tot_loss 0.4174 (0.3821)	mem 12198MB
Train: [53/300][350/971]	eta 0:04:02 lr 0.000001849	time 0.3737 (0.3911)	tot_loss 0.4040 (0.3840)	mem 12198MB
Train: [53/300][400/971]	eta 0:03:41 lr 0.000001849	time 0.3509 (0.3887)	tot_loss 0.3888 (0.3850)	mem 12198MB
Train: [53/300][450/971]	eta 0:03:21 lr 0.000001849	time 0.3479 (0.3876)	tot_loss 0.4234 (0.3857)	mem 12198MB
Train: [53/300][500/971]	eta 0:03:02 lr 0.000001849	time 0.3497 (0.3869)	tot_loss 0.3333 (0.3862)	mem 12198MB
Train: [53/300][550/971]	eta 0:02:42 lr 0.000001848	time 0.3746 (0.3863)	tot_loss 0.3640 (0.3853)	mem 12198MB
Train: [53/300][600/971]	eta 0:02:23 lr 0.000001848	time 0.3493 (0.3857)	tot_loss 0.4137 (0.3851)	mem 12198MB
Train: [53/300][650/971]	eta 0:02:03 lr 0.000001848	time 0.3577 (0.3850)	tot_loss 0.4357 (0.3855)	mem 12198MB
Train: [53/300][700/971]	eta 0:01:44 lr 0.000001847	time 0.3729 (0.3845)	tot_loss 0.3969 (0.3856)	mem 12198MB
Train: [53/300][750/971]	eta 0:01:24 lr 0.000001847	time 0.3519 (0.3840)	tot_loss 0.4318 (0.3860)	mem 12198MB
Train: [53/300][800/971]	eta 0:01:05 lr 0.000001847	time 0.3653 (0.3838)	tot_loss 0.4173 (0.3866)	mem 12198MB
Train: [53/300][850/971]	eta 0:00:46 lr 0.000001847	time 0.3468 (0.3834)	tot_loss 0.3102 (0.3867)	mem 12198MB
Train: [53/300][900/971]	eta 0:00:27 lr 0.000001846	time 0.3565 (0.3833)	tot_loss 0.4378 (0.3868)	mem 12198MB
Train: [53/300][950/971]	eta 0:00:08 lr 0.000001846	time 0.3354 (0.3830)	tot_loss 0.3822 (0.3869)	mem 12198MB
EPOCH 53 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 50.000	
Test: [100/3923]	Acc@1: 45.545	
Test: [150/3923]	Acc@1: 47.351	
Test: [200/3923]	Acc@1: 46.269	
Test: [250/3923]	Acc@1: 48.606	
Test: [300/3923]	Acc@1: 48.671	
Test: [350/3923]	Acc@1: 48.718	
Test: [400/3923]	Acc@1: 48.628	
Test: [450/3923]	Acc@1: 48.448	
Test: [500/3923]	Acc@1: 48.703	
Test: [550/3923]	Acc@1: 48.094	
Test: [600/3923]	Acc@1: 48.336	
Test: [650/3923]	Acc@1: 48.233	
Test: [700/3923]	Acc@1: 48.146	
Test: [750/3923]	Acc@1: 48.602	
Test: [800/3923]	Acc@1: 48.752	
Test: [850/3923]	Acc@1: 48.766	
Test: [900/3923]	Acc@1: 48.724	
Test: [950/3923]	Acc@1: 49.159	
Test: [1000/3923]	Acc@1: 49.001	
Test: [1050/3923]	Acc@1: 48.478	
Test: [1100/3923]	Acc@1: 48.456	
Test: [1150/3923]	Acc@1: 48.480	
Test: [1200/3923]	Acc@1: 48.043	
Test: [1250/3923]	Acc@1: 48.401	
Test: [1300/3923]	Acc@1: 48.540	
Test: [1350/3923]	Acc@1: 48.446	
Test: [1400/3923]	Acc@1: 48.572	
Test: [1450/3923]	Acc@1: 48.725	
Test: [1500/3923]	Acc@1: 48.701	
Test: [1550/3923]	Acc@1: 48.839	
Test: [1600/3923]	Acc@1: 49.094	
Test: [1650/3923]	Acc@1: 49.182	
Test: [1700/3923]	Acc@1: 49.089	
Test: [1750/3923]	Acc@1: 49.143	
Test: [1800/3923]	Acc@1: 48.973	
Test: [1850/3923]	Acc@1: 49.217	
Test: [1900/3923]	Acc@1: 49.237	
Test: [1950/3923]	Acc@1: 49.436	
Test: [2000/3923]	Acc@1: 49.475	
Test: [2050/3923]	Acc@1: 49.586	
Test: [2100/3923]	Acc@1: 49.619	
Test: [2150/3923]	Acc@1: 49.605	
Test: [2200/3923]	Acc@1: 49.727	
Test: [2250/3923]	Acc@1: 49.889	
Test: [2300/3923]	Acc@1: 50.000	
Test: [2350/3923]	Acc@1: 50.021	
Test: [2400/3923]	Acc@1: 50.021	
Test: [2450/3923]	Acc@1: 50.061	
Test: [2500/3923]	Acc@1: 50.160	
Test: [2550/3923]	Acc@1: 50.431	
Test: [2600/3923]	Acc@1: 50.365	
Test: [2650/3923]	Acc@1: 50.396	
Test: [2700/3923]	Acc@1: 50.167	
Test: [2750/3923]	Acc@1: 50.164	
Test: [2800/3923]	Acc@1: 50.214	
Test: [2850/3923]	Acc@1: 50.193	
Test: [2900/3923]	Acc@1: 50.190	
Test: [2950/3923]	Acc@1: 50.339	
Test: [3000/3923]	Acc@1: 50.300	
Test: [3050/3923]	Acc@1: 50.295	
Test: [3100/3923]	Acc@1: 50.371	
Test: [3150/3923]	Acc@1: 50.317	
Test: [3200/3923]	Acc@1: 50.312	
Test: [3250/3923]	Acc@1: 50.231	
Test: [3300/3923]	Acc@1: 50.136	
Test: [3350/3923]	Acc@1: 50.060	
Test: [3400/3923]	Acc@1: 50.059	
Test: [3450/3923]	Acc@1: 50.072	
Test: [3500/3923]	Acc@1: 50.043	
Test: [3550/3923]	Acc@1: 49.887	
Test: [3600/3923]	Acc@1: 49.861	
Test: [3650/3923]	Acc@1: 49.890	
Test: [3700/3923]	Acc@1: 49.919	
Test: [3750/3923]	Acc@1: 49.893	
Test: [3800/3923]	Acc@1: 49.974	
Test: [3850/3923]	Acc@1: 49.909	
Test: [3900/3923]	Acc@1: 49.821	
 * Acc@1 49.796 Acc@5 94.150 UAR 40.979Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [54/300][0/971]	eta 1:33:20 lr 0.000001846	time 5.7674 (5.7674)	tot_loss 0.3146 (0.3146)	mem 12198MB
Train: [54/300][50/971]	eta 0:07:39 lr 0.000001846	time 0.3576 (0.4986)	tot_loss 0.3827 (0.3856)	mem 12198MB
Train: [54/300][100/971]	eta 0:06:25 lr 0.000001845	time 0.3493 (0.4430)	tot_loss 0.3989 (0.3857)	mem 12198MB
Train: [54/300][150/971]	eta 0:05:45 lr 0.000001845	time 0.3507 (0.4206)	tot_loss 0.4120 (0.3837)	mem 12198MB
Train: [54/300][200/971]	eta 0:05:16 lr 0.000001845	time 0.3471 (0.4103)	tot_loss 0.4009 (0.3827)	mem 12198MB
Train: [54/300][250/971]	eta 0:04:51 lr 0.000001844	time 0.3548 (0.4037)	tot_loss 0.3024 (0.3850)	mem 12198MB
Train: [54/300][300/971]	eta 0:04:27 lr 0.000001844	time 0.3567 (0.3986)	tot_loss 0.3970 (0.3862)	mem 12198MB
Train: [54/300][350/971]	eta 0:04:05 lr 0.000001844	time 0.3527 (0.3957)	tot_loss 0.4014 (0.3871)	mem 12198MB
Train: [54/300][400/971]	eta 0:03:44 lr 0.000001844	time 0.3475 (0.3931)	tot_loss 0.3517 (0.3875)	mem 12198MB
Train: [54/300][450/971]	eta 0:03:23 lr 0.000001843	time 0.3565 (0.3910)	tot_loss 0.3586 (0.3869)	mem 12198MB
Train: [54/300][500/971]	eta 0:03:03 lr 0.000001843	time 0.3498 (0.3896)	tot_loss 0.3500 (0.3859)	mem 12198MB
Train: [54/300][550/971]	eta 0:02:43 lr 0.000001843	time 0.3635 (0.3882)	tot_loss 0.4039 (0.3857)	mem 12198MB
Train: [54/300][600/971]	eta 0:02:23 lr 0.000001842	time 0.3568 (0.3872)	tot_loss 0.4023 (0.3862)	mem 12198MB
Train: [54/300][650/971]	eta 0:02:03 lr 0.000001842	time 0.3594 (0.3862)	tot_loss 0.4001 (0.3867)	mem 12198MB
Train: [54/300][700/971]	eta 0:01:44 lr 0.000001842	time 0.3497 (0.3853)	tot_loss 0.3372 (0.3874)	mem 12198MB
Train: [54/300][750/971]	eta 0:01:25 lr 0.000001842	time 0.3647 (0.3851)	tot_loss 0.3775 (0.3873)	mem 12198MB
Train: [54/300][800/971]	eta 0:01:05 lr 0.000001841	time 0.3534 (0.3846)	tot_loss 0.3647 (0.3876)	mem 12198MB
Train: [54/300][850/971]	eta 0:00:46 lr 0.000001841	time 0.3540 (0.3840)	tot_loss 0.4046 (0.3874)	mem 12198MB
Train: [54/300][900/971]	eta 0:00:27 lr 0.000001841	time 0.3619 (0.3834)	tot_loss 0.3703 (0.3871)	mem 12198MB
Train: [54/300][950/971]	eta 0:00:08 lr 0.000001840	time 0.3361 (0.3829)	tot_loss 0.3872 (0.3866)	mem 12198MB
EPOCH 54 training takes 0:06:11
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 39.216	
Test: [100/3923]	Acc@1: 41.089	
Test: [150/3923]	Acc@1: 45.364	
Test: [200/3923]	Acc@1: 47.512	
Test: [250/3923]	Acc@1: 47.809	
Test: [300/3923]	Acc@1: 48.505	
Test: [350/3923]	Acc@1: 47.578	
Test: [400/3923]	Acc@1: 47.382	
Test: [450/3923]	Acc@1: 47.672	
Test: [500/3923]	Acc@1: 47.904	
Test: [550/3923]	Acc@1: 48.094	
Test: [600/3923]	Acc@1: 48.170	
Test: [650/3923]	Acc@1: 48.771	
Test: [700/3923]	Acc@1: 48.003	
Test: [750/3923]	Acc@1: 48.136	
Test: [800/3923]	Acc@1: 47.628	
Test: [850/3923]	Acc@1: 48.061	
Test: [900/3923]	Acc@1: 47.836	
Test: [950/3923]	Acc@1: 48.265	
Test: [1000/3923]	Acc@1: 48.402	
Test: [1050/3923]	Acc@1: 48.525	
Test: [1100/3923]	Acc@1: 48.547	
Test: [1150/3923]	Acc@1: 48.914	
Test: [1200/3923]	Acc@1: 49.042	
Test: [1250/3923]	Acc@1: 49.201	
Test: [1300/3923]	Acc@1: 49.308	
Test: [1350/3923]	Acc@1: 49.260	
Test: [1400/3923]	Acc@1: 49.072	
Test: [1450/3923]	Acc@1: 49.104	
Test: [1500/3923]	Acc@1: 48.967	
Test: [1550/3923]	Acc@1: 49.194	
Test: [1600/3923]	Acc@1: 49.344	
Test: [1650/3923]	Acc@1: 49.364	
Test: [1700/3923]	Acc@1: 49.559	
Test: [1750/3923]	Acc@1: 49.714	
Test: [1800/3923]	Acc@1: 49.667	
Test: [1850/3923]	Acc@1: 49.919	
Test: [1900/3923]	Acc@1: 49.974	
Test: [1950/3923]	Acc@1: 50.000	
Test: [2000/3923]	Acc@1: 50.025	
Test: [2050/3923]	Acc@1: 50.122	
Test: [2100/3923]	Acc@1: 50.000	
Test: [2150/3923]	Acc@1: 50.023	
Test: [2200/3923]	Acc@1: 50.136	
Test: [2250/3923]	Acc@1: 50.089	
Test: [2300/3923]	Acc@1: 49.935	
Test: [2350/3923]	Acc@1: 49.745	
Test: [2400/3923]	Acc@1: 49.646	
Test: [2450/3923]	Acc@1: 49.388	
Test: [2500/3923]	Acc@1: 49.460	
Test: [2550/3923]	Acc@1: 49.647	
Test: [2600/3923]	Acc@1: 49.539	
Test: [2650/3923]	Acc@1: 49.717	
Test: [2700/3923]	Acc@1: 49.704	
Test: [2750/3923]	Acc@1: 49.582	
Test: [2800/3923]	Acc@1: 49.607	
Test: [2850/3923]	Acc@1: 49.632	
Test: [2900/3923]	Acc@1: 49.673	
Test: [2950/3923]	Acc@1: 49.695	
Test: [3000/3923]	Acc@1: 49.933	
Test: [3050/3923]	Acc@1: 50.016	
Test: [3100/3923]	Acc@1: 50.048	
Test: [3150/3923]	Acc@1: 50.048	
Test: [3200/3923]	Acc@1: 50.078	
Test: [3250/3923]	Acc@1: 50.108	
Test: [3300/3923]	Acc@1: 50.136	
Test: [3350/3923]	Acc@1: 50.224	
Test: [3400/3923]	Acc@1: 50.191	
Test: [3450/3923]	Acc@1: 50.246	
Test: [3500/3923]	Acc@1: 50.343	
Test: [3550/3923]	Acc@1: 50.324	
Test: [3600/3923]	Acc@1: 50.250	
Test: [3650/3923]	Acc@1: 50.342	
Test: [3700/3923]	Acc@1: 50.243	
Test: [3750/3923]	Acc@1: 50.147	
Test: [3800/3923]	Acc@1: 50.105	
Test: [3850/3923]	Acc@1: 50.130	
Test: [3900/3923]	Acc@1: 50.141	
 * Acc@1 50.153 Acc@5 94.124 UAR 39.099Accuracy of the network on the 7847 test videos: 50.2%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [55/300][0/971]	eta 1:31:18 lr 0.000001840	time 5.6419 (5.6419)	tot_loss 0.3401 (0.3401)	mem 12198MB
Train: [55/300][50/971]	eta 0:07:32 lr 0.000001840	time 0.3608 (0.4917)	tot_loss 0.4115 (0.3829)	mem 12198MB
Train: [55/300][100/971]	eta 0:06:21 lr 0.000001840	time 0.3646 (0.4376)	tot_loss 0.3948 (0.3844)	mem 12198MB
Train: [55/300][150/971]	eta 0:05:42 lr 0.000001839	time 0.3590 (0.4177)	tot_loss 0.3080 (0.3874)	mem 12198MB
Train: [55/300][200/971]	eta 0:05:15 lr 0.000001839	time 0.3535 (0.4087)	tot_loss 0.3686 (0.3873)	mem 12198MB
Train: [55/300][250/971]	eta 0:04:50 lr 0.000001839	time 0.3627 (0.4029)	tot_loss 0.4146 (0.3869)	mem 12198MB
Train: [55/300][300/971]	eta 0:04:27 lr 0.000001839	time 0.3538 (0.3987)	tot_loss 0.3733 (0.3864)	mem 12198MB
Train: [55/300][350/971]	eta 0:04:05 lr 0.000001838	time 0.3533 (0.3951)	tot_loss 0.3701 (0.3868)	mem 12198MB
Train: [55/300][400/971]	eta 0:03:44 lr 0.000001838	time 0.3469 (0.3926)	tot_loss 0.4233 (0.3870)	mem 12198MB
Train: [55/300][450/971]	eta 0:03:23 lr 0.000001838	time 0.3551 (0.3902)	tot_loss 0.3893 (0.3854)	mem 12198MB
Train: [55/300][500/971]	eta 0:03:02 lr 0.000001837	time 0.3581 (0.3883)	tot_loss 0.4284 (0.3852)	mem 12198MB
Train: [55/300][550/971]	eta 0:02:42 lr 0.000001837	time 0.3633 (0.3871)	tot_loss 0.4297 (0.3853)	mem 12198MB
Train: [55/300][600/971]	eta 0:02:23 lr 0.000001837	time 0.3573 (0.3864)	tot_loss 0.3565 (0.3855)	mem 12198MB
Train: [55/300][650/971]	eta 0:02:03 lr 0.000001837	time 0.3620 (0.3860)	tot_loss 0.4154 (0.3855)	mem 12198MB
Train: [55/300][700/971]	eta 0:01:44 lr 0.000001836	time 0.3635 (0.3857)	tot_loss 0.3176 (0.3849)	mem 12198MB
Train: [55/300][750/971]	eta 0:01:25 lr 0.000001836	time 0.3568 (0.3855)	tot_loss 0.4613 (0.3849)	mem 12198MB
Train: [55/300][800/971]	eta 0:01:05 lr 0.000001836	time 0.3627 (0.3853)	tot_loss 0.3643 (0.3851)	mem 12198MB
Train: [55/300][850/971]	eta 0:00:46 lr 0.000001835	time 0.3607 (0.3849)	tot_loss 0.3954 (0.3852)	mem 12198MB
Train: [55/300][900/971]	eta 0:00:27 lr 0.000001835	time 0.3589 (0.3849)	tot_loss 0.4464 (0.3856)	mem 12198MB
Train: [55/300][950/971]	eta 0:00:08 lr 0.000001835	time 0.3376 (0.3844)	tot_loss 0.3777 (0.3856)	mem 12198MB
EPOCH 55 training takes 0:06:12
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 54.902	
Test: [100/3923]	Acc@1: 50.000	
Test: [150/3923]	Acc@1: 47.682	
Test: [200/3923]	Acc@1: 48.507	
Test: [250/3923]	Acc@1: 50.398	
Test: [300/3923]	Acc@1: 49.834	
Test: [350/3923]	Acc@1: 50.570	
Test: [400/3923]	Acc@1: 49.377	
Test: [450/3923]	Acc@1: 49.113	
Test: [500/3923]	Acc@1: 49.701	
Test: [550/3923]	Acc@1: 49.637	
Test: [600/3923]	Acc@1: 49.334	
Test: [650/3923]	Acc@1: 49.002	
Test: [700/3923]	Acc@1: 48.787	
Test: [750/3923]	Acc@1: 48.935	
Test: [800/3923]	Acc@1: 48.752	
Test: [850/3923]	Acc@1: 48.649	
Test: [900/3923]	Acc@1: 48.890	
Test: [950/3923]	Acc@1: 48.686	
Test: [1000/3923]	Acc@1: 48.252	
Test: [1050/3923]	Acc@1: 48.525	
Test: [1100/3923]	Acc@1: 48.547	
Test: [1150/3923]	Acc@1: 48.219	
Test: [1200/3923]	Acc@1: 48.127	
Test: [1250/3923]	Acc@1: 48.321	
Test: [1300/3923]	Acc@1: 48.386	
Test: [1350/3923]	Acc@1: 48.409	
Test: [1400/3923]	Acc@1: 48.287	
Test: [1450/3923]	Acc@1: 48.277	
Test: [1500/3923]	Acc@1: 48.135	
Test: [1550/3923]	Acc@1: 48.356	
Test: [1600/3923]	Acc@1: 48.657	
Test: [1650/3923]	Acc@1: 48.425	
Test: [1700/3923]	Acc@1: 48.413	
Test: [1750/3923]	Acc@1: 48.287	
Test: [1800/3923]	Acc@1: 48.223	
Test: [1850/3923]	Acc@1: 48.379	
Test: [1900/3923]	Acc@1: 48.238	
Test: [1950/3923]	Acc@1: 48.257	
Test: [2000/3923]	Acc@1: 48.251	
Test: [2050/3923]	Acc@1: 48.269	
Test: [2100/3923]	Acc@1: 48.406	
Test: [2150/3923]	Acc@1: 48.419	
Test: [2200/3923]	Acc@1: 48.319	
Test: [2250/3923]	Acc@1: 48.090	
Test: [2300/3923]	Acc@1: 48.044	
Test: [2350/3923]	Acc@1: 48.086	
Test: [2400/3923]	Acc@1: 48.209	
Test: [2450/3923]	Acc@1: 48.021	
Test: [2500/3923]	Acc@1: 47.861	
Test: [2550/3923]	Acc@1: 47.922	
Test: [2600/3923]	Acc@1: 48.039	
Test: [2650/3923]	Acc@1: 48.020	
Test: [2700/3923]	Acc@1: 47.945	
Test: [2750/3923]	Acc@1: 47.910	
Test: [2800/3923]	Acc@1: 47.894	
Test: [2850/3923]	Acc@1: 47.931	
Test: [2900/3923]	Acc@1: 47.880	
Test: [2950/3923]	Acc@1: 47.950	
Test: [3000/3923]	Acc@1: 47.934	
Test: [3050/3923]	Acc@1: 47.902	
Test: [3100/3923]	Acc@1: 47.791	
Test: [3150/3923]	Acc@1: 47.763	
Test: [3200/3923]	Acc@1: 47.860	
Test: [3250/3923]	Acc@1: 48.062	
Test: [3300/3923]	Acc@1: 48.046	
Test: [3350/3923]	Acc@1: 48.030	
Test: [3400/3923]	Acc@1: 48.074	
Test: [3450/3923]	Acc@1: 48.088	
Test: [3500/3923]	Acc@1: 48.058	
Test: [3550/3923]	Acc@1: 48.057	
Test: [3600/3923]	Acc@1: 48.042	
Test: [3650/3923]	Acc@1: 48.042	
Test: [3700/3923]	Acc@1: 48.190	
Test: [3750/3923]	Acc@1: 48.200	
Test: [3800/3923]	Acc@1: 48.316	
Test: [3850/3923]	Acc@1: 48.364	
Test: [3900/3923]	Acc@1: 48.411	
 * Acc@1 48.407 Acc@5 94.252 UAR 38.490Accuracy of the network on the 7847 test videos: 48.4%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [56/300][0/971]	eta 1:33:32 lr 0.000001835	time 5.7806 (5.7806)	tot_loss 0.3638 (0.3638)	mem 12198MB
Train: [56/300][50/971]	eta 0:07:42 lr 0.000001834	time 0.3655 (0.5019)	tot_loss 0.3947 (0.3825)	mem 12198MB
Train: [56/300][100/971]	eta 0:06:23 lr 0.000001834	time 0.3582 (0.4403)	tot_loss 0.4042 (0.3826)	mem 12198MB
Train: [56/300][150/971]	eta 0:05:43 lr 0.000001834	time 0.3602 (0.4186)	tot_loss 0.3142 (0.3821)	mem 12198MB
Train: [56/300][200/971]	eta 0:05:15 lr 0.000001833	time 0.3594 (0.4093)	tot_loss 0.4244 (0.3836)	mem 12198MB
Train: [56/300][250/971]	eta 0:04:50 lr 0.000001833	time 0.3470 (0.4030)	tot_loss 0.3816 (0.3851)	mem 12198MB
Train: [56/300][300/971]	eta 0:04:27 lr 0.000001833	time 0.3494 (0.3987)	tot_loss 0.3139 (0.3831)	mem 12198MB
Train: [56/300][350/971]	eta 0:04:06 lr 0.000001833	time 0.3550 (0.3963)	tot_loss 0.3697 (0.3824)	mem 12198MB
Train: [56/300][400/971]	eta 0:03:44 lr 0.000001832	time 0.3635 (0.3939)	tot_loss 0.3777 (0.3829)	mem 12198MB
Train: [56/300][450/971]	eta 0:03:24 lr 0.000001832	time 0.3612 (0.3923)	tot_loss 0.4287 (0.3829)	mem 12198MB
Train: [56/300][500/971]	eta 0:03:04 lr 0.000001832	time 0.3688 (0.3916)	tot_loss 0.3690 (0.3827)	mem 12198MB
Train: [56/300][550/971]	eta 0:02:44 lr 0.000001831	time 0.3671 (0.3912)	tot_loss 0.3795 (0.3822)	mem 12198MB
Train: [56/300][600/971]	eta 0:02:24 lr 0.000001831	time 0.3568 (0.3904)	tot_loss 0.4009 (0.3825)	mem 12198MB
Train: [56/300][650/971]	eta 0:02:05 lr 0.000001831	time 0.3652 (0.3895)	tot_loss 0.4031 (0.3825)	mem 12198MB
Train: [56/300][700/971]	eta 0:01:45 lr 0.000001830	time 0.3588 (0.3890)	tot_loss 0.3385 (0.3825)	mem 12198MB
Train: [56/300][750/971]	eta 0:01:25 lr 0.000001830	time 0.3668 (0.3886)	tot_loss 0.3253 (0.3828)	mem 12198MB
Train: [56/300][800/971]	eta 0:01:06 lr 0.000001830	time 0.3726 (0.3882)	tot_loss 0.3618 (0.3835)	mem 12198MB
Train: [56/300][850/971]	eta 0:00:46 lr 0.000001830	time 0.3669 (0.3879)	tot_loss 0.3808 (0.3839)	mem 12198MB
Train: [56/300][900/971]	eta 0:00:27 lr 0.000001829	time 0.3677 (0.3876)	tot_loss 0.3967 (0.3837)	mem 12198MB
Train: [56/300][950/971]	eta 0:00:08 lr 0.000001829	time 0.3338 (0.3868)	tot_loss 0.3874 (0.3839)	mem 12198MB
EPOCH 56 training takes 0:06:14
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 49.020	
Test: [100/3923]	Acc@1: 50.000	
Test: [150/3923]	Acc@1: 50.662	
Test: [200/3923]	Acc@1: 50.746	
Test: [250/3923]	Acc@1: 50.199	
Test: [300/3923]	Acc@1: 51.329	
Test: [350/3923]	Acc@1: 51.709	
Test: [400/3923]	Acc@1: 51.746	
Test: [450/3923]	Acc@1: 51.552	
Test: [500/3923]	Acc@1: 51.198	
Test: [550/3923]	Acc@1: 50.635	
Test: [600/3923]	Acc@1: 51.082	
Test: [650/3923]	Acc@1: 51.075	
Test: [700/3923]	Acc@1: 50.571	
Test: [750/3923]	Acc@1: 50.133	
Test: [800/3923]	Acc@1: 50.312	
Test: [850/3923]	Acc@1: 50.235	
Test: [900/3923]	Acc@1: 50.610	
Test: [950/3923]	Acc@1: 50.894	
Test: [1000/3923]	Acc@1: 50.649	
Test: [1050/3923]	Acc@1: 50.333	
Test: [1100/3923]	Acc@1: 50.136	
Test: [1150/3923]	Acc@1: 50.130	
Test: [1200/3923]	Acc@1: 50.291	
Test: [1250/3923]	Acc@1: 50.320	
Test: [1300/3923]	Acc@1: 50.231	
Test: [1350/3923]	Acc@1: 50.333	
Test: [1400/3923]	Acc@1: 50.321	
Test: [1450/3923]	Acc@1: 50.310	
Test: [1500/3923]	Acc@1: 50.266	
Test: [1550/3923]	Acc@1: 50.290	
Test: [1600/3923]	Acc@1: 50.344	
Test: [1650/3923]	Acc@1: 50.151	
Test: [1700/3923]	Acc@1: 50.147	
Test: [1750/3923]	Acc@1: 50.029	
Test: [1800/3923]	Acc@1: 50.056	
Test: [1850/3923]	Acc@1: 49.973	
Test: [1900/3923]	Acc@1: 49.921	
Test: [1950/3923]	Acc@1: 49.795	
Test: [2000/3923]	Acc@1: 49.725	
Test: [2050/3923]	Acc@1: 49.634	
Test: [2100/3923]	Acc@1: 49.595	
Test: [2150/3923]	Acc@1: 49.698	
Test: [2200/3923]	Acc@1: 49.796	
Test: [2250/3923]	Acc@1: 49.667	
Test: [2300/3923]	Acc@1: 49.674	
Test: [2350/3923]	Acc@1: 49.745	
Test: [2400/3923]	Acc@1: 49.875	
Test: [2450/3923]	Acc@1: 49.959	
Test: [2500/3923]	Acc@1: 50.040	
Test: [2550/3923]	Acc@1: 50.118	
Test: [2600/3923]	Acc@1: 50.192	
Test: [2650/3923]	Acc@1: 50.245	
Test: [2700/3923]	Acc@1: 50.296	
Test: [2750/3923]	Acc@1: 50.291	
Test: [2800/3923]	Acc@1: 50.179	
Test: [2850/3923]	Acc@1: 50.281	
Test: [2900/3923]	Acc@1: 50.155	
Test: [2950/3923]	Acc@1: 50.152	
Test: [3000/3923]	Acc@1: 50.183	
Test: [3050/3923]	Acc@1: 50.098	
Test: [3100/3923]	Acc@1: 50.097	
Test: [3150/3923]	Acc@1: 50.111	
Test: [3200/3923]	Acc@1: 50.141	
Test: [3250/3923]	Acc@1: 50.046	
Test: [3300/3923]	Acc@1: 50.045	
Test: [3350/3923]	Acc@1: 50.045	
Test: [3400/3923]	Acc@1: 50.059	
Test: [3450/3923]	Acc@1: 50.014	
Test: [3500/3923]	Acc@1: 50.000	
Test: [3550/3923]	Acc@1: 49.972	
Test: [3600/3923]	Acc@1: 50.000	
Test: [3650/3923]	Acc@1: 50.041	
Test: [3700/3923]	Acc@1: 50.149	
Test: [3750/3923]	Acc@1: 50.133	
Test: [3800/3923]	Acc@1: 50.132	
Test: [3850/3923]	Acc@1: 50.195	
Test: [3900/3923]	Acc@1: 50.154	
 * Acc@1 50.166 Acc@5 94.290 UAR 39.148Accuracy of the network on the 7847 test videos: 50.2%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [57/300][0/971]	eta 1:52:00 lr 0.000001829	time 6.9208 (6.9208)	tot_loss 0.4349 (0.4349)	mem 12198MB
Train: [57/300][50/971]	eta 0:08:07 lr 0.000001829	time 0.3638 (0.5298)	tot_loss 0.3802 (0.3810)	mem 12198MB
Train: [57/300][100/971]	eta 0:06:40 lr 0.000001828	time 0.3680 (0.4596)	tot_loss 0.3359 (0.3836)	mem 12198MB
Train: [57/300][150/971]	eta 0:05:56 lr 0.000001828	time 0.3609 (0.4341)	tot_loss 0.4128 (0.3850)	mem 12198MB
Train: [57/300][200/971]	eta 0:05:25 lr 0.000001828	time 0.3678 (0.4222)	tot_loss 0.4066 (0.3830)	mem 12198MB
Train: [57/300][250/971]	eta 0:04:59 lr 0.000001827	time 0.3588 (0.4149)	tot_loss 0.3991 (0.3826)	mem 12198MB
Train: [57/300][300/971]	eta 0:04:34 lr 0.000001827	time 0.3695 (0.4098)	tot_loss 0.3654 (0.3822)	mem 12198MB
Train: [57/300][350/971]	eta 0:04:12 lr 0.000001827	time 0.3702 (0.4073)	tot_loss 0.3294 (0.3819)	mem 12198MB
Train: [57/300][400/971]	eta 0:03:51 lr 0.000001826	time 0.3607 (0.4047)	tot_loss 0.4079 (0.3802)	mem 12200MB
Train: [57/300][450/971]	eta 0:03:30 lr 0.000001826	time 0.3759 (0.4032)	tot_loss 0.4282 (0.3806)	mem 12200MB
Train: [57/300][500/971]	eta 0:03:09 lr 0.000001826	time 0.3700 (0.4023)	tot_loss 0.4156 (0.3799)	mem 12200MB
Train: [57/300][550/971]	eta 0:02:49 lr 0.000001826	time 0.3654 (0.4014)	tot_loss 0.3165 (0.3798)	mem 12200MB
Train: [57/300][600/971]	eta 0:02:28 lr 0.000001825	time 0.3609 (0.3999)	tot_loss 0.2763 (0.3806)	mem 12200MB
Train: [57/300][650/971]	eta 0:02:07 lr 0.000001825	time 0.3624 (0.3984)	tot_loss 0.3742 (0.3803)	mem 12200MB
Train: [57/300][700/971]	eta 0:01:47 lr 0.000001825	time 0.3590 (0.3980)	tot_loss 0.4037 (0.3812)	mem 12200MB
Train: [57/300][750/971]	eta 0:01:27 lr 0.000001824	time 0.3627 (0.3969)	tot_loss 0.3832 (0.3815)	mem 12200MB
Train: [57/300][800/971]	eta 0:01:07 lr 0.000001824	time 0.3735 (0.3959)	tot_loss 0.3670 (0.3821)	mem 12200MB
Train: [57/300][850/971]	eta 0:00:47 lr 0.000001824	time 0.3670 (0.3951)	tot_loss 0.3979 (0.3824)	mem 12200MB
Train: [57/300][900/971]	eta 0:00:28 lr 0.000001823	time 0.3944 (0.3945)	tot_loss 0.3946 (0.3821)	mem 12200MB
Train: [57/300][950/971]	eta 0:00:08 lr 0.000001823	time 0.3324 (0.3936)	tot_loss 0.2923 (0.3824)	mem 12200MB
EPOCH 57 training takes 0:06:21
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 47.059	
Test: [100/3923]	Acc@1: 49.505	
Test: [150/3923]	Acc@1: 49.007	
Test: [200/3923]	Acc@1: 49.254	
Test: [250/3923]	Acc@1: 50.598	
Test: [300/3923]	Acc@1: 49.336	
Test: [350/3923]	Acc@1: 50.570	
Test: [400/3923]	Acc@1: 51.122	
Test: [450/3923]	Acc@1: 50.443	
Test: [500/3923]	Acc@1: 50.998	
Test: [550/3923]	Acc@1: 51.270	
Test: [600/3923]	Acc@1: 50.083	
Test: [650/3923]	Acc@1: 50.691	
Test: [700/3923]	Acc@1: 50.571	
Test: [750/3923]	Acc@1: 50.732	
Test: [800/3923]	Acc@1: 50.624	
Test: [850/3923]	Acc@1: 50.764	
Test: [900/3923]	Acc@1: 51.054	
Test: [950/3923]	Acc@1: 50.421	
Test: [1000/3923]	Acc@1: 50.599	
Test: [1050/3923]	Acc@1: 50.333	
Test: [1100/3923]	Acc@1: 50.500	
Test: [1150/3923]	Acc@1: 50.825	
Test: [1200/3923]	Acc@1: 50.833	
Test: [1250/3923]	Acc@1: 50.879	
Test: [1300/3923]	Acc@1: 50.846	
Test: [1350/3923]	Acc@1: 50.814	
Test: [1400/3923]	Acc@1: 50.857	
Test: [1450/3923]	Acc@1: 50.689	
Test: [1500/3923]	Acc@1: 50.866	
Test: [1550/3923]	Acc@1: 51.193	
Test: [1600/3923]	Acc@1: 51.374	
Test: [1650/3923]	Acc@1: 51.242	
Test: [1700/3923]	Acc@1: 51.440	
Test: [1750/3923]	Acc@1: 51.114	
Test: [1800/3923]	Acc@1: 51.027	
Test: [1850/3923]	Acc@1: 51.026	
Test: [1900/3923]	Acc@1: 50.894	
Test: [1950/3923]	Acc@1: 50.769	
Test: [2000/3923]	Acc@1: 50.750	
Test: [2050/3923]	Acc@1: 50.488	
Test: [2100/3923]	Acc@1: 50.571	
Test: [2150/3923]	Acc@1: 50.511	
Test: [2200/3923]	Acc@1: 50.522	
Test: [2250/3923]	Acc@1: 50.311	
Test: [2300/3923]	Acc@1: 50.261	
Test: [2350/3923]	Acc@1: 50.255	
Test: [2400/3923]	Acc@1: 50.250	
Test: [2450/3923]	Acc@1: 50.347	
Test: [2500/3923]	Acc@1: 50.340	
Test: [2550/3923]	Acc@1: 50.353	
Test: [2600/3923]	Acc@1: 50.327	
Test: [2650/3923]	Acc@1: 50.302	
Test: [2700/3923]	Acc@1: 50.407	
Test: [2750/3923]	Acc@1: 50.382	
Test: [2800/3923]	Acc@1: 50.428	
Test: [2850/3923]	Acc@1: 50.386	
Test: [2900/3923]	Acc@1: 50.500	
Test: [2950/3923]	Acc@1: 50.508	
Test: [3000/3923]	Acc@1: 50.633	
Test: [3050/3923]	Acc@1: 50.557	
Test: [3100/3923]	Acc@1: 50.451	
Test: [3150/3923]	Acc@1: 50.286	
Test: [3200/3923]	Acc@1: 50.312	
Test: [3250/3923]	Acc@1: 50.292	
Test: [3300/3923]	Acc@1: 50.333	
Test: [3350/3923]	Acc@1: 50.269	
Test: [3400/3923]	Acc@1: 50.206	
Test: [3450/3923]	Acc@1: 50.261	
Test: [3500/3923]	Acc@1: 50.428	
Test: [3550/3923]	Acc@1: 50.436	
Test: [3600/3923]	Acc@1: 50.417	
Test: [3650/3923]	Acc@1: 50.315	
Test: [3700/3923]	Acc@1: 50.392	
Test: [3750/3923]	Acc@1: 50.320	
Test: [3800/3923]	Acc@1: 50.250	
Test: [3850/3923]	Acc@1: 50.351	
Test: [3900/3923]	Acc@1: 50.256	
 * Acc@1 50.178 Acc@5 94.099 UAR 40.021Accuracy of the network on the 7847 test videos: 50.2%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [58/300][0/971]	eta 1:31:35 lr 0.000001823	time 5.6601 (5.6601)	tot_loss 0.3857 (0.3857)	mem 12200MB
Train: [58/300][50/971]	eta 0:07:43 lr 0.000001823	time 0.3639 (0.5036)	tot_loss 0.3087 (0.3763)	mem 12200MB
Train: [58/300][100/971]	eta 0:06:27 lr 0.000001822	time 0.3565 (0.4446)	tot_loss 0.3529 (0.3798)	mem 12200MB
Train: [58/300][150/971]	eta 0:05:47 lr 0.000001822	time 0.3635 (0.4238)	tot_loss 0.3841 (0.3819)	mem 12200MB
Train: [58/300][200/971]	eta 0:05:18 lr 0.000001822	time 0.3663 (0.4126)	tot_loss 0.3736 (0.3807)	mem 12200MB
Train: [58/300][250/971]	eta 0:04:52 lr 0.000001821	time 0.3620 (0.4060)	tot_loss 0.4299 (0.3811)	mem 12200MB
Train: [58/300][300/971]	eta 0:04:29 lr 0.000001821	time 0.3637 (0.4023)	tot_loss 0.4179 (0.3807)	mem 12200MB
Train: [58/300][350/971]	eta 0:04:08 lr 0.000001821	time 0.3588 (0.3994)	tot_loss 0.4329 (0.3805)	mem 12200MB
Train: [58/300][400/971]	eta 0:03:46 lr 0.000001820	time 0.3598 (0.3972)	tot_loss 0.3379 (0.3810)	mem 12200MB
Train: [58/300][450/971]	eta 0:03:26 lr 0.000001820	time 0.3705 (0.3956)	tot_loss 0.4026 (0.3804)	mem 12200MB
Train: [58/300][500/971]	eta 0:03:05 lr 0.000001820	time 0.3632 (0.3949)	tot_loss 0.4214 (0.3797)	mem 12200MB
Train: [58/300][550/971]	eta 0:02:45 lr 0.000001820	time 0.3615 (0.3934)	tot_loss 0.4221 (0.3796)	mem 12200MB
Train: [58/300][600/971]	eta 0:02:25 lr 0.000001819	time 0.3813 (0.3926)	tot_loss 0.4036 (0.3795)	mem 12200MB
Train: [58/300][650/971]	eta 0:02:05 lr 0.000001819	time 0.3626 (0.3922)	tot_loss 0.3125 (0.3797)	mem 12200MB
Train: [58/300][700/971]	eta 0:01:46 lr 0.000001819	time 0.3587 (0.3919)	tot_loss 0.3870 (0.3802)	mem 12200MB
Train: [58/300][750/971]	eta 0:01:26 lr 0.000001818	time 0.3603 (0.3911)	tot_loss 0.4037 (0.3802)	mem 12200MB
Train: [58/300][800/971]	eta 0:01:06 lr 0.000001818	time 0.3594 (0.3907)	tot_loss 0.3941 (0.3802)	mem 12200MB
Train: [58/300][850/971]	eta 0:00:47 lr 0.000001818	time 0.3704 (0.3903)	tot_loss 0.3865 (0.3810)	mem 12200MB
Train: [58/300][900/971]	eta 0:00:27 lr 0.000001817	time 0.3694 (0.3898)	tot_loss 0.4295 (0.3812)	mem 12200MB
Train: [58/300][950/971]	eta 0:00:08 lr 0.000001817	time 0.3303 (0.3893)	tot_loss 0.3941 (0.3811)	mem 12200MB
EPOCH 58 training takes 0:06:17
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 42.157	
Test: [100/3923]	Acc@1: 44.059	
Test: [150/3923]	Acc@1: 44.040	
Test: [200/3923]	Acc@1: 44.776	
Test: [250/3923]	Acc@1: 45.418	
Test: [300/3923]	Acc@1: 45.847	
Test: [350/3923]	Acc@1: 47.009	
Test: [400/3923]	Acc@1: 46.883	
Test: [450/3923]	Acc@1: 46.563	
Test: [500/3923]	Acc@1: 47.405	
Test: [550/3923]	Acc@1: 48.004	
Test: [600/3923]	Acc@1: 47.920	
Test: [650/3923]	Acc@1: 47.696	
Test: [700/3923]	Acc@1: 48.288	
Test: [750/3923]	Acc@1: 49.134	
Test: [800/3923]	Acc@1: 49.251	
Test: [850/3923]	Acc@1: 49.001	
Test: [900/3923]	Acc@1: 49.168	
Test: [950/3923]	Acc@1: 48.843	
Test: [1000/3923]	Acc@1: 48.851	
Test: [1050/3923]	Acc@1: 48.953	
Test: [1100/3923]	Acc@1: 49.319	
Test: [1150/3923]	Acc@1: 49.131	
Test: [1200/3923]	Acc@1: 48.876	
Test: [1250/3923]	Acc@1: 48.881	
Test: [1300/3923]	Acc@1: 49.001	
Test: [1350/3923]	Acc@1: 49.223	
Test: [1400/3923]	Acc@1: 49.286	
Test: [1450/3923]	Acc@1: 49.414	
Test: [1500/3923]	Acc@1: 49.101	
Test: [1550/3923]	Acc@1: 49.097	
Test: [1600/3923]	Acc@1: 49.063	
Test: [1650/3923]	Acc@1: 48.970	
Test: [1700/3923]	Acc@1: 48.971	
Test: [1750/3923]	Acc@1: 49.029	
Test: [1800/3923]	Acc@1: 49.084	
Test: [1850/3923]	Acc@1: 49.028	
Test: [1900/3923]	Acc@1: 48.869	
Test: [1950/3923]	Acc@1: 48.898	
Test: [2000/3923]	Acc@1: 48.926	
Test: [2050/3923]	Acc@1: 48.562	
Test: [2100/3923]	Acc@1: 48.572	
Test: [2150/3923]	Acc@1: 48.396	
Test: [2200/3923]	Acc@1: 48.342	
Test: [2250/3923]	Acc@1: 48.401	
Test: [2300/3923]	Acc@1: 48.262	
Test: [2350/3923]	Acc@1: 48.277	
Test: [2400/3923]	Acc@1: 48.334	
Test: [2450/3923]	Acc@1: 48.307	
Test: [2500/3923]	Acc@1: 48.201	
Test: [2550/3923]	Acc@1: 48.334	
Test: [2600/3923]	Acc@1: 48.385	
Test: [2650/3923]	Acc@1: 48.416	
Test: [2700/3923]	Acc@1: 48.278	
Test: [2750/3923]	Acc@1: 48.364	
Test: [2800/3923]	Acc@1: 48.268	
Test: [2850/3923]	Acc@1: 48.123	
Test: [2900/3923]	Acc@1: 48.035	
Test: [2950/3923]	Acc@1: 48.170	
Test: [3000/3923]	Acc@1: 48.301	
Test: [3050/3923]	Acc@1: 48.378	
Test: [3100/3923]	Acc@1: 48.339	
Test: [3150/3923]	Acc@1: 48.493	
Test: [3200/3923]	Acc@1: 48.625	
Test: [3250/3923]	Acc@1: 48.616	
Test: [3300/3923]	Acc@1: 48.561	
Test: [3350/3923]	Acc@1: 48.612	
Test: [3400/3923]	Acc@1: 48.736	
Test: [3450/3923]	Acc@1: 48.870	
Test: [3500/3923]	Acc@1: 49.015	
Test: [3550/3923]	Acc@1: 49.197	
Test: [3600/3923]	Acc@1: 49.125	
Test: [3650/3923]	Acc@1: 49.069	
Test: [3700/3923]	Acc@1: 49.095	
Test: [3750/3923]	Acc@1: 49.120	
Test: [3800/3923]	Acc@1: 49.092	
Test: [3850/3923]	Acc@1: 49.221	
Test: [3900/3923]	Acc@1: 49.193	
 * Acc@1 49.184 Acc@5 94.022 UAR 38.810Accuracy of the network on the 7847 test videos: 49.2%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [59/300][0/971]	eta 1:57:24 lr 0.000001817	time 7.2547 (7.2547)	tot_loss 0.3670 (0.3670)	mem 12200MB
Train: [59/300][50/971]	eta 0:08:13 lr 0.000001817	time 0.3764 (0.5357)	tot_loss 0.4286 (0.3844)	mem 12200MB
Train: [59/300][100/971]	eta 0:06:46 lr 0.000001816	time 0.3858 (0.4667)	tot_loss 0.2575 (0.3846)	mem 12200MB
Train: [59/300][150/971]	eta 0:06:01 lr 0.000001816	time 0.3634 (0.4408)	tot_loss 0.4026 (0.3873)	mem 12200MB
Train: [59/300][200/971]	eta 0:05:29 lr 0.000001816	time 0.3630 (0.4273)	tot_loss 0.4506 (0.3879)	mem 12200MB
Train: [59/300][250/971]	eta 0:05:01 lr 0.000001815	time 0.3574 (0.4184)	tot_loss 0.3554 (0.3837)	mem 12200MB
Train: [59/300][300/971]	eta 0:04:37 lr 0.000001815	time 0.3452 (0.4140)	tot_loss 0.3875 (0.3829)	mem 12200MB
Train: [59/300][350/971]	eta 0:04:14 lr 0.000001815	time 0.3755 (0.4099)	tot_loss 0.3789 (0.3824)	mem 12200MB
Train: [59/300][400/971]	eta 0:03:52 lr 0.000001815	time 0.3693 (0.4068)	tot_loss 0.3101 (0.3821)	mem 12200MB
Train: [59/300][450/971]	eta 0:03:30 lr 0.000001814	time 0.3992 (0.4050)	tot_loss 0.3167 (0.3811)	mem 12200MB
Train: [59/300][500/971]	eta 0:03:10 lr 0.000001814	time 0.3687 (0.4036)	tot_loss 0.4701 (0.3819)	mem 12200MB
Train: [59/300][550/971]	eta 0:02:49 lr 0.000001814	time 0.3754 (0.4027)	tot_loss 0.4104 (0.3817)	mem 12200MB
Train: [59/300][600/971]	eta 0:02:29 lr 0.000001813	time 0.3622 (0.4017)	tot_loss 0.4251 (0.3803)	mem 12200MB
Train: [59/300][650/971]	eta 0:02:08 lr 0.000001813	time 0.3594 (0.4006)	tot_loss 0.3919 (0.3801)	mem 12200MB
Train: [59/300][700/971]	eta 0:01:48 lr 0.000001813	time 0.3689 (0.3997)	tot_loss 0.4257 (0.3811)	mem 12200MB
Train: [59/300][750/971]	eta 0:01:28 lr 0.000001812	time 0.3731 (0.3988)	tot_loss 0.4353 (0.3820)	mem 12200MB
Train: [59/300][800/971]	eta 0:01:08 lr 0.000001812	time 0.3753 (0.3985)	tot_loss 0.3800 (0.3819)	mem 12200MB
Train: [59/300][850/971]	eta 0:00:48 lr 0.000001812	time 0.3623 (0.3979)	tot_loss 0.3030 (0.3821)	mem 12200MB
Train: [59/300][900/971]	eta 0:00:28 lr 0.000001811	time 0.3624 (0.3975)	tot_loss 0.3717 (0.3823)	mem 12200MB
Train: [59/300][950/971]	eta 0:00:08 lr 0.000001811	time 0.3302 (0.3965)	tot_loss 0.4381 (0.3821)	mem 12200MB
EPOCH 59 training takes 0:06:24
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 44.118	
Test: [100/3923]	Acc@1: 45.050	
Test: [150/3923]	Acc@1: 46.689	
Test: [200/3923]	Acc@1: 48.756	
Test: [250/3923]	Acc@1: 48.008	
Test: [300/3923]	Acc@1: 48.173	
Test: [350/3923]	Acc@1: 47.293	
Test: [400/3923]	Acc@1: 46.758	
Test: [450/3923]	Acc@1: 47.339	
Test: [500/3923]	Acc@1: 47.904	
Test: [550/3923]	Acc@1: 49.093	
Test: [600/3923]	Acc@1: 48.918	
Test: [650/3923]	Acc@1: 49.539	
Test: [700/3923]	Acc@1: 49.501	
Test: [750/3923]	Acc@1: 49.401	
Test: [800/3923]	Acc@1: 50.250	
Test: [850/3923]	Acc@1: 50.059	
Test: [900/3923]	Acc@1: 50.222	
Test: [950/3923]	Acc@1: 49.790	
Test: [1000/3923]	Acc@1: 49.650	
Test: [1050/3923]	Acc@1: 49.191	
Test: [1100/3923]	Acc@1: 49.319	
Test: [1150/3923]	Acc@1: 49.262	
Test: [1200/3923]	Acc@1: 49.042	
Test: [1250/3923]	Acc@1: 48.961	
Test: [1300/3923]	Acc@1: 49.231	
Test: [1350/3923]	Acc@1: 49.038	
Test: [1400/3923]	Acc@1: 49.143	
Test: [1450/3923]	Acc@1: 48.863	
Test: [1500/3923]	Acc@1: 48.834	
Test: [1550/3923]	Acc@1: 48.968	
Test: [1600/3923]	Acc@1: 48.969	
Test: [1650/3923]	Acc@1: 49.152	
Test: [1700/3923]	Acc@1: 49.059	
Test: [1750/3923]	Acc@1: 49.058	
Test: [1800/3923]	Acc@1: 49.001	
Test: [1850/3923]	Acc@1: 48.838	
Test: [1900/3923]	Acc@1: 49.053	
Test: [1950/3923]	Acc@1: 48.872	
Test: [2000/3923]	Acc@1: 48.726	
Test: [2050/3923]	Acc@1: 48.659	
Test: [2100/3923]	Acc@1: 48.739	
Test: [2150/3923]	Acc@1: 48.722	
Test: [2200/3923]	Acc@1: 48.887	
Test: [2250/3923]	Acc@1: 49.112	
Test: [2300/3923]	Acc@1: 48.979	
Test: [2350/3923]	Acc@1: 49.000	
Test: [2400/3923]	Acc@1: 49.042	
Test: [2450/3923]	Acc@1: 49.041	
Test: [2500/3923]	Acc@1: 49.000	
Test: [2550/3923]	Acc@1: 49.196	
Test: [2600/3923]	Acc@1: 49.212	
Test: [2650/3923]	Acc@1: 49.208	
Test: [2700/3923]	Acc@1: 49.241	
Test: [2750/3923]	Acc@1: 49.164	
Test: [2800/3923]	Acc@1: 49.143	
Test: [2850/3923]	Acc@1: 49.141	
Test: [2900/3923]	Acc@1: 49.380	
Test: [2950/3923]	Acc@1: 49.407	
Test: [3000/3923]	Acc@1: 49.334	
Test: [3050/3923]	Acc@1: 49.361	
Test: [3100/3923]	Acc@1: 49.307	
Test: [3150/3923]	Acc@1: 49.318	
Test: [3200/3923]	Acc@1: 49.250	
Test: [3250/3923]	Acc@1: 49.185	
Test: [3300/3923]	Acc@1: 49.288	
Test: [3350/3923]	Acc@1: 49.358	
Test: [3400/3923]	Acc@1: 49.632	
Test: [3450/3923]	Acc@1: 49.609	
Test: [3500/3923]	Acc@1: 49.643	
Test: [3550/3923]	Acc@1: 49.718	
Test: [3600/3923]	Acc@1: 49.625	
Test: [3650/3923]	Acc@1: 49.726	
Test: [3700/3923]	Acc@1: 49.703	
Test: [3750/3923]	Acc@1: 49.667	
Test: [3800/3923]	Acc@1: 49.605	
Test: [3850/3923]	Acc@1: 49.610	
Test: [3900/3923]	Acc@1: 49.577	
 * Acc@1 49.579 Acc@5 94.226 UAR 40.402Accuracy of the network on the 7847 test videos: 49.6%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [60/300][0/971]	eta 1:42:02 lr 0.000001811	time 6.3053 (6.3053)	tot_loss 0.3934 (0.3934)	mem 12200MB
Train: [60/300][50/971]	eta 0:07:58 lr 0.000001811	time 0.3650 (0.5192)	tot_loss 0.2730 (0.3846)	mem 12200MB
Train: [60/300][100/971]	eta 0:06:33 lr 0.000001810	time 0.3557 (0.4520)	tot_loss 0.3390 (0.3802)	mem 12200MB
Train: [60/300][150/971]	eta 0:05:50 lr 0.000001810	time 0.3563 (0.4275)	tot_loss 0.3987 (0.3769)	mem 12200MB
Train: [60/300][200/971]	eta 0:05:20 lr 0.000001810	time 0.3591 (0.4157)	tot_loss 0.4295 (0.3798)	mem 12200MB
Train: [60/300][250/971]	eta 0:04:55 lr 0.000001809	time 0.3587 (0.4093)	tot_loss 0.3555 (0.3810)	mem 12200MB
Train: [60/300][300/971]	eta 0:04:31 lr 0.000001809	time 0.3583 (0.4051)	tot_loss 0.4084 (0.3802)	mem 12200MB
Train: [60/300][350/971]	eta 0:04:09 lr 0.000001809	time 0.3688 (0.4022)	tot_loss 0.4291 (0.3797)	mem 12200MB
Train: [60/300][400/971]	eta 0:03:48 lr 0.000001808	time 0.3628 (0.3996)	tot_loss 0.4120 (0.3803)	mem 12200MB
Train: [60/300][450/971]	eta 0:03:27 lr 0.000001808	time 0.3656 (0.3976)	tot_loss 0.4211 (0.3801)	mem 12200MB
Train: [60/300][500/971]	eta 0:03:06 lr 0.000001808	time 0.3633 (0.3969)	tot_loss 0.3093 (0.3800)	mem 12200MB
Train: [60/300][550/971]	eta 0:02:46 lr 0.000001807	time 0.3597 (0.3954)	tot_loss 0.4618 (0.3799)	mem 12200MB
Train: [60/300][600/971]	eta 0:02:26 lr 0.000001807	time 0.3584 (0.3942)	tot_loss 0.4326 (0.3797)	mem 12200MB
Train: [60/300][650/971]	eta 0:02:06 lr 0.000001807	time 0.3764 (0.3934)	tot_loss 0.3506 (0.3796)	mem 12200MB
Train: [60/300][700/971]	eta 0:01:46 lr 0.000001807	time 0.3691 (0.3931)	tot_loss 0.3403 (0.3805)	mem 12200MB
Train: [60/300][750/971]	eta 0:01:26 lr 0.000001806	time 0.3634 (0.3925)	tot_loss 0.3531 (0.3804)	mem 12200MB
Train: [60/300][800/971]	eta 0:01:07 lr 0.000001806	time 0.3686 (0.3923)	tot_loss 0.4351 (0.3802)	mem 12200MB
Train: [60/300][850/971]	eta 0:00:47 lr 0.000001806	time 0.3732 (0.3920)	tot_loss 0.3616 (0.3802)	mem 12200MB
Train: [60/300][900/971]	eta 0:00:27 lr 0.000001805	time 0.3628 (0.3918)	tot_loss 0.4433 (0.3804)	mem 12200MB
Train: [60/300][950/971]	eta 0:00:08 lr 0.000001805	time 0.3282 (0.3909)	tot_loss 0.4129 (0.3808)	mem 12200MB
EPOCH 60 training takes 0:06:19
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 41.176	
Test: [100/3923]	Acc@1: 46.535	
Test: [150/3923]	Acc@1: 48.344	
Test: [200/3923]	Acc@1: 47.761	
Test: [250/3923]	Acc@1: 48.805	
Test: [300/3923]	Acc@1: 48.671	
Test: [350/3923]	Acc@1: 48.148	
Test: [400/3923]	Acc@1: 48.005	
Test: [450/3923]	Acc@1: 48.891	
Test: [500/3923]	Acc@1: 48.703	
Test: [550/3923]	Acc@1: 49.093	
Test: [600/3923]	Acc@1: 49.251	
Test: [650/3923]	Acc@1: 49.846	
Test: [700/3923]	Acc@1: 49.857	
Test: [750/3923]	Acc@1: 49.601	
Test: [800/3923]	Acc@1: 50.062	
Test: [850/3923]	Acc@1: 50.470	
Test: [900/3923]	Acc@1: 49.945	
Test: [950/3923]	Acc@1: 49.790	
Test: [1000/3923]	Acc@1: 50.050	
Test: [1050/3923]	Acc@1: 50.000	
Test: [1100/3923]	Acc@1: 50.045	
Test: [1150/3923]	Acc@1: 49.870	
Test: [1200/3923]	Acc@1: 50.208	
Test: [1250/3923]	Acc@1: 50.160	
Test: [1300/3923]	Acc@1: 50.115	
Test: [1350/3923]	Acc@1: 50.222	
Test: [1400/3923]	Acc@1: 50.286	
Test: [1450/3923]	Acc@1: 50.103	
Test: [1500/3923]	Acc@1: 50.000	
Test: [1550/3923]	Acc@1: 49.710	
Test: [1600/3923]	Acc@1: 49.969	
Test: [1650/3923]	Acc@1: 49.727	
Test: [1700/3923]	Acc@1: 49.824	
Test: [1750/3923]	Acc@1: 50.000	
Test: [1800/3923]	Acc@1: 49.944	
Test: [1850/3923]	Acc@1: 49.757	
Test: [1900/3923]	Acc@1: 49.842	
Test: [1950/3923]	Acc@1: 49.872	
Test: [2000/3923]	Acc@1: 50.075	
Test: [2050/3923]	Acc@1: 49.951	
Test: [2100/3923]	Acc@1: 50.048	
Test: [2150/3923]	Acc@1: 49.977	
Test: [2200/3923]	Acc@1: 49.818	
Test: [2250/3923]	Acc@1: 49.889	
Test: [2300/3923]	Acc@1: 49.696	
Test: [2350/3923]	Acc@1: 49.575	
Test: [2400/3923]	Acc@1: 49.646	
Test: [2450/3923]	Acc@1: 49.674	
Test: [2500/3923]	Acc@1: 49.420	
Test: [2550/3923]	Acc@1: 49.392	
Test: [2600/3923]	Acc@1: 49.500	
Test: [2650/3923]	Acc@1: 49.453	
Test: [2700/3923]	Acc@1: 49.445	
Test: [2750/3923]	Acc@1: 49.473	
Test: [2800/3923]	Acc@1: 49.554	
Test: [2850/3923]	Acc@1: 49.544	
Test: [2900/3923]	Acc@1: 49.638	
Test: [2950/3923]	Acc@1: 49.712	
Test: [3000/3923]	Acc@1: 49.733	
Test: [3050/3923]	Acc@1: 49.672	
Test: [3100/3923]	Acc@1: 49.678	
Test: [3150/3923]	Acc@1: 49.699	
Test: [3200/3923]	Acc@1: 49.641	
Test: [3250/3923]	Acc@1: 49.631	
Test: [3300/3923]	Acc@1: 49.682	
Test: [3350/3923]	Acc@1: 49.746	
Test: [3400/3923]	Acc@1: 49.809	
Test: [3450/3923]	Acc@1: 49.826	
Test: [3500/3923]	Acc@1: 49.800	
Test: [3550/3923]	Acc@1: 49.662	
Test: [3600/3923]	Acc@1: 49.708	
Test: [3650/3923]	Acc@1: 49.726	
Test: [3700/3923]	Acc@1: 49.797	
Test: [3750/3923]	Acc@1: 49.800	
Test: [3800/3923]	Acc@1: 49.803	
Test: [3850/3923]	Acc@1: 49.844	
Test: [3900/3923]	Acc@1: 49.833	
 * Acc@1 49.822 Acc@5 93.984 UAR 39.276Accuracy of the network on the 7847 test videos: 49.8%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [61/300][0/971]	eta 1:37:15 lr 0.000001805	time 6.0097 (6.0097)	tot_loss 0.3996 (0.3996)	mem 12200MB
Train: [61/300][50/971]	eta 0:08:05 lr 0.000001804	time 0.3727 (0.5270)	tot_loss 0.2885 (0.3834)	mem 12200MB
Train: [61/300][100/971]	eta 0:06:42 lr 0.000001804	time 0.3601 (0.4625)	tot_loss 0.4496 (0.3805)	mem 12200MB
Train: [61/300][150/971]	eta 0:05:58 lr 0.000001804	time 0.3680 (0.4371)	tot_loss 0.3638 (0.3799)	mem 12200MB
Train: [61/300][200/971]	eta 0:05:27 lr 0.000001804	time 0.3723 (0.4252)	tot_loss 0.3620 (0.3771)	mem 12200MB
Train: [61/300][250/971]	eta 0:05:02 lr 0.000001803	time 0.3673 (0.4192)	tot_loss 0.3422 (0.3770)	mem 12200MB
Train: [61/300][300/971]	eta 0:04:38 lr 0.000001803	time 0.3565 (0.4144)	tot_loss 0.3698 (0.3766)	mem 12200MB
Train: [61/300][350/971]	eta 0:04:14 lr 0.000001803	time 0.3683 (0.4104)	tot_loss 0.3995 (0.3769)	mem 12200MB
Train: [61/300][400/971]	eta 0:03:52 lr 0.000001802	time 0.3742 (0.4077)	tot_loss 0.2736 (0.3770)	mem 12200MB
Train: [61/300][450/971]	eta 0:03:31 lr 0.000001802	time 0.3783 (0.4056)	tot_loss 0.2878 (0.3772)	mem 12200MB
Train: [61/300][500/971]	eta 0:03:10 lr 0.000001802	time 0.3636 (0.4036)	tot_loss 0.3910 (0.3768)	mem 12200MB
Train: [61/300][550/971]	eta 0:02:49 lr 0.000001801	time 0.3710 (0.4025)	tot_loss 0.3380 (0.3764)	mem 12200MB
Train: [61/300][600/971]	eta 0:02:29 lr 0.000001801	time 0.3664 (0.4018)	tot_loss 0.3349 (0.3773)	mem 12200MB
Train: [61/300][650/971]	eta 0:02:08 lr 0.000001801	time 0.3707 (0.4002)	tot_loss 0.4301 (0.3776)	mem 12200MB
Train: [61/300][700/971]	eta 0:01:48 lr 0.000001800	time 0.3657 (0.3993)	tot_loss 0.4342 (0.3783)	mem 12200MB
Train: [61/300][750/971]	eta 0:01:28 lr 0.000001800	time 0.3771 (0.3986)	tot_loss 0.3966 (0.3781)	mem 12200MB
Train: [61/300][800/971]	eta 0:01:08 lr 0.000001800	time 0.3745 (0.3983)	tot_loss 0.4117 (0.3783)	mem 12200MB
Train: [61/300][850/971]	eta 0:00:48 lr 0.000001799	time 0.3776 (0.3982)	tot_loss 0.3179 (0.3783)	mem 12200MB
Train: [61/300][900/971]	eta 0:00:28 lr 0.000001799	time 0.3653 (0.3976)	tot_loss 0.3398 (0.3791)	mem 12200MB
Train: [61/300][950/971]	eta 0:00:08 lr 0.000001799	time 0.3349 (0.3971)	tot_loss 0.4042 (0.3794)	mem 12200MB
EPOCH 61 training takes 0:06:24
1 views inference
Test: [0/3923]	Acc@1: 0.000	
Test: [50/3923]	Acc@1: 45.098	
Test: [100/3923]	Acc@1: 46.535	
Test: [150/3923]	Acc@1: 46.689	
Test: [200/3923]	Acc@1: 48.507	
Test: [250/3923]	Acc@1: 48.406	
Test: [300/3923]	Acc@1: 49.169	
Test: [350/3923]	Acc@1: 50.000	
Test: [400/3923]	Acc@1: 50.374	
Test: [450/3923]	Acc@1: 49.667	
Test: [500/3923]	Acc@1: 48.603	
Test: [550/3923]	Acc@1: 49.365	
Test: [600/3923]	Acc@1: 49.251	
Test: [650/3923]	Acc@1: 48.694	
Test: [700/3923]	Acc@1: 48.573	
Test: [750/3923]	Acc@1: 48.602	
Test: [800/3923]	Acc@1: 48.627	
Test: [850/3923]	Acc@1: 48.590	
Test: [900/3923]	Acc@1: 48.835	
Test: [950/3923]	Acc@1: 49.001	
Test: [1000/3923]	Acc@1: 48.901	
Test: [1050/3923]	Acc@1: 48.573	
Test: [1100/3923]	Acc@1: 48.456	
Test: [1150/3923]	Acc@1: 48.480	
Test: [1200/3923]	Acc@1: 48.293	
Test: [1250/3923]	Acc@1: 48.241	
Test: [1300/3923]	Acc@1: 48.002	
Test: [1350/3923]	Acc@1: 47.742	
Test: [1400/3923]	Acc@1: 48.323	
Test: [1450/3923]	Acc@1: 48.312	
Test: [1500/3923]	Acc@1: 48.534	
Test: [1550/3923]	Acc@1: 48.614	
Test: [1600/3923]	Acc@1: 48.563	
Test: [1650/3923]	Acc@1: 48.667	
Test: [1700/3923]	Acc@1: 48.648	
Test: [1750/3923]	Acc@1: 48.744	
Test: [1800/3923]	Acc@1: 48.612	
Test: [1850/3923]	Acc@1: 48.595	
Test: [1900/3923]	Acc@1: 48.685	
Test: [1950/3923]	Acc@1: 48.642	
Test: [2000/3923]	Acc@1: 48.726	
Test: [2050/3923]	Acc@1: 48.708	
Test: [2100/3923]	Acc@1: 48.667	
Test: [2150/3923]	Acc@1: 48.745	
Test: [2200/3923]	Acc@1: 48.932	
Test: [2250/3923]	Acc@1: 48.845	
Test: [2300/3923]	Acc@1: 48.848	
Test: [2350/3923]	Acc@1: 48.830	
Test: [2400/3923]	Acc@1: 49.105	
Test: [2450/3923]	Acc@1: 49.000	
Test: [2500/3923]	Acc@1: 48.940	
Test: [2550/3923]	Acc@1: 49.020	
Test: [2600/3923]	Acc@1: 48.962	
Test: [2650/3923]	Acc@1: 48.812	
Test: [2700/3923]	Acc@1: 48.778	
Test: [2750/3923]	Acc@1: 49.073	
Test: [2800/3923]	Acc@1: 49.161	
Test: [2850/3923]	Acc@1: 49.158	
Test: [2900/3923]	Acc@1: 49.224	
Test: [2950/3923]	Acc@1: 49.254	
Test: [3000/3923]	Acc@1: 49.367	
Test: [3050/3923]	Acc@1: 49.459	
Test: [3100/3923]	Acc@1: 49.500	
Test: [3150/3923]	Acc@1: 49.460	
Test: [3200/3923]	Acc@1: 49.563	
Test: [3250/3923]	Acc@1: 49.569	
Test: [3300/3923]	Acc@1: 49.652	
Test: [3350/3923]	Acc@1: 49.612	
Test: [3400/3923]	Acc@1: 49.647	
Test: [3450/3923]	Acc@1: 49.580	
Test: [3500/3923]	Acc@1: 49.600	
Test: [3550/3923]	Acc@1: 49.564	
Test: [3600/3923]	Acc@1: 49.528	
Test: [3650/3923]	Acc@1: 49.480	
Test: [3700/3923]	Acc@1: 49.554	
Test: [3750/3923]	Acc@1: 49.653	
Test: [3800/3923]	Acc@1: 49.553	
Test: [3850/3923]	Acc@1: 49.494	
Test: [3900/3923]	Acc@1: 49.539	
 * Acc@1 49.554 Acc@5 93.857 UAR 39.463Accuracy of the network on the 7847 test videos: 49.6%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [62/300][0/971]	eta 1:28:17 lr 0.000001799	time 5.4560 (5.4560)	tot_loss 0.3299 (0.3299)	mem 12200MB
Train: [62/300][50/971]	eta 0:07:56 lr 0.000001798	time 0.3983 (0.5178)	tot_loss 0.3151 (0.3781)	mem 12200MB
Train: [62/300][100/971]	eta 0:06:33 lr 0.000001798	time 0.3584 (0.4516)	tot_loss 0.3153 (0.3746)	mem 12200MB
Train: [62/300][150/971]	eta 0:05:50 lr 0.000001798	time 0.3595 (0.4275)	tot_loss 0.3780 (0.3761)	mem 12200MB
Train: [62/300][200/971]	eta 0:05:20 lr 0.000001797	time 0.3698 (0.4160)	tot_loss 0.3927 (0.3758)	mem 12200MB
Train: [62/300][250/971]	eta 0:04:56 lr 0.000001797	time 0.3569 (0.4109)	tot_loss 0.4074 (0.3788)	mem 12200MB
Train: [62/300][300/971]	eta 0:04:32 lr 0.000001797	time 0.3631 (0.4063)	tot_loss 0.3938 (0.3791)	mem 12200MB
Train: [62/300][350/971]	eta 0:04:09 lr 0.000001796	time 0.3641 (0.4025)	tot_loss 0.4192 (0.3791)	mem 12200MB
Train: [62/300][400/971]	eta 0:03:48 lr 0.000001796	time 0.3657 (0.4004)	tot_loss 0.3353 (0.3799)	mem 12200MB
Train: [62/300][450/971]	eta 0:03:27 lr 0.000001796	time 0.3637 (0.3981)	tot_loss 0.4034 (0.3809)	mem 12200MB
Train: [62/300][500/971]	eta 0:03:06 lr 0.000001795	time 0.3623 (0.3966)	tot_loss 0.4271 (0.3813)	mem 12200MB
Train: [62/300][550/971]	eta 0:02:46 lr 0.000001795	time 0.3612 (0.3951)	tot_loss 0.3944 (0.3818)	mem 12200MB
Train: [62/300][600/971]	eta 0:02:26 lr 0.000001795	time 0.3597 (0.3940)	tot_loss 0.3072 (0.3814)	mem 12200MB
Train: [62/300][650/971]	eta 0:02:06 lr 0.000001794	time 0.3760 (0.3933)	tot_loss 0.3971 (0.3817)	mem 12200MB
Train: [62/300][700/971]	eta 0:01:46 lr 0.000001794	time 0.3724 (0.3925)	tot_loss 0.4140 (0.3819)	mem 12200MB
Train: [62/300][750/971]	eta 0:01:26 lr 0.000001794	time 0.3631 (0.3920)	tot_loss 0.3876 (0.3818)	mem 12200MB
Train: [62/300][800/971]	eta 0:01:07 lr 0.000001793	time 0.3670 (0.3918)	tot_loss 0.3730 (0.3816)	mem 12200MB
Train: [62/300][850/971]	eta 0:00:47 lr 0.000001793	time 0.3678 (0.3915)	tot_loss 0.4204 (0.3816)	mem 12200MB
Train: [62/300][900/971]	eta 0:00:27 lr 0.000001793	time 0.3636 (0.3912)	tot_loss 0.3925 (0.3815)	mem 12200MB
Train: [62/300][950/971]	eta 0:00:08 lr 0.000001792	time 0.3287 (0.3904)	tot_loss 0.3462 (0.3810)	mem 12200MB
EPOCH 62 training takes 0:06:18
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 44.118	
Test: [100/3923]	Acc@1: 46.535	
Test: [150/3923]	Acc@1: 46.358	
Test: [200/3923]	Acc@1: 46.269	
Test: [250/3923]	Acc@1: 46.414	
Test: [300/3923]	Acc@1: 47.508	
Test: [350/3923]	Acc@1: 47.721	
Test: [400/3923]	Acc@1: 47.880	
Test: [450/3923]	Acc@1: 47.561	
Test: [500/3923]	Acc@1: 48.004	
Test: [550/3923]	Acc@1: 47.731	
Test: [600/3923]	Acc@1: 48.253	
Test: [650/3923]	Acc@1: 48.310	
Test: [700/3923]	Acc@1: 47.932	
Test: [750/3923]	Acc@1: 48.469	
Test: [800/3923]	Acc@1: 47.940	
Test: [850/3923]	Acc@1: 47.944	
Test: [900/3923]	Acc@1: 47.558	
Test: [950/3923]	Acc@1: 47.371	
Test: [1000/3923]	Acc@1: 47.652	
Test: [1050/3923]	Acc@1: 47.954	
Test: [1100/3923]	Acc@1: 48.183	
Test: [1150/3923]	Acc@1: 48.610	
Test: [1200/3923]	Acc@1: 48.834	
Test: [1250/3923]	Acc@1: 48.681	
Test: [1300/3923]	Acc@1: 48.578	
Test: [1350/3923]	Acc@1: 48.668	
Test: [1400/3923]	Acc@1: 49.215	
Test: [1450/3923]	Acc@1: 49.380	
Test: [1500/3923]	Acc@1: 49.134	
Test: [1550/3923]	Acc@1: 49.130	
Test: [1600/3923]	Acc@1: 49.344	
Test: [1650/3923]	Acc@1: 49.364	
Test: [1700/3923]	Acc@1: 49.559	
Test: [1750/3923]	Acc@1: 49.315	
Test: [1800/3923]	Acc@1: 49.445	
Test: [1850/3923]	Acc@1: 49.487	
Test: [1900/3923]	Acc@1: 49.605	
Test: [1950/3923]	Acc@1: 49.462	
Test: [2000/3923]	Acc@1: 49.400	
Test: [2050/3923]	Acc@1: 49.391	
Test: [2100/3923]	Acc@1: 49.524	
Test: [2150/3923]	Acc@1: 49.651	
Test: [2200/3923]	Acc@1: 49.705	
Test: [2250/3923]	Acc@1: 49.711	
Test: [2300/3923]	Acc@1: 49.891	
Test: [2350/3923]	Acc@1: 49.851	
Test: [2400/3923]	Acc@1: 49.896	
Test: [2450/3923]	Acc@1: 49.653	
Test: [2500/3923]	Acc@1: 49.600	
Test: [2550/3923]	Acc@1: 49.647	
Test: [2600/3923]	Acc@1: 49.577	
Test: [2650/3923]	Acc@1: 49.378	
Test: [2700/3923]	Acc@1: 49.297	
Test: [2750/3923]	Acc@1: 49.146	
Test: [2800/3923]	Acc@1: 49.179	
Test: [2850/3923]	Acc@1: 49.246	
Test: [2900/3923]	Acc@1: 49.173	
Test: [2950/3923]	Acc@1: 49.271	
Test: [3000/3923]	Acc@1: 49.334	
Test: [3050/3923]	Acc@1: 49.295	
Test: [3100/3923]	Acc@1: 49.307	
Test: [3150/3923]	Acc@1: 49.334	
Test: [3200/3923]	Acc@1: 49.406	
Test: [3250/3923]	Acc@1: 49.400	
Test: [3300/3923]	Acc@1: 49.394	
Test: [3350/3923]	Acc@1: 49.418	
Test: [3400/3923]	Acc@1: 49.515	
Test: [3450/3923]	Acc@1: 49.464	
Test: [3500/3923]	Acc@1: 49.500	
Test: [3550/3923]	Acc@1: 49.535	
Test: [3600/3923]	Acc@1: 49.570	
Test: [3650/3923]	Acc@1: 49.493	
Test: [3700/3923]	Acc@1: 49.460	
Test: [3750/3923]	Acc@1: 49.480	
Test: [3800/3923]	Acc@1: 49.566	
Test: [3850/3923]	Acc@1: 49.559	
Test: [3900/3923]	Acc@1: 49.590	
 * Acc@1 49.579 Acc@5 94.010 UAR 39.832Accuracy of the network on the 7847 test videos: 49.6%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [63/300][0/971]	eta 1:15:46 lr 0.000001792	time 4.6822 (4.6822)	tot_loss 0.3832 (0.3832)	mem 12200MB
Train: [63/300][50/971]	eta 0:07:36 lr 0.000001792	time 0.3598 (0.4961)	tot_loss 0.4198 (0.3813)	mem 12200MB
Train: [63/300][100/971]	eta 0:06:21 lr 0.000001792	time 0.3545 (0.4381)	tot_loss 0.3236 (0.3779)	mem 12200MB
Train: [63/300][150/971]	eta 0:05:42 lr 0.000001791	time 0.3665 (0.4170)	tot_loss 0.2989 (0.3766)	mem 12200MB
Train: [63/300][200/971]	eta 0:05:14 lr 0.000001791	time 0.3599 (0.4075)	tot_loss 0.3869 (0.3761)	mem 12200MB
Train: [63/300][250/971]	eta 0:04:49 lr 0.000001791	time 0.3642 (0.4016)	tot_loss 0.3564 (0.3771)	mem 12200MB
Train: [63/300][300/971]	eta 0:04:26 lr 0.000001790	time 0.3608 (0.3976)	tot_loss 0.3030 (0.3773)	mem 12200MB
Train: [63/300][350/971]	eta 0:04:04 lr 0.000001790	time 0.3640 (0.3945)	tot_loss 0.3845 (0.3779)	mem 12200MB
Train: [63/300][400/971]	eta 0:03:44 lr 0.000001790	time 0.3706 (0.3929)	tot_loss 0.3601 (0.3793)	mem 12200MB
Train: [63/300][450/971]	eta 0:03:23 lr 0.000001789	time 0.3634 (0.3912)	tot_loss 0.4369 (0.3788)	mem 12200MB
Train: [63/300][500/971]	eta 0:03:03 lr 0.000001789	time 0.3622 (0.3905)	tot_loss 0.3255 (0.3783)	mem 12200MB
Train: [63/300][550/971]	eta 0:02:44 lr 0.000001789	time 0.3663 (0.3903)	tot_loss 0.4180 (0.3783)	mem 12200MB
Train: [63/300][600/971]	eta 0:02:24 lr 0.000001788	time 0.3484 (0.3896)	tot_loss 0.3915 (0.3783)	mem 12200MB
Train: [63/300][650/971]	eta 0:02:04 lr 0.000001788	time 0.3543 (0.3884)	tot_loss 0.3867 (0.3788)	mem 12200MB
Train: [63/300][700/971]	eta 0:01:45 lr 0.000001788	time 0.3602 (0.3876)	tot_loss 0.4056 (0.3793)	mem 12200MB
Train: [63/300][750/971]	eta 0:01:25 lr 0.000001787	time 0.3738 (0.3873)	tot_loss 0.3429 (0.3792)	mem 12200MB
Train: [63/300][800/971]	eta 0:01:06 lr 0.000001787	time 0.3697 (0.3871)	tot_loss 0.3683 (0.3795)	mem 12200MB
Train: [63/300][850/971]	eta 0:00:46 lr 0.000001787	time 0.3640 (0.3867)	tot_loss 0.4069 (0.3793)	mem 12200MB
Train: [63/300][900/971]	eta 0:00:27 lr 0.000001786	time 0.3586 (0.3867)	tot_loss 0.2970 (0.3798)	mem 12200MB
Train: [63/300][950/971]	eta 0:00:08 lr 0.000001786	time 0.3315 (0.3862)	tot_loss 0.4299 (0.3796)	mem 12200MB
EPOCH 63 training takes 0:06:14
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 36.275	
Test: [100/3923]	Acc@1: 44.059	
Test: [150/3923]	Acc@1: 49.338	
Test: [200/3923]	Acc@1: 47.015	
Test: [250/3923]	Acc@1: 46.016	
Test: [300/3923]	Acc@1: 46.179	
Test: [350/3923]	Acc@1: 47.721	
Test: [400/3923]	Acc@1: 48.504	
Test: [450/3923]	Acc@1: 49.002	
Test: [500/3923]	Acc@1: 48.603	
Test: [550/3923]	Acc@1: 48.820	
Test: [600/3923]	Acc@1: 48.918	
Test: [650/3923]	Acc@1: 49.386	
Test: [700/3923]	Acc@1: 49.144	
Test: [750/3923]	Acc@1: 49.134	
Test: [800/3923]	Acc@1: 48.814	
Test: [850/3923]	Acc@1: 48.766	
Test: [900/3923]	Acc@1: 48.724	
Test: [950/3923]	Acc@1: 48.738	
Test: [1000/3923]	Acc@1: 48.601	
Test: [1050/3923]	Acc@1: 48.716	
Test: [1100/3923]	Acc@1: 48.910	
Test: [1150/3923]	Acc@1: 48.957	
Test: [1200/3923]	Acc@1: 49.209	
Test: [1250/3923]	Acc@1: 48.881	
Test: [1300/3923]	Acc@1: 49.078	
Test: [1350/3923]	Acc@1: 49.297	
Test: [1400/3923]	Acc@1: 49.251	
Test: [1450/3923]	Acc@1: 49.242	
Test: [1500/3923]	Acc@1: 49.034	
Test: [1550/3923]	Acc@1: 49.162	
Test: [1600/3923]	Acc@1: 48.844	
Test: [1650/3923]	Acc@1: 48.879	
Test: [1700/3923]	Acc@1: 48.795	
Test: [1750/3923]	Acc@1: 48.572	
Test: [1800/3923]	Acc@1: 48.445	
Test: [1850/3923]	Acc@1: 48.433	
Test: [1900/3923]	Acc@1: 48.396	
Test: [1950/3923]	Acc@1: 48.462	
Test: [2000/3923]	Acc@1: 48.351	
Test: [2050/3923]	Acc@1: 48.391	
Test: [2100/3923]	Acc@1: 48.596	
Test: [2150/3923]	Acc@1: 48.675	
Test: [2200/3923]	Acc@1: 48.955	
Test: [2250/3923]	Acc@1: 49.067	
Test: [2300/3923]	Acc@1: 49.087	
Test: [2350/3923]	Acc@1: 49.000	
Test: [2400/3923]	Acc@1: 49.042	
Test: [2450/3923]	Acc@1: 49.082	
Test: [2500/3923]	Acc@1: 49.160	
Test: [2550/3923]	Acc@1: 49.196	
Test: [2600/3923]	Acc@1: 49.077	
Test: [2650/3923]	Acc@1: 48.944	
Test: [2700/3923]	Acc@1: 48.982	
Test: [2750/3923]	Acc@1: 48.982	
Test: [2800/3923]	Acc@1: 48.822	
Test: [2850/3923]	Acc@1: 48.720	
Test: [2900/3923]	Acc@1: 48.794	
Test: [2950/3923]	Acc@1: 48.848	
Test: [3000/3923]	Acc@1: 48.967	
Test: [3050/3923]	Acc@1: 49.082	
Test: [3100/3923]	Acc@1: 48.952	
Test: [3150/3923]	Acc@1: 49.191	
Test: [3200/3923]	Acc@1: 49.172	
Test: [3250/3923]	Acc@1: 49.246	
Test: [3300/3923]	Acc@1: 49.182	
Test: [3350/3923]	Acc@1: 49.269	
Test: [3400/3923]	Acc@1: 49.177	
Test: [3450/3923]	Acc@1: 49.131	
Test: [3500/3923]	Acc@1: 49.115	
Test: [3550/3923]	Acc@1: 49.113	
Test: [3600/3923]	Acc@1: 49.139	
Test: [3650/3923]	Acc@1: 49.192	
Test: [3700/3923]	Acc@1: 49.203	
Test: [3750/3923]	Acc@1: 49.267	
Test: [3800/3923]	Acc@1: 49.395	
Test: [3850/3923]	Acc@1: 49.390	
Test: [3900/3923]	Acc@1: 49.423	
 * Acc@1 49.439 Acc@5 93.806 UAR 40.815Accuracy of the network on the 7847 test videos: 49.4%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [64/300][0/971]	eta 1:19:04 lr 0.000001786	time 4.8863 (4.8863)	tot_loss 0.3947 (0.3947)	mem 12200MB
Train: [64/300][50/971]	eta 0:07:45 lr 0.000001786	time 0.3651 (0.5050)	tot_loss 0.3368 (0.3790)	mem 12200MB
Train: [64/300][100/971]	eta 0:06:26 lr 0.000001785	time 0.3560 (0.4439)	tot_loss 0.4115 (0.3774)	mem 12200MB
Train: [64/300][150/971]	eta 0:05:46 lr 0.000001785	time 0.3622 (0.4220)	tot_loss 0.4261 (0.3748)	mem 12200MB
Train: [64/300][200/971]	eta 0:05:18 lr 0.000001785	time 0.3565 (0.4126)	tot_loss 0.2954 (0.3747)	mem 12200MB
Train: [64/300][250/971]	eta 0:04:52 lr 0.000001784	time 0.3730 (0.4057)	tot_loss 0.4015 (0.3767)	mem 12200MB
Train: [64/300][300/971]	eta 0:04:29 lr 0.000001784	time 0.3589 (0.4016)	tot_loss 0.4047 (0.3746)	mem 12200MB
Train: [64/300][350/971]	eta 0:04:07 lr 0.000001784	time 0.3549 (0.3985)	tot_loss 0.3702 (0.3747)	mem 12200MB
Train: [64/300][400/971]	eta 0:03:46 lr 0.000001783	time 0.3601 (0.3960)	tot_loss 0.3437 (0.3743)	mem 12200MB
Train: [64/300][450/971]	eta 0:03:25 lr 0.000001783	time 0.3667 (0.3949)	tot_loss 0.3997 (0.3757)	mem 12200MB
Train: [64/300][500/971]	eta 0:03:05 lr 0.000001783	time 0.3599 (0.3934)	tot_loss 0.3111 (0.3766)	mem 12200MB
Train: [64/300][550/971]	eta 0:02:45 lr 0.000001782	time 0.3609 (0.3925)	tot_loss 0.3108 (0.3767)	mem 12200MB
Train: [64/300][600/971]	eta 0:02:25 lr 0.000001782	time 0.3755 (0.3918)	tot_loss 0.2848 (0.3771)	mem 12200MB
Train: [64/300][650/971]	eta 0:02:05 lr 0.000001782	time 0.3601 (0.3914)	tot_loss 0.4394 (0.3787)	mem 12200MB
Train: [64/300][700/971]	eta 0:01:45 lr 0.000001781	time 0.3529 (0.3907)	tot_loss 0.3672 (0.3780)	mem 12200MB
Train: [64/300][750/971]	eta 0:01:26 lr 0.000001781	time 0.3638 (0.3902)	tot_loss 0.3551 (0.3778)	mem 12200MB
Train: [64/300][800/971]	eta 0:01:06 lr 0.000001781	time 0.3513 (0.3895)	tot_loss 0.3635 (0.3776)	mem 12200MB
Train: [64/300][850/971]	eta 0:00:47 lr 0.000001780	time 0.3567 (0.3888)	tot_loss 0.4468 (0.3777)	mem 12200MB
Train: [64/300][900/971]	eta 0:00:27 lr 0.000001780	time 0.3626 (0.3889)	tot_loss 0.3268 (0.3773)	mem 12200MB
Train: [64/300][950/971]	eta 0:00:08 lr 0.000001780	time 0.3263 (0.3880)	tot_loss 0.4454 (0.3774)	mem 12200MB
EPOCH 64 training takes 0:06:16
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 53.922	
Test: [100/3923]	Acc@1: 48.515	
Test: [150/3923]	Acc@1: 49.669	
Test: [200/3923]	Acc@1: 49.254	
Test: [250/3923]	Acc@1: 48.406	
Test: [300/3923]	Acc@1: 49.502	
Test: [350/3923]	Acc@1: 48.433	
Test: [400/3923]	Acc@1: 48.254	
Test: [450/3923]	Acc@1: 48.670	
Test: [500/3923]	Acc@1: 49.301	
Test: [550/3923]	Acc@1: 49.456	
Test: [600/3923]	Acc@1: 49.834	
Test: [650/3923]	Acc@1: 49.923	
Test: [700/3923]	Acc@1: 49.572	
Test: [750/3923]	Acc@1: 49.268	
Test: [800/3923]	Acc@1: 49.001	
Test: [850/3923]	Acc@1: 49.001	
Test: [900/3923]	Acc@1: 49.279	
Test: [950/3923]	Acc@1: 48.791	
Test: [1000/3923]	Acc@1: 49.051	
Test: [1050/3923]	Acc@1: 49.429	
Test: [1100/3923]	Acc@1: 49.319	
Test: [1150/3923]	Acc@1: 49.696	
Test: [1200/3923]	Acc@1: 50.042	
Test: [1250/3923]	Acc@1: 49.880	
Test: [1300/3923]	Acc@1: 49.923	
Test: [1350/3923]	Acc@1: 49.593	
Test: [1400/3923]	Acc@1: 49.500	
Test: [1450/3923]	Acc@1: 49.690	
Test: [1500/3923]	Acc@1: 49.700	
Test: [1550/3923]	Acc@1: 49.645	
Test: [1600/3923]	Acc@1: 49.438	
Test: [1650/3923]	Acc@1: 49.606	
Test: [1700/3923]	Acc@1: 49.383	
Test: [1750/3923]	Acc@1: 49.258	
Test: [1800/3923]	Acc@1: 49.278	
Test: [1850/3923]	Acc@1: 49.244	
Test: [1900/3923]	Acc@1: 49.158	
Test: [1950/3923]	Acc@1: 49.103	
Test: [2000/3923]	Acc@1: 49.175	
Test: [2050/3923]	Acc@1: 49.317	
Test: [2100/3923]	Acc@1: 49.453	
Test: [2150/3923]	Acc@1: 49.768	
Test: [2200/3923]	Acc@1: 49.909	
Test: [2250/3923]	Acc@1: 49.845	
Test: [2300/3923]	Acc@1: 49.870	
Test: [2350/3923]	Acc@1: 49.936	
Test: [2400/3923]	Acc@1: 49.917	
Test: [2450/3923]	Acc@1: 49.878	
Test: [2500/3923]	Acc@1: 49.940	
Test: [2550/3923]	Acc@1: 49.922	
Test: [2600/3923]	Acc@1: 49.616	
Test: [2650/3923]	Acc@1: 49.661	
Test: [2700/3923]	Acc@1: 49.759	
Test: [2750/3923]	Acc@1: 49.709	
Test: [2800/3923]	Acc@1: 49.804	
Test: [2850/3923]	Acc@1: 49.614	
Test: [2900/3923]	Acc@1: 49.586	
Test: [2950/3923]	Acc@1: 49.627	
Test: [3000/3923]	Acc@1: 49.733	
Test: [3050/3923]	Acc@1: 49.672	
Test: [3100/3923]	Acc@1: 49.613	
Test: [3150/3923]	Acc@1: 49.476	
Test: [3200/3923]	Acc@1: 49.500	
Test: [3250/3923]	Acc@1: 49.523	
Test: [3300/3923]	Acc@1: 49.621	
Test: [3350/3923]	Acc@1: 49.702	
Test: [3400/3923]	Acc@1: 49.677	
Test: [3450/3923]	Acc@1: 49.710	
Test: [3500/3923]	Acc@1: 49.757	
Test: [3550/3923]	Acc@1: 49.732	
Test: [3600/3923]	Acc@1: 49.695	
Test: [3650/3923]	Acc@1: 49.658	
Test: [3700/3923]	Acc@1: 49.608	
Test: [3750/3923]	Acc@1: 49.653	
Test: [3800/3923]	Acc@1: 49.658	
Test: [3850/3923]	Acc@1: 49.662	
Test: [3900/3923]	Acc@1: 49.680	
 * Acc@1 49.618 Acc@5 93.334 UAR 39.892Accuracy of the network on the 7847 test videos: 49.6%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [65/300][0/971]	eta 1:08:09 lr 0.000001779	time 4.2112 (4.2112)	tot_loss 0.3999 (0.3999)	mem 12200MB
Train: [65/300][50/971]	eta 0:07:41 lr 0.000001779	time 0.3682 (0.5015)	tot_loss 0.3725 (0.3808)	mem 12200MB
Train: [65/300][100/971]	eta 0:06:28 lr 0.000001779	time 0.3617 (0.4460)	tot_loss 0.4612 (0.3834)	mem 12200MB
Train: [65/300][150/971]	eta 0:05:53 lr 0.000001778	time 0.3717 (0.4310)	tot_loss 0.2846 (0.3816)	mem 12200MB
Train: [65/300][200/971]	eta 0:05:26 lr 0.000001778	time 0.3823 (0.4235)	tot_loss 0.4331 (0.3813)	mem 12200MB
Train: [65/300][250/971]	eta 0:04:59 lr 0.000001778	time 0.3700 (0.4153)	tot_loss 0.3898 (0.3782)	mem 12200MB
Train: [65/300][300/971]	eta 0:04:36 lr 0.000001777	time 0.3677 (0.4117)	tot_loss 0.4123 (0.3804)	mem 12200MB
Train: [65/300][350/971]	eta 0:04:13 lr 0.000001777	time 0.3585 (0.4080)	tot_loss 0.3997 (0.3798)	mem 12200MB
Train: [65/300][400/971]	eta 0:03:51 lr 0.000001777	time 0.3593 (0.4048)	tot_loss 0.3931 (0.3818)	mem 12200MB
Train: [65/300][450/971]	eta 0:03:29 lr 0.000001776	time 0.3623 (0.4026)	tot_loss 0.3583 (0.3822)	mem 12200MB
Train: [65/300][500/971]	eta 0:03:08 lr 0.000001776	time 0.3672 (0.4008)	tot_loss 0.3826 (0.3824)	mem 12200MB
Train: [65/300][550/971]	eta 0:02:47 lr 0.000001776	time 0.3652 (0.3990)	tot_loss 0.4079 (0.3818)	mem 12200MB
Train: [65/300][600/971]	eta 0:02:27 lr 0.000001775	time 0.3642 (0.3978)	tot_loss 0.4170 (0.3822)	mem 12200MB
Train: [65/300][650/971]	eta 0:02:07 lr 0.000001775	time 0.3680 (0.3969)	tot_loss 0.4182 (0.3822)	mem 12200MB
Train: [65/300][700/971]	eta 0:01:47 lr 0.000001775	time 0.3662 (0.3961)	tot_loss 0.2671 (0.3825)	mem 12200MB
Train: [65/300][750/971]	eta 0:01:27 lr 0.000001774	time 0.3900 (0.3957)	tot_loss 0.3906 (0.3826)	mem 12200MB
Train: [65/300][800/971]	eta 0:01:07 lr 0.000001774	time 0.3636 (0.3958)	tot_loss 0.3412 (0.3817)	mem 12200MB
Train: [65/300][850/971]	eta 0:00:47 lr 0.000001774	time 0.3601 (0.3950)	tot_loss 0.3927 (0.3817)	mem 12200MB
Train: [65/300][900/971]	eta 0:00:27 lr 0.000001773	time 0.3642 (0.3943)	tot_loss 0.4140 (0.3814)	mem 12200MB
Train: [65/300][950/971]	eta 0:00:08 lr 0.000001773	time 0.3316 (0.3934)	tot_loss 0.3633 (0.3811)	mem 12200MB
EPOCH 65 training takes 0:06:21
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 49.020	
Test: [100/3923]	Acc@1: 48.515	
Test: [150/3923]	Acc@1: 49.669	
Test: [200/3923]	Acc@1: 50.498	
Test: [250/3923]	Acc@1: 49.801	
Test: [300/3923]	Acc@1: 49.834	
Test: [350/3923]	Acc@1: 49.003	
Test: [400/3923]	Acc@1: 49.002	
Test: [450/3923]	Acc@1: 48.337	
Test: [500/3923]	Acc@1: 49.501	
Test: [550/3923]	Acc@1: 49.093	
Test: [600/3923]	Acc@1: 49.501	
Test: [650/3923]	Acc@1: 49.002	
Test: [700/3923]	Acc@1: 48.716	
Test: [750/3923]	Acc@1: 48.602	
Test: [800/3923]	Acc@1: 48.689	
Test: [850/3923]	Acc@1: 48.590	
Test: [900/3923]	Acc@1: 49.279	
Test: [950/3923]	Acc@1: 49.474	
Test: [1000/3923]	Acc@1: 49.900	
Test: [1050/3923]	Acc@1: 49.952	
Test: [1100/3923]	Acc@1: 49.909	
Test: [1150/3923]	Acc@1: 50.174	
Test: [1200/3923]	Acc@1: 50.416	
Test: [1250/3923]	Acc@1: 50.160	
Test: [1300/3923]	Acc@1: 49.962	
Test: [1350/3923]	Acc@1: 50.037	
Test: [1400/3923]	Acc@1: 50.000	
Test: [1450/3923]	Acc@1: 50.069	
Test: [1500/3923]	Acc@1: 50.000	
Test: [1550/3923]	Acc@1: 50.032	
Test: [1600/3923]	Acc@1: 49.969	
Test: [1650/3923]	Acc@1: 50.000	
Test: [1700/3923]	Acc@1: 50.294	
Test: [1750/3923]	Acc@1: 49.971	
Test: [1800/3923]	Acc@1: 49.889	
Test: [1850/3923]	Acc@1: 49.676	
Test: [1900/3923]	Acc@1: 49.868	
Test: [1950/3923]	Acc@1: 49.769	
Test: [2000/3923]	Acc@1: 49.675	
Test: [2050/3923]	Acc@1: 49.586	
Test: [2100/3923]	Acc@1: 49.833	
Test: [2150/3923]	Acc@1: 49.930	
Test: [2200/3923]	Acc@1: 49.841	
Test: [2250/3923]	Acc@1: 50.000	
Test: [2300/3923]	Acc@1: 49.783	
Test: [2350/3923]	Acc@1: 49.745	
Test: [2400/3923]	Acc@1: 49.688	
Test: [2450/3923]	Acc@1: 49.633	
Test: [2500/3923]	Acc@1: 49.820	
Test: [2550/3923]	Acc@1: 49.843	
Test: [2600/3923]	Acc@1: 49.923	
Test: [2650/3923]	Acc@1: 49.887	
Test: [2700/3923]	Acc@1: 49.963	
Test: [2750/3923]	Acc@1: 49.945	
Test: [2800/3923]	Acc@1: 49.821	
Test: [2850/3923]	Acc@1: 49.912	
Test: [2900/3923]	Acc@1: 49.741	
Test: [2950/3923]	Acc@1: 49.797	
Test: [3000/3923]	Acc@1: 49.683	
Test: [3050/3923]	Acc@1: 49.803	
Test: [3100/3923]	Acc@1: 49.758	
Test: [3150/3923]	Acc@1: 49.683	
Test: [3200/3923]	Acc@1: 49.844	
Test: [3250/3923]	Acc@1: 49.831	
Test: [3300/3923]	Acc@1: 49.879	
Test: [3350/3923]	Acc@1: 49.896	
Test: [3400/3923]	Acc@1: 49.926	
Test: [3450/3923]	Acc@1: 49.783	
Test: [3500/3923]	Acc@1: 49.843	
Test: [3550/3923]	Acc@1: 49.845	
Test: [3600/3923]	Acc@1: 49.764	
Test: [3650/3923]	Acc@1: 49.836	
Test: [3700/3923]	Acc@1: 49.865	
Test: [3750/3923]	Acc@1: 49.933	
Test: [3800/3923]	Acc@1: 50.066	
Test: [3850/3923]	Acc@1: 50.091	
Test: [3900/3923]	Acc@1: 49.987	
 * Acc@1 49.924 Acc@5 93.321 UAR 40.187Accuracy of the network on the 7847 test videos: 49.9%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [66/300][0/971]	eta 1:16:52 lr 0.000001773	time 4.7499 (4.7499)	tot_loss 0.4179 (0.4179)	mem 12200MB
Train: [66/300][50/971]	eta 0:07:12 lr 0.000001772	time 0.3585 (0.4701)	tot_loss 0.4059 (0.3884)	mem 12200MB
Train: [66/300][100/971]	eta 0:06:13 lr 0.000001772	time 0.3481 (0.4291)	tot_loss 0.3675 (0.3842)	mem 12200MB
Train: [66/300][150/971]	eta 0:05:40 lr 0.000001772	time 0.3546 (0.4148)	tot_loss 0.4178 (0.3794)	mem 12200MB
Train: [66/300][200/971]	eta 0:05:13 lr 0.000001771	time 0.3449 (0.4070)	tot_loss 0.3907 (0.3782)	mem 12200MB
Train: [66/300][250/971]	eta 0:04:48 lr 0.000001771	time 0.3614 (0.4001)	tot_loss 0.3063 (0.3762)	mem 12200MB
Train: [66/300][300/971]	eta 0:04:26 lr 0.000001771	time 0.3560 (0.3976)	tot_loss 0.3906 (0.3778)	mem 12200MB
Train: [66/300][350/971]	eta 0:04:05 lr 0.000001770	time 0.3546 (0.3947)	tot_loss 0.4134 (0.3776)	mem 12200MB
Train: [66/300][400/971]	eta 0:03:44 lr 0.000001770	time 0.3874 (0.3929)	tot_loss 0.3528 (0.3775)	mem 12200MB
Train: [66/300][450/971]	eta 0:03:23 lr 0.000001770	time 0.3580 (0.3910)	tot_loss 0.4226 (0.3771)	mem 12200MB
Train: [66/300][500/971]	eta 0:03:03 lr 0.000001769	time 0.3538 (0.3894)	tot_loss 0.3092 (0.3757)	mem 12200MB
Train: [66/300][550/971]	eta 0:02:43 lr 0.000001769	time 0.3515 (0.3890)	tot_loss 0.4038 (0.3760)	mem 12200MB
Train: [66/300][600/971]	eta 0:02:23 lr 0.000001769	time 0.3489 (0.3879)	tot_loss 0.4120 (0.3767)	mem 12200MB
Train: [66/300][650/971]	eta 0:02:04 lr 0.000001768	time 0.3834 (0.3871)	tot_loss 0.3198 (0.3768)	mem 12200MB
Train: [66/300][700/971]	eta 0:01:45 lr 0.000001768	time 0.3720 (0.3879)	tot_loss 0.3734 (0.3769)	mem 12200MB
Train: [66/300][750/971]	eta 0:01:25 lr 0.000001768	time 0.3661 (0.3881)	tot_loss 0.3007 (0.3768)	mem 12200MB
Train: [66/300][800/971]	eta 0:01:06 lr 0.000001767	time 0.3492 (0.3877)	tot_loss 0.3855 (0.3764)	mem 12200MB
Train: [66/300][850/971]	eta 0:00:46 lr 0.000001767	time 0.4025 (0.3872)	tot_loss 0.4891 (0.3764)	mem 12200MB
Train: [66/300][900/971]	eta 0:00:27 lr 0.000001767	time 0.3548 (0.3876)	tot_loss 0.2986 (0.3765)	mem 12200MB
Train: [66/300][950/971]	eta 0:00:08 lr 0.000001766	time 0.3672 (0.3882)	tot_loss 0.3647 (0.3770)	mem 12200MB
EPOCH 66 training takes 0:06:17
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 46.078	
Test: [100/3923]	Acc@1: 48.515	
Test: [150/3923]	Acc@1: 48.675	
Test: [200/3923]	Acc@1: 49.751	
Test: [250/3923]	Acc@1: 48.805	
Test: [300/3923]	Acc@1: 49.336	
Test: [350/3923]	Acc@1: 50.000	
Test: [400/3923]	Acc@1: 49.626	
Test: [450/3923]	Acc@1: 50.000	
Test: [500/3923]	Acc@1: 50.998	
Test: [550/3923]	Acc@1: 50.907	
Test: [600/3923]	Acc@1: 50.666	
Test: [650/3923]	Acc@1: 50.845	
Test: [700/3923]	Acc@1: 50.713	
Test: [750/3923]	Acc@1: 50.599	
Test: [800/3923]	Acc@1: 50.437	
Test: [850/3923]	Acc@1: 50.470	
Test: [900/3923]	Acc@1: 50.555	
Test: [950/3923]	Acc@1: 50.841	
Test: [1000/3923]	Acc@1: 50.599	
Test: [1050/3923]	Acc@1: 50.571	
Test: [1100/3923]	Acc@1: 50.590	
Test: [1150/3923]	Acc@1: 50.869	
Test: [1200/3923]	Acc@1: 51.041	
Test: [1250/3923]	Acc@1: 51.079	
Test: [1300/3923]	Acc@1: 50.884	
Test: [1350/3923]	Acc@1: 50.740	
Test: [1400/3923]	Acc@1: 50.749	
Test: [1450/3923]	Acc@1: 50.689	
Test: [1500/3923]	Acc@1: 50.933	
Test: [1550/3923]	Acc@1: 50.709	
Test: [1600/3923]	Acc@1: 50.375	
Test: [1650/3923]	Acc@1: 50.303	
Test: [1700/3923]	Acc@1: 50.147	
Test: [1750/3923]	Acc@1: 49.971	
Test: [1800/3923]	Acc@1: 50.056	
Test: [1850/3923]	Acc@1: 50.000	
Test: [1900/3923]	Acc@1: 50.079	
Test: [1950/3923]	Acc@1: 50.256	
Test: [2000/3923]	Acc@1: 50.375	
Test: [2050/3923]	Acc@1: 50.195	
Test: [2100/3923]	Acc@1: 50.309	
Test: [2150/3923]	Acc@1: 50.163	
Test: [2200/3923]	Acc@1: 50.023	
Test: [2250/3923]	Acc@1: 50.133	
Test: [2300/3923]	Acc@1: 50.196	
Test: [2350/3923]	Acc@1: 50.043	
Test: [2400/3923]	Acc@1: 50.042	
Test: [2450/3923]	Acc@1: 50.020	
Test: [2500/3923]	Acc@1: 50.060	
Test: [2550/3923]	Acc@1: 49.980	
Test: [2600/3923]	Acc@1: 49.865	
Test: [2650/3923]	Acc@1: 50.019	
Test: [2700/3923]	Acc@1: 49.926	
Test: [2750/3923]	Acc@1: 49.800	
Test: [2800/3923]	Acc@1: 49.786	
Test: [2850/3923]	Acc@1: 49.877	
Test: [2900/3923]	Acc@1: 49.897	
Test: [2950/3923]	Acc@1: 49.932	
Test: [3000/3923]	Acc@1: 49.883	
Test: [3050/3923]	Acc@1: 49.902	
Test: [3100/3923]	Acc@1: 49.936	
Test: [3150/3923]	Acc@1: 49.905	
Test: [3200/3923]	Acc@1: 49.938	
Test: [3250/3923]	Acc@1: 50.000	
Test: [3300/3923]	Acc@1: 50.136	
Test: [3350/3923]	Acc@1: 50.075	
Test: [3400/3923]	Acc@1: 50.059	
Test: [3450/3923]	Acc@1: 49.841	
Test: [3500/3923]	Acc@1: 49.829	
Test: [3550/3923]	Acc@1: 49.958	
Test: [3600/3923]	Acc@1: 49.986	
Test: [3650/3923]	Acc@1: 49.986	
Test: [3700/3923]	Acc@1: 50.054	
Test: [3750/3923]	Acc@1: 50.000	
Test: [3800/3923]	Acc@1: 50.026	
Test: [3850/3923]	Acc@1: 50.026	
Test: [3900/3923]	Acc@1: 49.897	
 * Acc@1 49.873 Acc@5 93.844 UAR 39.782Accuracy of the network on the 7847 test videos: 49.9%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [67/300][0/971]	eta 1:26:31 lr 0.000001766	time 5.3466 (5.3466)	tot_loss 0.3838 (0.3838)	mem 12200MB
Train: [67/300][50/971]	eta 0:07:30 lr 0.000001766	time 0.3677 (0.4895)	tot_loss 0.3030 (0.3769)	mem 12200MB
Train: [67/300][100/971]	eta 0:06:20 lr 0.000001765	time 0.4123 (0.4373)	tot_loss 0.3239 (0.3774)	mem 12200MB
Train: [67/300][150/971]	eta 0:05:45 lr 0.000001765	time 0.3619 (0.4204)	tot_loss 0.3343 (0.3763)	mem 12200MB
Train: [67/300][200/971]	eta 0:05:18 lr 0.000001765	time 0.3797 (0.4134)	tot_loss 0.3964 (0.3759)	mem 12200MB
Train: [67/300][250/971]	eta 0:04:53 lr 0.000001764	time 0.3597 (0.4072)	tot_loss 0.3500 (0.3773)	mem 12200MB
Train: [67/300][300/971]	eta 0:04:31 lr 0.000001764	time 0.3571 (0.4040)	tot_loss 0.2487 (0.3760)	mem 12200MB
Train: [67/300][350/971]	eta 0:04:08 lr 0.000001764	time 0.3662 (0.4009)	tot_loss 0.3840 (0.3780)	mem 12200MB
Train: [67/300][400/971]	eta 0:03:48 lr 0.000001763	time 0.3649 (0.3997)	tot_loss 0.3769 (0.3772)	mem 12200MB
Train: [67/300][450/971]	eta 0:03:27 lr 0.000001763	time 0.3648 (0.3990)	tot_loss 0.4156 (0.3766)	mem 12200MB
Train: [67/300][500/971]	eta 0:03:07 lr 0.000001763	time 0.3739 (0.3983)	tot_loss 0.3996 (0.3768)	mem 12200MB
Train: [67/300][550/971]	eta 0:02:47 lr 0.000001762	time 0.3543 (0.3973)	tot_loss 0.3559 (0.3770)	mem 12200MB
Train: [67/300][600/971]	eta 0:02:27 lr 0.000001762	time 0.3701 (0.3973)	tot_loss 0.4307 (0.3774)	mem 12200MB
Train: [67/300][650/971]	eta 0:02:07 lr 0.000001762	time 0.3610 (0.3965)	tot_loss 0.3648 (0.3778)	mem 12200MB
Train: [67/300][700/971]	eta 0:01:47 lr 0.000001761	time 0.3861 (0.3958)	tot_loss 0.3920 (0.3775)	mem 12200MB
Train: [67/300][750/971]	eta 0:01:27 lr 0.000001761	time 0.3840 (0.3955)	tot_loss 0.4335 (0.3766)	mem 12200MB
Train: [67/300][800/971]	eta 0:01:07 lr 0.000001761	time 0.3495 (0.3962)	tot_loss 0.4095 (0.3774)	mem 12200MB
Train: [67/300][850/971]	eta 0:00:47 lr 0.000001760	time 0.3942 (0.3955)	tot_loss 0.4059 (0.3773)	mem 12200MB
Train: [67/300][900/971]	eta 0:00:28 lr 0.000001760	time 0.3645 (0.3951)	tot_loss 0.3345 (0.3772)	mem 12200MB
Train: [67/300][950/971]	eta 0:00:08 lr 0.000001760	time 0.3399 (0.3946)	tot_loss 0.3798 (0.3772)	mem 12200MB
EPOCH 67 training takes 0:06:22
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 44.118	
Test: [100/3923]	Acc@1: 48.020	
Test: [150/3923]	Acc@1: 48.013	
Test: [200/3923]	Acc@1: 48.507	
Test: [250/3923]	Acc@1: 47.410	
Test: [300/3923]	Acc@1: 47.674	
Test: [350/3923]	Acc@1: 47.721	
Test: [400/3923]	Acc@1: 47.880	
Test: [450/3923]	Acc@1: 48.226	
Test: [500/3923]	Acc@1: 48.802	
Test: [550/3923]	Acc@1: 48.730	
Test: [600/3923]	Acc@1: 49.584	
Test: [650/3923]	Acc@1: 49.616	
Test: [700/3923]	Acc@1: 49.929	
Test: [750/3923]	Acc@1: 49.933	
Test: [800/3923]	Acc@1: 49.501	
Test: [850/3923]	Acc@1: 49.295	
Test: [900/3923]	Acc@1: 49.390	
Test: [950/3923]	Acc@1: 49.317	
Test: [1000/3923]	Acc@1: 48.901	
Test: [1050/3923]	Acc@1: 49.096	
Test: [1100/3923]	Acc@1: 48.774	
Test: [1150/3923]	Acc@1: 48.827	
Test: [1200/3923]	Acc@1: 49.251	
Test: [1250/3923]	Acc@1: 49.161	
Test: [1300/3923]	Acc@1: 49.154	
Test: [1350/3923]	Acc@1: 49.001	
Test: [1400/3923]	Acc@1: 48.822	
Test: [1450/3923]	Acc@1: 49.035	
Test: [1500/3923]	Acc@1: 48.934	
Test: [1550/3923]	Acc@1: 49.162	
Test: [1600/3923]	Acc@1: 49.500	
Test: [1650/3923]	Acc@1: 49.455	
Test: [1700/3923]	Acc@1: 49.471	
Test: [1750/3923]	Acc@1: 49.400	
Test: [1800/3923]	Acc@1: 49.611	
Test: [1850/3923]	Acc@1: 49.406	
Test: [1900/3923]	Acc@1: 49.421	
Test: [1950/3923]	Acc@1: 49.129	
Test: [2000/3923]	Acc@1: 49.325	
Test: [2050/3923]	Acc@1: 49.196	
Test: [2100/3923]	Acc@1: 49.096	
Test: [2150/3923]	Acc@1: 49.024	
Test: [2200/3923]	Acc@1: 49.182	
Test: [2250/3923]	Acc@1: 49.023	
Test: [2300/3923]	Acc@1: 49.022	
Test: [2350/3923]	Acc@1: 49.064	
Test: [2400/3923]	Acc@1: 48.959	
Test: [2450/3923]	Acc@1: 49.082	
Test: [2500/3923]	Acc@1: 49.120	
Test: [2550/3923]	Acc@1: 49.118	
Test: [2600/3923]	Acc@1: 49.135	
Test: [2650/3923]	Acc@1: 49.019	
Test: [2700/3923]	Acc@1: 48.982	
Test: [2750/3923]	Acc@1: 49.091	
Test: [2800/3923]	Acc@1: 49.107	
Test: [2850/3923]	Acc@1: 49.053	
Test: [2900/3923]	Acc@1: 49.121	
Test: [2950/3923]	Acc@1: 49.000	
Test: [3000/3923]	Acc@1: 49.067	
Test: [3050/3923]	Acc@1: 49.017	
Test: [3100/3923]	Acc@1: 49.145	
Test: [3150/3923]	Acc@1: 49.175	
Test: [3200/3923]	Acc@1: 49.078	
Test: [3250/3923]	Acc@1: 48.954	
Test: [3300/3923]	Acc@1: 49.046	
Test: [3350/3923]	Acc@1: 49.120	
Test: [3400/3923]	Acc@1: 49.089	
Test: [3450/3923]	Acc@1: 49.131	
Test: [3500/3923]	Acc@1: 49.100	
Test: [3550/3923]	Acc@1: 49.099	
Test: [3600/3923]	Acc@1: 49.028	
Test: [3650/3923]	Acc@1: 49.000	
Test: [3700/3923]	Acc@1: 49.000	
Test: [3750/3923]	Acc@1: 48.960	
Test: [3800/3923]	Acc@1: 49.079	
Test: [3850/3923]	Acc@1: 49.039	
Test: [3900/3923]	Acc@1: 49.077	
 * Acc@1 49.082 Acc@5 93.334 UAR 40.916Accuracy of the network on the 7847 test videos: 49.1%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [68/300][0/971]	eta 1:29:32 lr 0.000001759	time 5.5325 (5.5325)	tot_loss 0.3075 (0.3075)	mem 12200MB
Train: [68/300][50/971]	eta 0:07:32 lr 0.000001759	time 0.3511 (0.4911)	tot_loss 0.3140 (0.3833)	mem 12200MB
Train: [68/300][100/971]	eta 0:06:22 lr 0.000001759	time 0.3760 (0.4386)	tot_loss 0.3730 (0.3754)	mem 12200MB
Train: [68/300][150/971]	eta 0:05:46 lr 0.000001758	time 0.3547 (0.4221)	tot_loss 0.3802 (0.3718)	mem 12200MB
Train: [68/300][200/971]	eta 0:05:18 lr 0.000001758	time 0.3644 (0.4127)	tot_loss 0.3961 (0.3717)	mem 12200MB
Train: [68/300][250/971]	eta 0:04:53 lr 0.000001758	time 0.3531 (0.4064)	tot_loss 0.4199 (0.3722)	mem 12200MB
Train: [68/300][300/971]	eta 0:04:31 lr 0.000001757	time 0.3801 (0.4040)	tot_loss 0.4235 (0.3724)	mem 12200MB
Train: [68/300][350/971]	eta 0:04:08 lr 0.000001757	time 0.3670 (0.4008)	tot_loss 0.3243 (0.3736)	mem 12200MB
Train: [68/300][400/971]	eta 0:03:47 lr 0.000001757	time 0.3551 (0.3987)	tot_loss 0.3135 (0.3727)	mem 12200MB
Train: [68/300][450/971]	eta 0:03:26 lr 0.000001756	time 0.3624 (0.3972)	tot_loss 0.3964 (0.3720)	mem 12200MB
Train: [68/300][500/971]	eta 0:03:06 lr 0.000001756	time 0.3770 (0.3960)	tot_loss 0.4019 (0.3724)	mem 12200MB
Train: [68/300][550/971]	eta 0:02:46 lr 0.000001756	time 0.3658 (0.3949)	tot_loss 0.2662 (0.3724)	mem 12200MB
Train: [68/300][600/971]	eta 0:02:26 lr 0.000001755	time 0.3835 (0.3938)	tot_loss 0.4317 (0.3731)	mem 12200MB
Train: [68/300][650/971]	eta 0:02:06 lr 0.000001755	time 0.3567 (0.3930)	tot_loss 0.3314 (0.3728)	mem 12200MB
Train: [68/300][700/971]	eta 0:01:46 lr 0.000001755	time 0.3564 (0.3922)	tot_loss 0.4129 (0.3728)	mem 12200MB
Train: [68/300][750/971]	eta 0:01:26 lr 0.000001754	time 0.3717 (0.3914)	tot_loss 0.4227 (0.3735)	mem 12200MB
Train: [68/300][800/971]	eta 0:01:06 lr 0.000001754	time 0.3533 (0.3910)	tot_loss 0.4594 (0.3741)	mem 12200MB
Train: [68/300][850/971]	eta 0:00:47 lr 0.000001753	time 0.3563 (0.3902)	tot_loss 0.3368 (0.3745)	mem 12200MB
Train: [68/300][900/971]	eta 0:00:27 lr 0.000001753	time 0.3644 (0.3896)	tot_loss 0.3593 (0.3747)	mem 12200MB
Train: [68/300][950/971]	eta 0:00:08 lr 0.000001753	time 0.3364 (0.3891)	tot_loss 0.3864 (0.3749)	mem 12200MB
EPOCH 68 training takes 0:06:17
1 views inference
Test: [0/3923]	Acc@1: 100.000	
Test: [50/3923]	Acc@1: 50.980	
Test: [100/3923]	Acc@1: 46.040	
Test: [150/3923]	Acc@1: 44.040	
Test: [200/3923]	Acc@1: 44.527	
Test: [250/3923]	Acc@1: 45.817	
Test: [300/3923]	Acc@1: 47.010	
Test: [350/3923]	Acc@1: 47.436	
Test: [400/3923]	Acc@1: 48.254	
Test: [450/3923]	Acc@1: 48.115	
Test: [500/3923]	Acc@1: 48.303	
Test: [550/3923]	Acc@1: 48.639	
Test: [600/3923]	Acc@1: 49.501	
Test: [650/3923]	Acc@1: 49.846	
Test: [700/3923]	Acc@1: 50.285	
Test: [750/3923]	Acc@1: 49.601	
Test: [800/3923]	Acc@1: 50.000	
Test: [850/3923]	Acc@1: 50.470	
Test: [900/3923]	Acc@1: 50.555	
Test: [950/3923]	Acc@1: 50.315	
Test: [1000/3923]	Acc@1: 50.150	
Test: [1050/3923]	Acc@1: 49.286	
Test: [1100/3923]	Acc@1: 49.591	
Test: [1150/3923]	Acc@1: 49.870	
Test: [1200/3923]	Acc@1: 50.416	
Test: [1250/3923]	Acc@1: 50.320	
Test: [1300/3923]	Acc@1: 49.923	
Test: [1350/3923]	Acc@1: 49.667	
Test: [1400/3923]	Acc@1: 49.750	
Test: [1450/3923]	Acc@1: 49.897	
Test: [1500/3923]	Acc@1: 49.767	
Test: [1550/3923]	Acc@1: 49.710	
Test: [1600/3923]	Acc@1: 49.875	
Test: [1650/3923]	Acc@1: 49.818	
Test: [1700/3923]	Acc@1: 49.765	
Test: [1750/3923]	Acc@1: 49.943	
Test: [1800/3923]	Acc@1: 49.695	
Test: [1850/3923]	Acc@1: 49.757	
Test: [1900/3923]	Acc@1: 49.711	
Test: [1950/3923]	Acc@1: 49.692	
Test: [2000/3923]	Acc@1: 49.500	
Test: [2050/3923]	Acc@1: 49.464	
Test: [2100/3923]	Acc@1: 49.167	
Test: [2150/3923]	Acc@1: 49.024	
Test: [2200/3923]	Acc@1: 49.000	
Test: [2250/3923]	Acc@1: 49.089	
Test: [2300/3923]	Acc@1: 49.087	
Test: [2350/3923]	Acc@1: 49.234	
Test: [2400/3923]	Acc@1: 49.354	
Test: [2450/3923]	Acc@1: 49.449	
Test: [2500/3923]	Acc@1: 49.400	
Test: [2550/3923]	Acc@1: 49.177	
Test: [2600/3923]	Acc@1: 49.173	
Test: [2650/3923]	Acc@1: 48.982	
Test: [2700/3923]	Acc@1: 49.093	
Test: [2750/3923]	Acc@1: 49.218	
Test: [2800/3923]	Acc@1: 49.268	
Test: [2850/3923]	Acc@1: 49.211	
Test: [2900/3923]	Acc@1: 49.207	
Test: [2950/3923]	Acc@1: 49.238	
Test: [3000/3923]	Acc@1: 49.184	
Test: [3050/3923]	Acc@1: 49.230	
Test: [3100/3923]	Acc@1: 49.258	
Test: [3150/3923]	Acc@1: 49.381	
Test: [3200/3923]	Acc@1: 49.469	
Test: [3250/3923]	Acc@1: 49.523	
Test: [3300/3923]	Acc@1: 49.591	
Test: [3350/3923]	Acc@1: 49.567	
Test: [3400/3923]	Acc@1: 49.559	
Test: [3450/3923]	Acc@1: 49.493	
Test: [3500/3923]	Acc@1: 49.457	
Test: [3550/3923]	Acc@1: 49.465	
Test: [3600/3923]	Acc@1: 49.528	
Test: [3650/3923]	Acc@1: 49.507	
Test: [3700/3923]	Acc@1: 49.554	
Test: [3750/3923]	Acc@1: 49.507	
Test: [3800/3923]	Acc@1: 49.540	
Test: [3850/3923]	Acc@1: 49.598	
Test: [3900/3923]	Acc@1: 49.603	
 * Acc@1 49.579 Acc@5 93.118 UAR 40.987Accuracy of the network on the 7847 test videos: 49.6%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [69/300][0/971]	eta 1:20:07 lr 0.000001753	time 4.9513 (4.9513)	tot_loss 0.4311 (0.4311)	mem 12200MB
Train: [69/300][50/971]	eta 0:07:41 lr 0.000001752	time 0.3631 (0.5006)	tot_loss 0.3286 (0.3726)	mem 12200MB
Train: [69/300][100/971]	eta 0:06:26 lr 0.000001752	time 0.3597 (0.4434)	tot_loss 0.3701 (0.3746)	mem 12200MB
Train: [69/300][150/971]	eta 0:05:46 lr 0.000001752	time 0.3467 (0.4219)	tot_loss 0.3991 (0.3766)	mem 12200MB
Train: [69/300][200/971]	eta 0:05:15 lr 0.000001751	time 0.3532 (0.4086)	tot_loss 0.3107 (0.3769)	mem 12200MB
Train: [69/300][250/971]	eta 0:04:50 lr 0.000001751	time 0.3589 (0.4023)	tot_loss 0.3533 (0.3760)	mem 12200MB
Train: [69/300][300/971]	eta 0:04:28 lr 0.000001750	time 0.3941 (0.4005)	tot_loss 0.3518 (0.3746)	mem 12200MB
Train: [69/300][350/971]	eta 0:04:07 lr 0.000001750	time 0.3517 (0.3980)	tot_loss 0.2956 (0.3767)	mem 12200MB
Train: [69/300][400/971]	eta 0:03:46 lr 0.000001750	time 0.3635 (0.3959)	tot_loss 0.4308 (0.3772)	mem 12200MB
Train: [69/300][450/971]	eta 0:03:25 lr 0.000001749	time 0.3481 (0.3948)	tot_loss 0.3994 (0.3762)	mem 12200MB
Train: [69/300][500/971]	eta 0:03:05 lr 0.000001749	time 0.3599 (0.3934)	tot_loss 0.3556 (0.3761)	mem 12200MB
Train: [69/300][550/971]	eta 0:02:45 lr 0.000001749	time 0.3735 (0.3922)	tot_loss 0.3856 (0.3759)	mem 12200MB
Train: [69/300][600/971]	eta 0:02:25 lr 0.000001748	time 0.3483 (0.3913)	tot_loss 0.3512 (0.3760)	mem 12200MB
Train: [69/300][650/971]	eta 0:02:05 lr 0.000001748	time 0.3563 (0.3899)	tot_loss 0.2509 (0.3753)	mem 12200MB
Train: [69/300][700/971]	eta 0:01:45 lr 0.000001748	time 0.3513 (0.3891)	tot_loss 0.4214 (0.3760)	mem 12200MB
Train: [69/300][750/971]	eta 0:01:25 lr 0.000001747	time 0.3666 (0.3883)	tot_loss 0.3729 (0.3759)	mem 12200MB
Train: [69/300][800/971]	eta 0:01:06 lr 0.000001747	time 0.3572 (0.3878)	tot_loss 0.4237 (0.3762)	mem 12200MB
Train: [69/300][850/971]	eta 0:00:46 lr 0.000001747	time 0.3554 (0.3870)	tot_loss 0.3809 (0.3755)	mem 12200MB
Train: [69/300][900/971]	eta 0:00:27 lr 0.000001746	time 0.3599 (0.3863)	tot_loss 0.3579 (0.3757)	mem 12200MB
Train: [69/300][950/971]	eta 0:00:08 lr 0.000001746	time 0.3400 (0.3854)	tot_loss 0.4386 (0.3765)	mem 12200MB
EPOCH 69 training takes 0:06:13
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 51.961	
Test: [100/3923]	Acc@1: 49.010	
Test: [150/3923]	Acc@1: 45.364	
Test: [200/3923]	Acc@1: 44.776	
Test: [250/3923]	Acc@1: 47.012	
Test: [300/3923]	Acc@1: 47.508	
Test: [350/3923]	Acc@1: 47.293	
Test: [400/3923]	Acc@1: 48.504	
Test: [450/3923]	Acc@1: 48.448	
Test: [500/3923]	Acc@1: 49.501	
Test: [550/3923]	Acc@1: 49.456	
Test: [600/3923]	Acc@1: 49.501	
Test: [650/3923]	Acc@1: 49.309	
Test: [700/3923]	Acc@1: 49.358	
Test: [750/3923]	Acc@1: 49.467	
Test: [800/3923]	Acc@1: 49.438	
Test: [850/3923]	Acc@1: 49.765	
Test: [900/3923]	Acc@1: 49.889	
Test: [950/3923]	Acc@1: 50.053	
Test: [1000/3923]	Acc@1: 50.450	
Test: [1050/3923]	Acc@1: 50.428	
Test: [1100/3923]	Acc@1: 50.590	
Test: [1150/3923]	Acc@1: 50.608	
Test: [1200/3923]	Acc@1: 50.958	
Test: [1250/3923]	Acc@1: 50.799	
Test: [1300/3923]	Acc@1: 50.884	
Test: [1350/3923]	Acc@1: 50.629	
Test: [1400/3923]	Acc@1: 50.500	
Test: [1450/3923]	Acc@1: 50.482	
Test: [1500/3923]	Acc@1: 50.566	
Test: [1550/3923]	Acc@1: 50.226	
Test: [1600/3923]	Acc@1: 50.312	
Test: [1650/3923]	Acc@1: 50.121	
Test: [1700/3923]	Acc@1: 49.971	
Test: [1750/3923]	Acc@1: 50.228	
Test: [1800/3923]	Acc@1: 50.056	
Test: [1850/3923]	Acc@1: 50.243	
Test: [1900/3923]	Acc@1: 50.132	
Test: [1950/3923]	Acc@1: 50.000	
Test: [2000/3923]	Acc@1: 50.000	
Test: [2050/3923]	Acc@1: 49.878	
Test: [2100/3923]	Acc@1: 49.905	
Test: [2150/3923]	Acc@1: 50.209	
Test: [2200/3923]	Acc@1: 50.136	
Test: [2250/3923]	Acc@1: 50.222	
Test: [2300/3923]	Acc@1: 50.217	
Test: [2350/3923]	Acc@1: 50.170	
Test: [2400/3923]	Acc@1: 50.271	
Test: [2450/3923]	Acc@1: 50.122	
Test: [2500/3923]	Acc@1: 50.220	
Test: [2550/3923]	Acc@1: 50.118	
Test: [2600/3923]	Acc@1: 50.058	
Test: [2650/3923]	Acc@1: 50.189	
Test: [2700/3923]	Acc@1: 50.148	
Test: [2750/3923]	Acc@1: 50.273	
Test: [2800/3923]	Acc@1: 50.179	
Test: [2850/3923]	Acc@1: 50.105	
Test: [2900/3923]	Acc@1: 50.121	
Test: [2950/3923]	Acc@1: 50.271	
Test: [3000/3923]	Acc@1: 50.267	
Test: [3050/3923]	Acc@1: 50.393	
Test: [3100/3923]	Acc@1: 50.339	
Test: [3150/3923]	Acc@1: 50.238	
Test: [3200/3923]	Acc@1: 50.141	
Test: [3250/3923]	Acc@1: 50.046	
Test: [3300/3923]	Acc@1: 49.879	
Test: [3350/3923]	Acc@1: 49.896	
Test: [3400/3923]	Acc@1: 49.956	
Test: [3450/3923]	Acc@1: 50.000	
Test: [3500/3923]	Acc@1: 49.929	
Test: [3550/3923]	Acc@1: 49.873	
Test: [3600/3923]	Acc@1: 49.889	
Test: [3650/3923]	Acc@1: 49.890	
Test: [3700/3923]	Acc@1: 49.878	
Test: [3750/3923]	Acc@1: 49.933	
Test: [3800/3923]	Acc@1: 49.908	
Test: [3850/3923]	Acc@1: 49.857	
Test: [3900/3923]	Acc@1: 49.885	
 * Acc@1 49.949 Acc@5 93.500 UAR 39.799Accuracy of the network on the 7847 test videos: 49.9%
Max accuracy: 51.08%, Current UAR : 40.32%, Max UAR :41.11%Train: [70/300][0/971]	eta 1:35:51 lr 0.000001746	time 5.9232 (5.9232)	tot_loss 0.3018 (0.3018)	mem 12200MB
Train: [70/300][50/971]	eta 0:07:36 lr 0.000001745	time 0.3566 (0.4952)	tot_loss 0.3196 (0.3680)	mem 12200MB
Train: [70/300][100/971]	eta 0:06:24 lr 0.000001745	time 0.3721 (0.4418)	tot_loss 0.4103 (0.3753)	mem 12200MB
Train: [70/300][150/971]	eta 0:05:46 lr 0.000001745	time 0.3571 (0.4222)	tot_loss 0.3662 (0.3750)	mem 12200MB
Train: [70/300][200/971]	eta 0:05:17 lr 0.000001744	time 0.3640 (0.4112)	tot_loss 0.3919 (0.3754)	mem 12200MB
Train: [70/300][250/971]	eta 0:04:52 lr 0.000001744	time 0.3619 (0.4056)	tot_loss 0.2910 (0.3749)	mem 12200MB
Train: [70/300][300/971]	eta 0:04:30 lr 0.000001744	time 0.3999 (0.4029)	tot_loss 0.3861 (0.3744)	mem 12200MB
Train: [70/300][350/971]	eta 0:04:08 lr 0.000001743	time 0.3614 (0.4001)	tot_loss 0.3888 (0.3736)	mem 12200MB
Train: [70/300][400/971]	eta 0:03:47 lr 0.000001743	time 0.3587 (0.3981)	tot_loss 0.4203 (0.3746)	mem 12200MB
Train: [70/300][450/971]	eta 0:03:26 lr 0.000001743	time 0.3530 (0.3968)	tot_loss 0.4313 (0.3754)	mem 12200MB
Train: [70/300][500/971]	eta 0:03:06 lr 0.000001742	time 0.3574 (0.3960)	tot_loss 0.3737 (0.3761)	mem 12200MB
Train: [70/300][550/971]	eta 0:02:46 lr 0.000001742	time 0.3664 (0.3947)	tot_loss 0.3758 (0.3759)	mem 12200MB
Train: [70/300][600/971]	eta 0:02:26 lr 0.000001741	time 0.3583 (0.3939)	tot_loss 0.3852 (0.3746)	mem 12200MB
Train: [70/300][650/971]	eta 0:02:06 lr 0.000001741	time 0.3546 (0.3925)	tot_loss 0.3144 (0.3745)	mem 12200MB
Train: [70/300][700/971]	eta 0:01:46 lr 0.000001741	time 0.3696 (0.3918)	tot_loss 0.4453 (0.3751)	mem 12200MB
Train: [70/300][750/971]	eta 0:01:26 lr 0.000001740	time 0.3694 (0.3912)	tot_loss 0.3962 (0.3761)	mem 12200MB
Train: [70/300][800/971]	eta 0:01:06 lr 0.000001740	time 0.3628 (0.3908)	tot_loss 0.3647 (0.3762)	mem 12200MB
Train: [70/300][850/971]	eta 0:00:47 lr 0.000001740	time 0.3617 (0.3901)	tot_loss 0.3175 (0.3755)	mem 12200MB
Train: [70/300][900/971]	eta 0:00:27 lr 0.000001739	time 0.3656 (0.3898)	tot_loss 0.3467 (0.3754)	mem 12200MB
Train: [70/300][950/971]	eta 0:00:08 lr 0.000001739	time 0.3436 (0.3893)	tot_loss 0.3996 (0.3757)	mem 12200MB
EPOCH 70 training takes 0:06:17
1 views inference
Test: [0/3923]	Acc@1: 50.000	
Test: [50/3923]	Acc@1: 44.118	
Test: [100/3923]	Acc@1: 45.545	
Test: [150/3923]	Acc@1: 45.033	
Test: [200/3923]	Acc@1: 43.781	
Test: [250/3923]	Acc@1: 43.825	
Test: [300/3923]	Acc@1: 43.688	
Test: [350/3923]	Acc@1: 44.587	
Test: [400/3923]	Acc@1: 45.012	
Test: [450/3923]	Acc@1: 45.233	
Test: [500/3923]	Acc@1: 44.810	
Test: [550/3923]	Acc@1: 44.465	
Test: [600/3923]	Acc@1: 44.925	
Test: [650/3923]	Acc@1: 45.161	
Test: [700/3923]	Acc@1: 45.292	
Test: [750/3923]	Acc@1: 45.739	
Test: [800/3923]	Acc@1: 45.880	
